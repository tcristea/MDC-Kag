{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cbdbbca",
   "metadata": {
    "papermill": {
     "duration": 0.006417,
     "end_time": "2025-07-08T18:29:40.903930",
     "exception": false,
     "start_time": "2025-07-08T18:29:40.897513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📈 Inference Pipeline (No GROBID)\n",
    "\n",
    "This notebook:\n",
    "- Loads your trained classifier (`saved_model`)\n",
    "- Reads PDFs directly via Marker-PDF\n",
    "- Predicts `type`\n",
    "- Extracts `dataset_id` using regex\n",
    "- Produces `submission.csv`\n",
    "\n",
    "**Note:** No GROBID needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0897b007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:29:40.915436Z",
     "iopub.status.busy": "2025-07-08T18:29:40.915147Z",
     "iopub.status.idle": "2025-07-08T18:29:40.922058Z",
     "shell.execute_reply": "2025-07-08T18:29:40.921221Z"
    },
    "papermill": {
     "duration": 0.01392,
     "end_time": "2025-07-08T18:29:40.923347",
     "exception": false,
     "start_time": "2025-07-08T18:29:40.909427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SUBMIT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ed7a25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:29:40.933868Z",
     "iopub.status.busy": "2025-07-08T18:29:40.933277Z",
     "iopub.status.idle": "2025-07-08T18:32:45.893292Z",
     "shell.execute_reply": "2025-07-08T18:32:45.892325Z"
    },
    "papermill": {
     "duration": 184.966855,
     "end_time": "2025-07-08T18:32:45.894754",
     "exception": false,
     "start_time": "2025-07-08T18:29:40.927899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./cache/pip/wheels/8d/ac/a9/4e6dd2d86235ea3da1c286279118c49e931f77cfb33e9b1af5/EbookLib-0.18-py3-none-any.whl\r\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from EbookLib==0.18) (5.3.1)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from EbookLib==0.18) (1.17.0)\r\n",
      "Installing collected packages: EbookLib\r\n",
      "Successfully installed EbookLib-0.18\r\n",
      "Looking in links: /kaggle/input/mdc-marker-pdf-reqs\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/marker_pdf-1.8.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (from marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/anthropic-0.46.0-py3-none-any.whl (from marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/click-8.2.1-py3-none-any.whl (from marker-pdf[full])\r\n",
      "Requirement already satisfied: ebooklib<0.19,>=0.18 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (0.18)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/filetype-1.2.0-py2.py3-none-any.whl (from marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/ftfy-6.3.1-py3-none-any.whl (from marker-pdf[full])\r\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (1.9.0)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/mammoth-1.9.1-py2.py3-none-any.whl (from marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/markdown2-2.5.3-py3-none-any.whl (from marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/markdownify-1.1.0-py3-none-any.whl (from marker-pdf[full])\r\n",
      "Requirement already satisfied: openai<2.0.0,>=1.65.2 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (1.70.0)\r\n",
      "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (3.1.5)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/pdftext-0.6.3-py3-none-any.whl (from marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/pre_commit-4.2.0-py2.py3-none-any.whl (from marker-pdf[full])\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (2.11.4)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/pydantic_settings-2.10.1-py3-none-any.whl (from marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/python_dotenv-1.1.1-py3-none-any.whl (from marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/python_pptx-1.0.2-py3-none-any.whl (from marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from marker-pdf[full])\r\n",
      "Requirement already satisfied: regex<2025.0.0,>=2024.4.28 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (2024.11.6)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/surya_ocr-0.14.6-py3-none-any.whl (from marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (from marker-pdf[full])\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (4.67.1)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.45.2 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (4.51.3)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/weasyprint-63.1-py3-none-any.whl (from marker-pdf[full])\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (4.9.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (0.28.1)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (0.9.0)\r\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (1.3.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (4.13.2)\r\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from ebooklib<0.19,>=0.18->marker-pdf[full]) (5.3.1)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from ebooklib<0.19,>=0.18->marker-pdf[full]) (1.17.0)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy<7.0.0,>=6.1.1->marker-pdf[full]) (0.2.13)\r\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (2.40.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (2.32.3)\r\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (15.0.1)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/cobble-0.1.4-py3-none-any.whl (from mammoth<2.0.0,>=1.9.0->marker-pdf[full])\r\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /usr/local/lib/python3.11/dist-packages (from markdownify<2.0.0,>=1.1.0->marker-pdf[full]) (4.13.3)\r\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl<4.0.0,>=3.1.5->marker-pdf[full]) (2.0.0)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from pdftext<0.7.0,>=0.6.3->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/cfgv-3.4.0-py2.py3-none-any.whl (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/identify-2.6.12-py2.py3-none-any.whl (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nodeenv-1.9.1-py2.py3-none-any.whl (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full])\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full]) (6.0.2)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/virtualenv-20.31.2-py3-none-any.whl (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full])\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->marker-pdf[full]) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->marker-pdf[full]) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->marker-pdf[full]) (0.4.0)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/xlsxwriter-3.2.5-py3-none-any.whl (from python-pptx<2.0.0,>=1.0.2->marker-pdf[full])\r\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (1.15.2)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (1.5.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (3.6.0)\r\n",
      "Requirement already satisfied: einops<0.9.0,>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from surya-ocr<0.15.0,>=0.14.6->marker-pdf[full]) (0.8.1)\r\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from surya-ocr<0.15.0,>=0.14.6->marker-pdf[full]) (4.11.0.86)\r\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.6 in /usr/local/lib/python3.11/dist-packages (from surya-ocr<0.15.0,>=0.14.6->marker-pdf[full]) (4.3.8)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.7.0->marker-pdf[full]) (3.18.0)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/sympy-1.14.0-py3-none-any.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.7.0->marker-pdf[full]) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.7.0->marker-pdf[full]) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.7.0->marker-pdf[full]) (2025.3.2)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (from torch<3.0.0,>=2.7.0->marker-pdf[full])\r\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch<3.0.0,>=2.7.0->marker-pdf[full]) (75.2.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.2->marker-pdf[full]) (0.31.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.2->marker-pdf[full]) (25.0)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.2->marker-pdf[full]) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.2->marker-pdf[full]) (0.5.3)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/pydyf-0.11.0-py3-none-any.whl (from weasyprint<64.0,>=63.1->marker-pdf[full])\r\n",
      "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.11/dist-packages (from weasyprint<64.0,>=63.1->marker-pdf[full]) (1.17.1)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/tinyhtml5-2.0.0-py3-none-any.whl (from weasyprint<64.0,>=63.1->marker-pdf[full])\r\n",
      "Requirement already satisfied: tinycss2>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint<64.0,>=63.1->marker-pdf[full]) (1.4.0)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/cssselect2-0.8.0-py3-none-any.whl (from weasyprint<64.0,>=63.1->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/pyphen-0.17.2-py3-none-any.whl (from weasyprint<64.0,>=63.1->marker-pdf[full])\r\n",
      "Requirement already satisfied: fonttools>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint<64.0,>=63.1->marker-pdf[full]) (4.57.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (3.10)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.9->markdownify<2.0.0,>=1.1.0->marker-pdf[full]) (2.6)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=0.6->weasyprint<64.0,>=63.1->marker-pdf[full]) (2.22)\r\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from cssselect2>=0.1->weasyprint<64.0,>=63.1->marker-pdf[full]) (0.5.1)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from fonttools[woff]>=4.0.0->weasyprint<64.0,>=63.1->marker-pdf[full])\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/zopfli-0.2.3.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from fonttools[woff]>=4.0.0->weasyprint<64.0,>=63.1->marker-pdf[full])\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (5.5.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (0.4.2)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (4.9.1)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (2025.4.26)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (1.0.7)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (0.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers<5.0.0,>=4.45.2->marker-pdf[full]) (1.1.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (2.4.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch<3.0.0,>=2.7.0->marker-pdf[full]) (1.3.0)\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/distlib-0.3.9-py2.py3-none-any.whl (from virtualenv>=20.10.0->pre-commit<5.0.0,>=4.2.0->marker-pdf[full])\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.7.0->marker-pdf[full]) (3.0.2)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (0.6.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.0->scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.0->scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.0->scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.0->scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.0->scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (2024.2.0)\r\n",
      "Installing collected packages: nvidia-cusparselt-cu12, filetype, distlib, brotli, zopfli, XlsxWriter, virtualenv, triton, tinyhtml5, sympy, rapidfuzz, python-dotenv, Pyphen, pypdfium2, pydyf, Pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nodeenv, markdown2, identify, ftfy, cobble, click, cfgv, python-pptx, pre-commit, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, markdownify, mammoth, cssselect2, weasyprint, pydantic-settings, nvidia-cusolver-cu12, anthropic, torch, pdftext, surya-ocr, scikit-learn, marker-pdf\r\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\r\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\r\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\r\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.2.0\r\n",
      "    Uninstalling triton-3.2.0:\r\n",
      "      Successfully uninstalled triton-3.2.0\r\n",
      "  Attempting uninstall: sympy\r\n",
      "    Found existing installation: sympy 1.13.1\r\n",
      "    Uninstalling sympy-1.13.1:\r\n",
      "      Successfully uninstalled sympy-1.13.1\r\n",
      "  Attempting uninstall: Pillow\r\n",
      "    Found existing installation: pillow 11.1.0\r\n",
      "    Uninstalling pillow-11.1.0:\r\n",
      "      Successfully uninstalled pillow-11.1.0\r\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\r\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\r\n",
      "  Attempting uninstall: nvidia-nccl-cu12\r\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\r\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\r\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\r\n",
      "  Attempting uninstall: click\r\n",
      "    Found existing installation: click 8.1.8\r\n",
      "    Uninstalling click-8.1.8:\r\n",
      "      Successfully uninstalled click-8.1.8\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.6.0+cu124\r\n",
      "    Uninstalling torch-2.6.0+cu124:\r\n",
      "      Successfully uninstalled torch-2.6.0+cu124\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.0 which is incompatible.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\r\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\r\n",
      "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed Pillow-10.4.0 Pyphen-0.17.2 XlsxWriter-3.2.5 anthropic-0.46.0 brotli-1.1.0 cfgv-3.4.0 click-8.2.1 cobble-0.1.4 cssselect2-0.8.0 distlib-0.3.9 filetype-1.2.0 ftfy-6.3.1 identify-2.6.12 mammoth-1.9.1 markdown2-2.5.3 markdownify-1.1.0 marker-pdf-1.8.0 nodeenv-1.9.1 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pdftext-0.6.3 pre-commit-4.2.0 pydantic-settings-2.10.1 pydyf-0.11.0 pypdfium2-4.30.0 python-dotenv-1.1.1 python-pptx-1.0.2 rapidfuzz-3.13.0 scikit-learn-1.7.0 surya-ocr-0.14.6 sympy-1.14.0 tinyhtml5-2.0.0 torch-2.7.1 triton-3.3.1 virtualenv-20.31.2 weasyprint-63.1 zopfli-0.2.3.post1\r\n",
      "Looking in links: /kaggle/input/mdc-marker-pdf-reqs\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\r\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Processing /kaggle/input/mdc-marker-pdf-reqs/torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Requirement already satisfied: torch==2.7.1 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.7.1)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (10.4.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (4.13.2)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (9.5.1.17)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (0.6.3)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (2.26.2)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (3.3.1)\r\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch==2.7.1->torchvision) (75.2.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.1->torchvision) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.1->torchvision) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Installing collected packages: torchvision\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.21.0+cu124\r\n",
      "    Uninstalling torchvision-0.21.0+cu124:\r\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torchvision-0.22.1\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "! mkdir cache data\n",
    "os.environ[\"XDG_CACHE_HOME\"] = os.path.join(os.getcwd(), \"cache\")\n",
    "os.environ[\"XDG_DATA_HOME\"] = os.path.join(os.getcwd(), \"data\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "! cp -r /kaggle/input/datalab-marker/kaggle/working/datalab ./cache\n",
    "! cp -r /kaggle/input/pip-datalab/kaggle/working/cache/pip ./cache\n",
    "! mkdir -p /usr/local/lib/python3.11/dist-packages/static/fonts\n",
    "! cp /kaggle/input/marker-font/GoNotoCurrent-Regular.ttf /usr/local/lib/python3.11/dist-packages/static/fonts/GoNotoCurrent-Regular.ttf\n",
    "! pip install /kaggle/working/cache/pip/wheels/8d/ac/a9/4e6dd2d86235ea3da1c286279118c49e931f77cfb33e9b1af5/EbookLib-0.18-py3-none-any.whl\n",
    "! sh /kaggle/input/mdc-marker-pdf-reqs/install_requirements.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2516b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:32:45.916401Z",
     "iopub.status.busy": "2025-07-08T18:32:45.915533Z",
     "iopub.status.idle": "2025-07-08T18:33:10.741059Z",
     "shell.execute_reply": "2025-07-08T18:33:10.740416Z"
    },
    "papermill": {
     "duration": 24.837915,
     "end_time": "2025-07-08T18:33:10.742392",
     "exception": false,
     "start_time": "2025-07-08T18:32:45.904477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-08 18:32:58.831290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751999579.011715      18 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751999579.070381      18 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# 📚 Imports\n",
    "import re\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "from marker.output import text_from_rendered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fec8ce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:33:10.762392Z",
     "iopub.status.busy": "2025-07-08T18:33:10.761397Z",
     "iopub.status.idle": "2025-07-08T18:33:15.578956Z",
     "shell.execute_reply": "2025-07-08T18:33:15.578045Z"
    },
    "papermill": {
     "duration": 4.829186,
     "end_time": "2025-07-08T18:33:15.580720",
     "exception": false,
     "start_time": "2025-07-08T18:33:10.751534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 🧠 Load model and tokenizer\n",
    "model_path = \"/kaggle/input/makedatacount-mixed-train/saved_model_dual_text\"\n",
    "token_path = model_path\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(token_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288747b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:33:15.611469Z",
     "iopub.status.busy": "2025-07-08T18:33:15.611249Z",
     "iopub.status.idle": "2025-07-08T18:33:15.617440Z",
     "shell.execute_reply": "2025-07-08T18:33:15.616933Z"
    },
    "papermill": {
     "duration": 0.020738,
     "end_time": "2025-07-08T18:33:15.618543",
     "exception": false,
     "start_time": "2025-07-08T18:33:15.597805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 🧩 Utility functions\n",
    "REPO_KEYWORDS = ['zenodo', 'dryad', 'figshare', 'pangaea', 'tcia']\n",
    "\n",
    "def standardize_doi(doi):\n",
    "    doi = str(doi).strip()\n",
    "    if doi.startswith(\"http\"):\n",
    "        return doi #.lower()\n",
    "    if doi.startswith(\"doi:\"):\n",
    "        return \"https://doi.org/\" + doi[4:] #.lower()\n",
    "    if doi.startswith(\"10.\"):\n",
    "        return \"https://doi.org/\" + doi #.lower()\n",
    "    return doi #.lower()\n",
    "\n",
    "def extract_dataset_dois(text):\n",
    "    text = text.replace('](', '] (').replace(')](', ') (')\n",
    "    url_pattern = r'https?://[^\\s\\)<>\\]]+'\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    doi_pattern = r'\\b10\\.\\d{4,9}/[^\\s\\)<>\\]]+'\n",
    "    bare_dois = re.findall(doi_pattern, text)\n",
    "\n",
    "    candidates = []\n",
    "    for u in urls:\n",
    "        if 'doi.org/10.' in u:\n",
    "            candidates.append(u.rstrip('.,;)]>'))\n",
    "    for d in bare_dois:\n",
    "        candidates.append(standardize_doi(d))\n",
    "\n",
    "    return sorted(set(candidates))\n",
    "\n",
    "def find_accession_ids_in_text(text):\n",
    "    patterns = [\n",
    "        r'\\b(GSE\\d+)\\b',\n",
    "        r'\\b(PRJ[ENAD]\\d+)\\b',\n",
    "        r'\\b(SRP\\d+)\\b',\n",
    "        r'\\b(E-[A-Z]+-\\d+)\\b',\n",
    "        r'\\b(pdb\\s[\\d\\w]+)\\b',\n",
    "        r'\\b(CHEMBL\\d+)\\b'\n",
    "    ]\n",
    "    matches = []\n",
    "    for pat in patterns:\n",
    "        matches.extend(re.findall(pat, text, re.IGNORECASE))\n",
    "    return [m.replace(\" \", \"\") for m in matches] #[m.lower().replace(\" \", \"\") for m in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93cec4ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:33:15.637167Z",
     "iopub.status.busy": "2025-07-08T18:33:15.636973Z",
     "iopub.status.idle": "2025-07-08T18:33:15.642044Z",
     "shell.execute_reply": "2025-07-08T18:33:15.641516Z"
    },
    "papermill": {
     "duration": 0.01558,
     "end_time": "2025-07-08T18:33:15.643150",
     "exception": false,
     "start_time": "2025-07-08T18:33:15.627570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_accession_patterns=['(GSE\\\\d+)',\n",
    " '(PRJ[ENAD]\\\\d+)',\n",
    " '(SRP\\\\d+)',\n",
    " '(E\\\\-[A-Z]+\\\\-\\\\d+)',\n",
    " '(CHEMBL\\\\d+)',\n",
    " '([A-Z0-9]{4})',\n",
    " '(BX\\\\d+)',\n",
    " '(CAB\\\\d+)',\n",
    " '(CP\\\\d+)',\n",
    " '(CVCL\\\\d+)',\n",
    " '(D\\\\d+)',\n",
    " '(EMPIAR\\\\d+)',\n",
    " '(ENSBTAG\\\\d+)',\n",
    " '(ENSMMUT\\\\d+)',\n",
    " '(ENSOARG\\\\d+)',\n",
    " '(EPI\\\\d+)',\n",
    " '(ERR\\\\d+)',\n",
    " '(F\\\\d+)',\n",
    " '(HPA\\\\d+)',\n",
    " '(IPR\\\\d+)',\n",
    " '(K\\\\d+)',\n",
    " '(KX\\\\d+)',\n",
    " '(MODEL\\\\d+)',\n",
    " '(NC\\\\d+)',\n",
    " '(NM\\\\d+)',\n",
    " '(O\\\\d+)',\n",
    " '(P\\\\d+)',\n",
    " '(PF\\\\d+)',\n",
    " '(PRJNA\\\\d+)',\n",
    " '(PXD\\\\d+)',\n",
    " '(Q\\\\d+)',\n",
    " '(SAMN\\\\d+)',\n",
    " '(SRR\\\\d+)',\n",
    " '(SRX\\\\d+)',\n",
    " '(STH\\\\d+)']\n",
    "\n",
    "# DOI extractor\n",
    "def extract_dois(text):\n",
    "    # Regex for DOI-like URLs\n",
    "    doi_pattern = r'https?://doi\\.org/10\\.\\d{4,9}/[^\\s\\)\\]\\}\\.,;]+'\n",
    "    matches = re.findall(doi_pattern, text)\n",
    "    # Deduplicate & clean\n",
    "    return sorted(set(m.rstrip('.;,)]>') for m in matches))\n",
    "\n",
    "# Accession extractor\n",
    "def extract_accessions(text):\n",
    "    found = []\n",
    "    for pat in all_accession_patterns:\n",
    "        found.extend(re.findall(pat, text, re.IGNORECASE))\n",
    "    return sorted(set(f for f in found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6344e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:33:15.661529Z",
     "iopub.status.busy": "2025-07-08T18:33:15.661346Z",
     "iopub.status.idle": "2025-07-08T18:33:15.666985Z",
     "shell.execute_reply": "2025-07-08T18:33:15.666428Z"
    },
    "papermill": {
     "duration": 0.015863,
     "end_time": "2025-07-08T18:33:15.668020",
     "exception": false,
     "start_time": "2025-07-08T18:33:15.652157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_dataset_ids(text):\n",
    "    \"\"\"\n",
    "    Extract DOIs and known accession IDs robustly.\n",
    "    Returns a sorted list of unique dataset IDs.\n",
    "    \"\"\"\n",
    "    repos = ['dryad','zenodo','figshare','pangaea','tcia','p9','d9','pasta','cranfield','dtu','usn','f7','jb','xyb','dl']\n",
    "    candidates = set()\n",
    "\n",
    "    # DOI pattern (strict)\n",
    "    doi_pattern = r'10\\.\\d{4,9}/[^\\s\\)\\]<]+'\n",
    "    for match in re.findall(doi_pattern, text):\n",
    "        clean = match.rstrip('.,;)]>').strip()\n",
    "        # Keep only known repositories\n",
    "        if any(repo in clean.lower() for repo in repos):\n",
    "            candidates.add(f\"https://doi.org/{clean}\")\n",
    "\n",
    "    # Accession patterns\n",
    "    accession_patterns = [\n",
    "        r'\\b(GSE\\d+)\\b',\n",
    "        r'\\b(PRJ[EDNA]\\d+)\\b',\n",
    "        r'\\b(SRP\\d+)\\b',\n",
    "        r'\\b(E-[A-Z]+-\\d+)\\b',\n",
    "        r'\\b(pdb\\s*\\w+)\\b',\n",
    "        r'\\b(CHEMBL\\d+)\\b',\n",
    "        r'\\b(EMPIAR\\d+)\\b',\n",
    "        r'\\b(ENSM\\d+)\\b',\n",
    "        r'\\b(PXD\\d+)\\b',\n",
    "        r'\\b(SAMN\\d+)\\b',\n",
    "        r'\\b(SRR\\d+)\\b',\n",
    "        r'\\b(SRX\\d+)\\b',\n",
    "        r'\\b(IPR\\d+)\\b',\n",
    "        r'\\b(SVA\\d+)\\b',\n",
    "        r'\\b(NC_\\d+\\.\\d+)\\b',\n",
    "        r'\\b(NM_\\d+)\\b',\n",
    "        r'\\b(PF\\d+)\\b',\n",
    "        r'\\b(K\\d+)\\b',\n",
    "        r'\\b(Q\\d+)\\b',\n",
    "        r'\\b(O\\d+)\\b',\n",
    "        r'\\b(MODEL\\d+)\\b',\n",
    "        r'\\b(rs\\d+)\\b',\n",
    "    ]\n",
    "    for pat in accession_patterns:\n",
    "        candidates.update(re.findall(pat, text))\n",
    "\n",
    "    # Filter: drop very short garbage\n",
    "    candidates = [c for c in candidates if len(c) >= 5]\n",
    "\n",
    "    return sorted(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09e2daff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:33:15.686395Z",
     "iopub.status.busy": "2025-07-08T18:33:15.686209Z",
     "iopub.status.idle": "2025-07-08T18:33:15.692400Z",
     "shell.execute_reply": "2025-07-08T18:33:15.691906Z"
    },
    "papermill": {
     "duration": 0.016619,
     "end_time": "2025-07-08T18:33:15.693476",
     "exception": false,
     "start_time": "2025-07-08T18:33:15.676857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# REGEX\n",
    "re_doi = re.compile(r\"10\\.\\d{4}\")\n",
    "big_re = re.compile(r\"GSE\\d+|SR[APRX]\\d+|PRJ[NAED][A-Z]?\\d+|IPR\\d{6}|PF\\d{5}|EMPIAR-\\d{5}|CHEMBL\\d+|CVCL_[A-Z0-9]{4}|ENS[A-Z]{0,6}[GT]\\d{11}|N[MC]_\\d+(?:\\.\\d+)?|rs\\d+|EPI(?:_ISL_)?\\d+|PXD\\d{6}|SAM[ND]\\d+|ERR\\d+\", re.I)\n",
    "\n",
    "# REMOVE REFERENCES\n",
    "def remove_references_section(text):\n",
    "    lines = text.split('\\n')\n",
    "    cut_index = -1\n",
    "    for i in range(len(lines) - 1, max(0, int(len(lines) * 0.3)), -1):\n",
    "        line = lines[i].strip()\n",
    "        patterns = [r'^REFERENCES?$', r'^\\d+\\.?\\s+REFERENCES?$', r'^\\d+\\.?\\s+References?$', r'^References?:$',\n",
    "                    r'^BIBLIOGRAPHY$', r'^\\d+\\.?\\s+BIBLIOGRAPHY$', r'^\\d+\\.?\\s+Bibliography$', r'^Bibliography:$',\n",
    "                    r'^Literature\\s+Cited$', r'^Works\\s+Cited$']\n",
    "        if any(re.match(p, line, re.I) for p in patterns):\n",
    "            following = lines[i+1:i+4]\n",
    "            if any(re.search(r'\\(\\d{4}\\)|\\d{4}\\.|doi:| et al', fl, re.I) for fl in following):\n",
    "                cut_index = i\n",
    "                break\n",
    "    return '\\n'.join(lines[:cut_index]).strip() if cut_index != -1 else text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5414b28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:33:15.712941Z",
     "iopub.status.busy": "2025-07-08T18:33:15.712717Z",
     "iopub.status.idle": "2025-07-08T18:33:15.715582Z",
     "shell.execute_reply": "2025-07-08T18:33:15.715071Z"
    },
    "papermill": {
     "duration": 0.013241,
     "end_time": "2025-07-08T18:33:15.716544",
     "exception": false,
     "start_time": "2025-07-08T18:33:15.703303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_article_id(filename):\n",
    "    # return filename[:-4].replace(\"_\", \"/\")\n",
    "    return Path(pdf_path).stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e53998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:33:15.734981Z",
     "iopub.status.busy": "2025-07-08T18:33:15.734746Z",
     "iopub.status.idle": "2025-07-08T18:33:15.738324Z",
     "shell.execute_reply": "2025-07-08T18:33:15.737732Z"
    },
    "papermill": {
     "duration": 0.013855,
     "end_time": "2025-07-08T18:33:15.739358",
     "exception": false,
     "start_time": "2025-07-08T18:33:15.725503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"DETECTOR_MODEL_CHECKPOINT\"] = \"/kaggle/working/cache/datalab/modelstext_detection/2025_05_07\"\n",
    "os.environ[\"RECOGNITION_MODEL_CHECKPOINT\"] = \"/kaggle/working/cache/datalab/modelstext_recognition/2025_05_16\"\n",
    "os.environ[\"LAYOUT_MODEL_CHECKPOINT\"] = \"/kaggle/working/cache/datalab/modelslayout/2025_02_18\"\n",
    "os.environ[\"OCR_ERROR_MODEL_CHECKPOINT\"] = \"/kaggle/working/cache/datalab/modelsocr_error_detection/2025_02_18\"\n",
    "os.environ[\"TABLE_REC_MODEL_CHECKPOINT\"] = \"/kaggle/working/cache/datalab/modelstable_recognition/2025_02_18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e168062e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:33:15.757648Z",
     "iopub.status.busy": "2025-07-08T18:33:15.757451Z",
     "iopub.status.idle": "2025-07-08T18:33:31.288395Z",
     "shell.execute_reply": "2025-07-08T18:33:31.287024Z"
    },
    "papermill": {
     "duration": 15.542878,
     "end_time": "2025-07-08T18:33:31.290882",
     "exception": false,
     "start_time": "2025-07-08T18:33:15.748004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collect PDF files\n",
    "# pdf_files = sorted(glob(os.path.join(pdf_dir, \"*.pdf\")))\n",
    "\n",
    "# Collect XML basenames for lookup\n",
    "import os\n",
    "if SUBMIT:\n",
    "    pdf_dir = \"/kaggle/input/make-data-count-finding-data-references/test/PDF\"\n",
    "    xml_dir = \"/kaggle/input/make-data-count-finding-data-references/test/XML\"\n",
    "else: # infer on train_labels\n",
    "    pdf_dir = \"/kaggle/input/make-data-count-finding-data-references/train/PDF\"\n",
    "    xml_dir = \"/kaggle/input/make-data-count-finding-data-references/train/XML\"\n",
    "pdf_files = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")]\n",
    "# xml_basenames = [os.path.join(xml_dir, f) for f in os.listdir(xml_dir) if f.endswith(\".xml\")]\n",
    "xml_basenames = set(\n",
    "    os.path.splitext(os.path.basename(p))[0]\n",
    "    for p in glob(os.path.join(xml_dir, \"*.xml\"))\n",
    ")\n",
    "\n",
    "# pdf_files = sorted(glob(os.path.join(pdf_dir, \"*.pdf\")))\n",
    "converter = PdfConverter(artifact_dict=create_model_dict(device='cuda'))\n",
    "\n",
    "rows = []\n",
    "def extract_text_from_pdf(file_path):\n",
    "    rendered = converter(file_path)\n",
    "    text, _, _ = text_from_rendered(rendered)\n",
    "    #text = remove_references_section(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad7b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T09:33:11.729940Z",
     "iopub.status.busy": "2025-07-08T09:33:11.729602Z",
     "iopub.status.idle": "2025-07-08T09:33:11.767658Z",
     "shell.execute_reply": "2025-07-08T09:33:11.766973Z",
     "shell.execute_reply.started": "2025-07-08T09:33:11.729918Z"
    },
    "papermill": {
     "duration": 0.012666,
     "end_time": "2025-07-08T18:33:31.319070",
     "exception": false,
     "start_time": "2025-07-08T18:33:31.306404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse(\"/kaggle/input/make-data-count-finding-data-references/test/XML/10.1002_2017jc013030.xml\")\n",
    "root = tree.getroot()\n",
    "ns = {\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "\n",
    "tei_elem = root.find(\".//tei:tei\", namespaces=ns)\n",
    "print(\"tei_elem:\", tei_elem)\n",
    "\n",
    "if tei_elem is not None:\n",
    "    body = tei_elem.find(\".//tei:body\", namespaces=ns)\n",
    "    print(\"body:\", body)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d05134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T09:33:11.768841Z",
     "iopub.status.busy": "2025-07-08T09:33:11.768547Z",
     "iopub.status.idle": "2025-07-08T09:33:11.780676Z",
     "shell.execute_reply": "2025-07-08T09:33:11.779977Z",
     "shell.execute_reply.started": "2025-07-08T09:33:11.768813Z"
    },
    "papermill": {
     "duration": 0.011216,
     "end_time": "2025-07-08T18:33:31.342580",
     "exception": false,
     "start_time": "2025-07-08T18:33:31.331364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse(\"/kaggle/input/make-data-count-finding-data-references/test/XML/10.1002_2017jc013030.xml\")\n",
    "root = tree.getroot()\n",
    "ns = {\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "\n",
    "tei_elem = root.find(\".//tei:tei\", namespaces=ns)\n",
    "print(\"tei_elem:\", tei_elem)\n",
    "\n",
    "if tei_elem is not None:\n",
    "    for child in tei_elem:\n",
    "        print(\"child tag:\", child.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c57001",
   "metadata": {
    "papermill": {
     "duration": 0.00825,
     "end_time": "2025-07-08T18:33:31.359595",
     "exception": false,
     "start_time": "2025-07-08T18:33:31.351345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "text_elem = tei_elem.find(\".//tei:text\", namespaces=ns)\n",
    "print(\"text_elem:\", text_elem)\n",
    "if text_elem is not None:\n",
    "    for sub in text_elem:\n",
    "        print(\"sub tag:\", sub.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38557146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:33:31.377629Z",
     "iopub.status.busy": "2025-07-08T18:33:31.377386Z",
     "iopub.status.idle": "2025-07-08T18:33:31.382566Z",
     "shell.execute_reply": "2025-07-08T18:33:31.382041Z"
    },
    "papermill": {
     "duration": 0.015464,
     "end_time": "2025-07-08T18:33:31.383628",
     "exception": false,
     "start_time": "2025-07-08T18:33:31.368164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_grobid_xml(xml_path):\n",
    "    \"\"\"\n",
    "    Parses a GROBID TEI XML file or fallback HTML-ish XML,\n",
    "    extracting all text content in a single clean string.\n",
    "    \"\"\"\n",
    "    import xml.etree.ElementTree as ET\n",
    "\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"[!] Error parsing XML: {xml_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    ns = {\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "\n",
    "    tei_elem = root.find(\".//tei:tei\", namespaces=ns)\n",
    "    if tei_elem is not None:\n",
    "        source_elem = tei_elem\n",
    "    else:\n",
    "        print(f\"[ℹ️] No <tei> element in: {xml_path}, using fallback traversal.\")\n",
    "        source_elem = root\n",
    "\n",
    "    # Recursively extract all text nodes\n",
    "    all_text = \" \".join(source_elem.itertext())\n",
    "\n",
    "    # Collapse repeated whitespace\n",
    "    import re\n",
    "    all_text = re.sub(r\"\\s+\", \" \", all_text).strip()\n",
    "\n",
    "    if not all_text:\n",
    "        print(f\"[⚠️] Empty result from: {xml_path}\")\n",
    "\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e000d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T09:33:11.803943Z",
     "iopub.status.busy": "2025-07-08T09:33:11.803641Z",
     "iopub.status.idle": "2025-07-08T09:33:11.830100Z",
     "shell.execute_reply": "2025-07-08T09:33:11.829541Z",
     "shell.execute_reply.started": "2025-07-08T09:33:11.803927Z"
    },
    "papermill": {
     "duration": 0.008875,
     "end_time": "2025-07-08T18:33:31.447863",
     "exception": false,
     "start_time": "2025-07-08T18:33:31.438988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "text = parse_grobid_xml('/kaggle/input/make-data-count-finding-data-references/test/XML/10.1002_2017jc013030.xml')\n",
    "print(\"Extracted text length:\", len(text))\n",
    "print(text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27025522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:33:31.466387Z",
     "iopub.status.busy": "2025-07-08T18:33:31.466144Z",
     "iopub.status.idle": "2025-07-08T18:34:41.461792Z",
     "shell.execute_reply": "2025-07-08T18:34:41.460848Z"
    },
    "papermill": {
     "duration": 70.006941,
     "end_time": "2025-07-08T18:34:41.463399",
     "exception": false,
     "start_time": "2025-07-08T18:33:31.456458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "for pdf_path in pdf_files:\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    base = os.path.splitext(filename)[0]\n",
    "    article_id = extract_article_id(filename)\n",
    "\n",
    "    xml_path = os.path.join(xml_dir, f\"{base}.xml\")\n",
    "    if os.path.exists(xml_path):\n",
    "        print(\"Parsing XML:\", article_id)\n",
    "        text = parse_grobid_xml(xml_path)\n",
    "        print(\"text:\", text[:100])\n",
    "    else:\n",
    "        print(\"Parsing PDF:\", article_id)\n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    rows.append({\"article_id\": article_id, \"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f16c806c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:34:41.483758Z",
     "iopub.status.busy": "2025-07-08T18:34:41.483201Z",
     "iopub.status.idle": "2025-07-08T18:34:43.240349Z",
     "shell.execute_reply": "2025-07-08T18:34:43.239424Z"
    },
    "papermill": {
     "duration": 1.768241,
     "end_time": "2025-07-08T18:34:43.241489",
     "exception": false,
     "start_time": "2025-07-08T18:34:41.473248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# 🔮 Predict type\n",
    "label_map = {0: \"Primary\", 1: \"Secondary\", 2: \"Missing\"}\n",
    "batch_size = 8\n",
    "preds = []\n",
    "\n",
    "for i in tqdm(range(0, len(rows), batch_size)):\n",
    "    batch_texts = [r[\"text\"] for r in rows[i:i+batch_size]]\n",
    "    enc = tokenizer(batch_texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "        p = torch.argmax(logits, dim=1).cpu().tolist()\n",
    "        preds.extend(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08c02a9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:34:43.261425Z",
     "iopub.status.busy": "2025-07-08T18:34:43.260964Z",
     "iopub.status.idle": "2025-07-08T18:34:44.067649Z",
     "shell.execute_reply": "2025-07-08T18:34:44.067038Z"
    },
    "papermill": {
     "duration": 0.817857,
     "end_time": "2025-07-08T18:34:44.069015",
     "exception": false,
     "start_time": "2025-07-08T18:34:43.251158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 🏷️ Extract dataset IDs and build results\n",
    "results = []\n",
    "for i, r in enumerate(rows):\n",
    "    t = r[\"text\"]\n",
    "    dataset_ids = extract_dataset_ids(t)\n",
    "    if not dataset_ids:\n",
    "        dataset_ids = [\"Missing\"]  # or optionally: [\"Missing\"]\n",
    "    \n",
    "    for did in dataset_ids:\n",
    "        results.append({\n",
    "            \"article_id\": r[\"article_id\"],\n",
    "            \"dataset_id\": did,\n",
    "            \"type\": label_map[preds[i]]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "786c15cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:34:44.088760Z",
     "iopub.status.busy": "2025-07-08T18:34:44.088537Z",
     "iopub.status.idle": "2025-07-08T18:34:44.096022Z",
     "shell.execute_reply": "2025-07-08T18:34:44.095289Z"
    },
    "papermill": {
     "duration": 0.018531,
     "end_time": "2025-07-08T18:34:44.097284",
     "exception": false,
     "start_time": "2025-07-08T18:34:44.078753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 📝 Build submission DataFrame\n",
    "df_preds = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "376afa91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:34:44.116870Z",
     "iopub.status.busy": "2025-07-08T18:34:44.116588Z",
     "iopub.status.idle": "2025-07-08T18:34:44.119795Z",
     "shell.execute_reply": "2025-07-08T18:34:44.119294Z"
    },
    "papermill": {
     "duration": 0.014006,
     "end_time": "2025-07-08T18:34:44.120774",
     "exception": false,
     "start_time": "2025-07-08T18:34:44.106768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not SUBMIT:\n",
    "    df_preds.to_csv(\"raw_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12a6d647",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:34:44.140309Z",
     "iopub.status.busy": "2025-07-08T18:34:44.140076Z",
     "iopub.status.idle": "2025-07-08T18:34:44.170413Z",
     "shell.execute_reply": "2025-07-08T18:34:44.169907Z"
    },
    "papermill": {
     "duration": 0.041349,
     "end_time": "2025-07-08T18:34:44.171517",
     "exception": false,
     "start_time": "2025-07-08T18:34:44.130168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_types = {\"Primary\", \"Secondary\"}\n",
    "df = df_preds[df_preds['type'] != 'Missing'].reset_index(drop=True)\n",
    "df = df[df['type'].isin(valid_types)].reset_index(drop=True)\n",
    "\n",
    "df = df[df['dataset_id'] != 'Missing'].reset_index(drop=True)\n",
    "df = df[df['dataset_id'].notnull()].reset_index(drop=True)\n",
    "df = df[df['dataset_id'].str.strip() != \"\"].reset_index(drop=True)\n",
    "\n",
    "df = df.drop_duplicates(subset=['article_id', 'dataset_id'])\n",
    "\n",
    "df['dataset_id'] = df['dataset_id'].apply( lambda x: x.lower() if isinstance(x, str) and x.startswith('http') else x)\n",
    "df.insert(0, \"row_id\", range(len(df)))\n",
    "assert df['dataset_id'].notnull().all()\n",
    "assert df['dataset_id'].str.strip().ne(\"\").all()\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32e8bd4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T18:34:44.190863Z",
     "iopub.status.busy": "2025-07-08T18:34:44.190620Z",
     "iopub.status.idle": "2025-07-08T18:34:44.200855Z",
     "shell.execute_reply": "2025-07-08T18:34:44.200285Z"
    },
    "papermill": {
     "duration": 0.021063,
     "end_time": "2025-07-08T18:34:44.201948",
     "exception": false,
     "start_time": "2025-07-08T18:34:44.180885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DO_SAVE = False\n",
    "import pandas as pd\n",
    "if not SUBMIT:\n",
    "    if DO_SAVE:\n",
    "        df_true = pd.read_csv(\"/kaggle/input/make-data-count-finding-data-references/train_labels.csv\")\n",
    "        # Merge on article_id\n",
    "        df_merged = df_true.merge(df_preds, on=\"article_id\", suffixes=(\"_true\", \"_pred\"))\n",
    "        print(f\"Merged {len(df_merged)} records.\")\n",
    "        df_merged.head()\n",
    "        df_merged.to_csv(\"merged.csv\", index=False)\n",
    "    else:\n",
    "        df_merged=pd.read_csv(\"/kaggle/input/mdc-submit-merged-ds/merged.csv\")\n",
    "    # df_merged['dataset_id_pred'] = df_merged['dataset_id_pred'].apply( lambda x: x.lower() if isinstance(x, str) and x.startswith('http') else x)\n",
    "    from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "    \n",
    "    # Encode type as numeric labels\n",
    "    type_label_map = {\"Primary\":0, \"Secondary\":1, \"Missing\":2}\n",
    "    y_true_type = df_merged[\"type_true\"].map(type_label_map)\n",
    "    y_pred_type = df_merged[\"type_pred\"].map(type_label_map)\n",
    "    \n",
    "    def compute_type_metrics(y_true, y_pred):\n",
    "        f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "        f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "        def safe_f1(class_label):\n",
    "            return report[str(class_label)][\"f1-score\"] if str(class_label) in report else 0.0\n",
    "    \n",
    "        return {\n",
    "            \"f1_micro\": f1_micro,\n",
    "            \"f1_macro\": f1_macro,\n",
    "            \"f1_primary\": safe_f1(0),\n",
    "            \"f1_secondary\": safe_f1(1),\n",
    "            \"f1_missing\": safe_f1(2)\n",
    "        }\n",
    "    \n",
    "    type_metrics = compute_type_metrics(y_true_type, y_pred_type)\n",
    "    print(\"✅ Type classification metrics\")\n",
    "    print(type_metrics)\n",
    "    \n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    cm = confusion_matrix(y_true_type, y_pred_type)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=type_label_map.keys(),\n",
    "                yticklabels=type_label_map.keys())\n",
    "    plt.xlabel(\"Predicted Type\")\n",
    "    plt.ylabel(\"True Type\")\n",
    "    plt.title(\"Confusion Matrix - Type\")\n",
    "    plt.show()\n",
    "    \n",
    "    df_merged = df_merged[df_merged['type_pred'] != 'Missing'].reset_index(drop=True)\n",
    "\n",
    "    accuracy_ds = (df_merged[\"dataset_id_true\"] == df_merged[\"dataset_id_pred\"]).mean()\n",
    "    print(f\"✅ Dataset ID Exact Match Accuracy: {accuracy_ds:.4f}\")\n",
    "    \n",
    "    top_n = 100\n",
    "    counts = df_merged[\"dataset_id_true\"].value_counts().nlargest(top_n)\n",
    "    top_ids = counts.index.tolist()\n",
    "    \n",
    "    mask = df_merged[\"dataset_id_true\"].isin(top_ids)\n",
    "    cm_ds = confusion_matrix(\n",
    "        df_merged.loc[mask, \"dataset_id_true\"],\n",
    "        df_merged.loc[mask, \"dataset_id_pred\"],\n",
    "        labels=top_ids\n",
    "    )\n",
    "    \n",
    "    sns.heatmap(cm_ds, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "                xticklabels=top_ids,\n",
    "                yticklabels=top_ids)\n",
    "    plt.xlabel(\"Predicted dataset_id\")\n",
    "    plt.ylabel(\"True dataset_id\")\n",
    "    plt.title(\"Dataset ID Confusion Matrix (Top 10)\")\n",
    "    plt.show()\n",
    "    print(cm_ds.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df61546",
   "metadata": {
    "papermill": {
     "duration": 0.008918,
     "end_time": "2025-07-08T18:34:44.220200",
     "exception": false,
     "start_time": "2025-07-08T18:34:44.211282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12656064,
     "isSourceIdPinned": false,
     "sourceId": 82370,
     "sourceType": "competition"
    },
    {
     "datasetId": 7775152,
     "sourceId": 12334120,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7778248,
     "sourceId": 12338599,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7779053,
     "sourceId": 12339780,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7811604,
     "sourceId": 12388229,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 248033444,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 248091965,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 311.589079,
   "end_time": "2025-07-08T18:34:47.649691",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-08T18:29:36.060612",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
