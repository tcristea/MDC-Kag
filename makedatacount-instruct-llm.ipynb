{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a567af4",
   "metadata": {
    "papermill": {
     "duration": 0.015644,
     "end_time": "2025-07-15T11:39:59.131985",
     "exception": false,
     "start_time": "2025-07-15T11:39:59.116341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Enhancements based on the baseline: Dataset Mention Extraction 📄🔍**\n",
    "\n",
    "**Inspiration for using Regex & Context Chunking:**\n",
    "\n",
    "Inspired by the need to extract dataset accessions and DOIs with high precision, I combined regex with smart context slicing and domain-specific heuristics.\n",
    "\n",
    "**What I changed:**\n",
    "\n",
    "1. **Regex-Based Identifier Extraction**\n",
    "\n",
    "   * Added robust patterns to detect **DOIs**, **GSE/SRA**, **CHEMBL**, **UniProt**, and other dataset-related IDs.\n",
    "\n",
    "2. **Heuristic Keyword Filtering**\n",
    "\n",
    "   * Matched surrounding text against known **dataset-related phrases** (e.g., “data available at”, “repository”) to filter meaningful mentions.\n",
    "\n",
    "3. **Smart Contextual Chunking**\n",
    "\n",
    "   * Implemented a `TextChunker` that aligns context by sentence boundaries, ensuring that extracted snippets are informative and self-contained.\n",
    "\n",
    "4. **Dataset DOI Classification**\n",
    "\n",
    "   * Checked matched DOIs against a curated list of known **dataset DOI prefixes** to validate dataset relevance.\n",
    "\n",
    "5. **Parallel PDF Processing**\n",
    "\n",
    "   * Boosted performance with **ThreadPoolExecutor**, allowing multiple PDFs to be parsed concurrently.\n",
    "\n",
    "6. **Model Testing: Non-Reasoning vs Reasoning**\n",
    "\n",
    "   * This notebook includes evaluation with **Qwen 2.5** for non-reasoning classification and **Qwen 3** for reasoning-intensive classification — allowing comparison and ablation between the two modes.\n",
    "\n",
    "7. **Detailed False Negative (FN) Analysis**\n",
    "\n",
    "   * Added in-depth analysis to categorize and quantify **False Negatives** (FN), separated into:\n",
    "\n",
    "     * **Wrongly classified**: Model predicted something, but not exactly correct.\n",
    "     * **Completely missed**: No prediction was made for a ground-truth item.\n",
    "   * Each group is further broken down into:\n",
    "\n",
    "     * **DOI**-based errors (e.g., wrong prefix or mismatched)\n",
    "     * **Accession ID** errors (e.g., GSE, PRJNA, etc.)\n",
    "   * This helps reveal weaknesses such as:\n",
    "\n",
    "     * Ambiguous contexts\n",
    "     * Incomplete extraction logic\n",
    "     * Confusions between similar dataset identifiers\n",
    "\n",
    "**Next Goal:**\n",
    "\n",
    "1. **Improve Chunk and Reduce Junk Chunk**\n",
    "2. **What to Improve Regex**\n",
    "3. **Added Prompt Caching**\n",
    "4. **Reduce Runtime for run**\n",
    "5. **More F1-Score Reduce FN**\n",
    "\n",
    "**I hope this notebook to goal gold medal notebook**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452321c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:39:59.161613Z",
     "iopub.status.busy": "2025-07-15T11:39:59.161049Z",
     "iopub.status.idle": "2025-07-15T11:43:55.505286Z",
     "shell.execute_reply": "2025-07-15T11:43:55.504283Z"
    },
    "papermill": {
     "duration": 236.361102,
     "end_time": "2025-07-15T11:43:55.507132",
     "exception": false,
     "start_time": "2025-07-15T11:39:59.146030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/mdcfitz/pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl\r\n",
      "Installing collected packages: pymupdf\r\n",
      "Successfully installed pymupdf-1.26.3\r\n",
      "Looking in links: file:///kaggle/input/mdcllm\r\n",
      "Processing /kaggle/input/mdcllm/vllm-0.9.2-cp38-abi3-manylinux1_x86_64.whl\r\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from vllm) (2024.11.6)\r\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (7.0.0)\r\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.4)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\r\n",
      "Processing /kaggle/input/mdcllm/blake3-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\r\n",
      "Requirement already satisfied: transformers>=4.51.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.52.4)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.33.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.33.0->vllm) (0.33.1)\r\n",
      "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.2)\r\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (3.20.3)\r\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.13)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.12.13)\r\n",
      "Processing /kaggle/input/mdcllm/openai-1.90.0-py3-none-any.whl (from vllm)\r\n",
      "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.7)\r\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.22.1)\r\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.2.1)\r\n",
      "Processing /kaggle/input/mdcllm/prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (from vllm)\r\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.0)\r\n",
      "Processing /kaggle/input/mdcllm/lm_format_enforcer-0.10.11-py3-none-any.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/outlines-0.1.11-py3-none-any.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/lark-1.2.2-py3-none-any.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/xgrammar-0.1.19-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\r\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.14.0)\r\n",
      "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.18.0)\r\n",
      "Processing /kaggle/input/mdcllm/partial_json_parser-0.2.1.1.post6-py3-none-any.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/pyzmq-27.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/gguf-0.17.1-py3-none-any.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/mistral_common-1.6.3-py3-none-any.whl (from mistral_common[opencv]>=1.6.2->vllm)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\r\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\r\n",
      "Processing /kaggle/input/mdcllm/compressed_tensors-0.10.2-py3-none-any.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/depyf-0.18.0-py3-none-any.whl (from vllm)\r\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\r\n",
      "Processing /kaggle/input/mdcllm/watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\r\n",
      "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from vllm) (3.3.0)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.15.3)\r\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from vllm) (1.11.1.4)\r\n",
      "Processing /kaggle/input/mdcllm/pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from vllm)\r\n",
      "Requirement already satisfied: ray!=2.44.*,>=2.43.0 in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (2.47.1)\r\n",
      "Processing /kaggle/input/mdcllm/torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl (from vllm)\r\n",
      "Processing /kaggle/input/mdcllm/astor-0.8.1-py2.py3-none-any.whl (from depyf==0.18.0->vllm)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->vllm) (0.3.8)\r\n",
      "Processing /kaggle/input/mdcllm/llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from numba==0.61.2->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/interegular-0.3.3-py37-none-any.whl (from outlines==0.1.11->vllm)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (3.1.6)\r\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (1.6.0)\r\n",
      "Processing /kaggle/input/mdcllm/diskcache-5.6.3-py3-none-any.whl (from outlines==0.1.11->vllm)\r\n",
      "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.36.2)\r\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (4.24.0)\r\n",
      "Processing /kaggle/input/mdcllm/pycountry-24.6.1-py3-none-any.whl (from outlines==0.1.11->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/airportsdata-20250706-py3-none-any.whl (from outlines==0.1.11->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from outlines==0.1.11->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/sympy-1.14.0-py3-none-any.whl (from torch==2.7.0->vllm)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm) (3.5)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->vllm) (2025.5.1)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (from torch==2.7.0->vllm)\r\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0->vllm) (75.2.0)\r\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.2)\r\n",
      "Processing /kaggle/input/mdcllm/fastapi_cli-0.0.8-py3-none-any.whl (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\r\n",
      "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\r\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\r\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\r\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.3)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm) (25.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm) (1.1.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2.4.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.52.0->vllm) (4.9.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.52.0->vllm) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.52.0->vllm) (0.10.0)\r\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.52.0->vllm) (1.3.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.4.1)\r\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.2.1)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.1)\r\n",
      "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.6.15)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.1->vllm) (0.5.3)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.1)\r\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\r\n",
      "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.16.0)\r\n",
      "Processing /kaggle/input/mdcllm/rich_toolkit-0.14.8-py3-none-any.whl (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/fastapi_cloud_cli-0.1.1-py3-none-any.whl (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2025.4.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.25.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0->vllm) (1.3.0)\r\n",
      "Processing /kaggle/input/mdcllm/httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/python_dotenv-1.1.1-py3-none-any.whl (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\r\n",
      "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vllm) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vllm) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->vllm) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->vllm) (2024.2.0)\r\n",
      "Processing /kaggle/input/mdcllm/rignore-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\r\n",
      "Processing /kaggle/input/mdcllm/httpx-0.27.2-py3-none-any.whl (from fastapi[standard]>=0.115.0->vllm)\r\n",
      "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.31.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->vllm) (2024.2.0)\r\n",
      "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.0.0)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\r\n",
      "Installing collected packages: nvidia-cusparselt-cu12, blake3, uvloop, triton, sympy, rignore, pyzmq, python-dotenv, pycountry, pybase64, partial-json-parser, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, llvmlite, llguidance, lark, interegular, httptools, diskcache, astor, airportsdata, watchfiles, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, httpx, depyf, rich-toolkit, prometheus-fastapi-instrumentator, openai, nvidia-cusolver-cu12, lm-format-enforcer, torch, outlines_core, fastapi-cloud-cli, fastapi-cli, torchaudio, mistral_common, xgrammar, xformers, torchvision, outlines, numba, gguf, compressed-tensors, vllm\r\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\r\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\r\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\r\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.2.0\r\n",
      "    Uninstalling triton-3.2.0:\r\n",
      "      Successfully uninstalled triton-3.2.0\r\n",
      "  Attempting uninstall: sympy\r\n",
      "    Found existing installation: sympy 1.13.1\r\n",
      "    Uninstalling sympy-1.13.1:\r\n",
      "      Successfully uninstalled sympy-1.13.1\r\n",
      "  Attempting uninstall: pyzmq\r\n",
      "    Found existing installation: pyzmq 24.0.1\r\n",
      "    Uninstalling pyzmq-24.0.1:\r\n",
      "      Successfully uninstalled pyzmq-24.0.1\r\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\r\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-nccl-cu12\r\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\r\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\r\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: llvmlite\r\n",
      "    Found existing installation: llvmlite 0.43.0\r\n",
      "    Uninstalling llvmlite-0.43.0:\r\n",
      "      Successfully uninstalled llvmlite-0.43.0\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: httpx\r\n",
      "    Found existing installation: httpx 0.28.1\r\n",
      "    Uninstalling httpx-0.28.1:\r\n",
      "      Successfully uninstalled httpx-0.28.1\r\n",
      "  Attempting uninstall: openai\r\n",
      "    Found existing installation: openai 1.91.0\r\n",
      "    Uninstalling openai-1.91.0:\r\n",
      "      Successfully uninstalled openai-1.91.0\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.6.0+cu124\r\n",
      "    Uninstalling torch-2.6.0+cu124:\r\n",
      "      Successfully uninstalled torch-2.6.0+cu124\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.6.0+cu124\r\n",
      "    Uninstalling torchaudio-2.6.0+cu124:\r\n",
      "      Successfully uninstalled torchaudio-2.6.0+cu124\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.21.0+cu124\r\n",
      "    Uninstalling torchvision-0.21.0+cu124:\r\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "  Attempting uninstall: numba\r\n",
      "    Found existing installation: numba 0.60.0\r\n",
      "    Uninstalling numba-0.60.0:\r\n",
      "      Successfully uninstalled numba-0.60.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\r\n",
      "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\r\n",
      "cudf-cu12 25.2.2 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\r\n",
      "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\r\n",
      "ydata-profiling 4.16.1 requires numba<=0.61,>=0.56.0, but you have numba 0.61.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\r\n",
      "google-genai 1.21.1 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\r\n",
      "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\r\n",
      "langchain-core 0.3.66 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\r\n",
      "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\r\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed airportsdata-20250706 astor-0.8.1 blake3-1.0.5 compressed-tensors-0.10.2 depyf-0.18.0 diskcache-5.6.3 fastapi-cli-0.0.8 fastapi-cloud-cli-0.1.1 gguf-0.17.1 httptools-0.6.4 httpx-0.27.2 interegular-0.3.3 lark-1.2.2 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.10.11 mistral_common-1.6.3 msgspec-0.19.0 numba-0.61.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 openai-1.90.0 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 pybase64-1.4.1 pycountry-24.6.1 python-dotenv-1.1.1 pyzmq-27.0.0 rich-toolkit-0.14.8 rignore-0.5.1 sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 triton-3.3.0 uvloop-0.21.0 vllm-0.9.2 watchfiles-1.1.0 xformers-0.0.30 xgrammar-0.1.19\r\n",
      "Looking in links: file:///kaggle/input/mdcllm\r\n",
      "Processing /kaggle/input/mdcllm/logits_processor_zoo-0.1.10-py3-none-any.whl\r\n",
      "Requirement already satisfied: accelerate>=0.26.1 in /usr/local/lib/python3.11/dist-packages (from logits-processor-zoo==0.1.10) (1.8.1)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from logits-processor-zoo==0.1.10) (2.7.0)\r\n",
      "Requirement already satisfied: transformers>=4.41.2 in /usr/local/lib/python3.11/dist-packages (from logits-processor-zoo==0.1.10) (4.52.4)\r\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.1->logits-processor-zoo==0.1.10) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.1->logits-processor-zoo==0.1.10) (25.0)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.1->logits-processor-zoo==0.1.10) (7.0.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.1->logits-processor-zoo==0.1.10) (6.0.2)\r\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.1->logits-processor-zoo==0.1.10) (0.33.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.1->logits-processor-zoo==0.1.10) (0.5.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (4.14.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (2025.5.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (9.5.1.17)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (0.6.3)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (2.26.2)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch->logits-processor-zoo==0.1.10) (3.3.0)\r\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch->logits-processor-zoo==0.1.10) (75.2.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.2->logits-processor-zoo==0.1.10) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.2->logits-processor-zoo==0.1.10) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.2->logits-processor-zoo==0.1.10) (0.21.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.2->logits-processor-zoo==0.1.10) (4.67.1)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.1->logits-processor-zoo==0.1.10) (1.1.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.26.1->logits-processor-zoo==0.1.10) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.26.1->logits-processor-zoo==0.1.10) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.26.1->logits-processor-zoo==0.1.10) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.26.1->logits-processor-zoo==0.1.10) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.26.1->logits-processor-zoo==0.1.10) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.26.1->logits-processor-zoo==0.1.10) (2.4.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch->logits-processor-zoo==0.1.10) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->logits-processor-zoo==0.1.10) (3.0.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.41.2->logits-processor-zoo==0.1.10) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.41.2->logits-processor-zoo==0.1.10) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.41.2->logits-processor-zoo==0.1.10) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.41.2->logits-processor-zoo==0.1.10) (2025.6.15)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.26.1->logits-processor-zoo==0.1.10) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.26.1->logits-processor-zoo==0.1.10) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate>=0.26.1->logits-processor-zoo==0.1.10) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate>=0.26.1->logits-processor-zoo==0.1.10) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate>=0.26.1->logits-processor-zoo==0.1.10) (2024.2.0)\r\n",
      "Installing collected packages: logits-processor-zoo\r\n",
      "Successfully installed logits-processor-zoo-0.1.10\r\n",
      "Looking in links: file:///kaggle/input/mdcllm\r\n",
      "Processing /kaggle/input/mdcllm/triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: triton\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.3.0\r\n",
      "    Uninstalling triton-3.3.0:\r\n",
      "      Successfully uninstalled triton-3.3.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "torch 2.7.0 requires triton==3.3.0; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have triton 3.2.0 which is incompatible.\r\n",
      "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed triton-3.2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/mdcfitz/pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl\n",
    "!pip install vllm --no-index --find-links file:///kaggle/input/mdcllm\n",
    "!pip install logits-processor-zoo==0.1.10 --no-index --find-links file:///kaggle/input/mdcllm\n",
    "!pip install triton==3.2.0 --no-index --find-links file:///kaggle/input/mdcllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae0dc1ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:43:55.546707Z",
     "iopub.status.busy": "2025-07-15T11:43:55.546223Z",
     "iopub.status.idle": "2025-07-15T11:44:05.367331Z",
     "shell.execute_reply": "2025-07-15T11:44:05.366586Z"
    },
    "papermill": {
     "duration": 9.84187,
     "end_time": "2025-07-15T11:44:05.368760",
     "exception": false,
     "start_time": "2025-07-15T11:43:55.526890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "\n",
    "import re\n",
    "import pymupdf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n",
    "import pickle\n",
    "import vllm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf8ae7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:44:05.410748Z",
     "iopub.status.busy": "2025-07-15T11:44:05.409939Z",
     "iopub.status.idle": "2025-07-15T11:44:05.413578Z",
     "shell.execute_reply": "2025-07-15T11:44:05.412884Z"
    },
    "papermill": {
     "duration": 0.025242,
     "end_time": "2025-07-15T11:44:05.414587",
     "exception": false,
     "start_time": "2025-07-15T11:44:05.389345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"KAGGLE_IS_COMPETITION_RERUN\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12449899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:44:05.454934Z",
     "iopub.status.busy": "2025-07-15T11:44:05.454725Z",
     "iopub.status.idle": "2025-07-15T11:44:10.376738Z",
     "shell.execute_reply": "2025-07-15T11:44:10.375973Z"
    },
    "papermill": {
     "duration": 4.943715,
     "end_time": "2025-07-15T11:44:10.377938",
     "exception": false,
     "start_time": "2025-07-15T11:44:05.434223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb58957882194fc2a5571d59d235beb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI chunks: 293\n",
      "Other ID chunks: 1\n"
     ]
    }
   ],
   "source": [
    "# vLLM V1 does not accept logits processor, so disable it\n",
    "# https://docs.vllm.ai/en/latest/getting_started/v1_user_guide.html#deprecated-features\n",
    "pdf_directory = \"/kaggle/input/make-data-count-finding-data-references/test/PDF\" \\\n",
    "                if os.getenv('KAGGLE_IS_COMPETITION_RERUN') \\\n",
    "                else \"/kaggle/input/make-data-count-finding-data-references/train/PDF\"\n",
    "chunks = []\n",
    "chunks2 = []\n",
    "text_span_len = 300\n",
    "\n",
    "re_doi = re.compile(r\"10\\.\\d{4,9}/[-._;()/:A-Z0-9]+\", re.IGNORECASE)\n",
    "re_gsr = re.compile(r\"GSE\\d+|SR[APRX]\\d+|PRJ[NAED][A-Z]?\\d+|E-[A-Z]+-\\d+\", re.IGNORECASE)\n",
    "re_ipe = re.compile(r\"IPR\\d{6}|PF\\d{5}|EMPIAR-\\d{5}|EMD-\\d{4,5}\", re.IGNORECASE)\n",
    "re_c = re.compile(r\"CHEMBL\\d+|CVCL_[A-Z0-9]{4}|CID:\\d+\", re.IGNORECASE)\n",
    "re_e = re.compile(r\"ENS[A-Z]{0,6}[GT]\\d{11}|ENSG\\d{11}\", re.IGNORECASE)\n",
    "re_r = re.compile(r\"N[MC]_\\d+(?:\\.\\d+)?|rs\\d+|XM_\\d+|XP_\\d+\", re.IGNORECASE)\n",
    "re_u = re.compile(r\"(?:uniprot:)?(?:[OPQ][0-9][A-Z0-9]{3}[0-9]|[A-NR-Z][0-9][A-Z][A-Z0-9]{2}[0-9])\", re.IGNORECASE)\n",
    "re_g = re.compile(r\"EPI(?:_ISL_)?\\d+|GISAID\", re.IGNORECASE)\n",
    "re_p = re.compile(r\"PXD\\d{6}|SAM[ND]\\d+|ERR\\d+|DRR\\d+|MSV\\d+\", re.IGNORECASE)\n",
    "re_pdb = re.compile(r\"\\b[0-9][A-Z0-9]{3}\\b\", re.IGNORECASE)\n",
    "re_geo = re.compile(r\"GDS\\d+|GPL\\d+|GSM\\d+\", re.IGNORECASE)\n",
    "re_arrayexpress = re.compile(r\"E-[A-Z]+-\\d+\", re.IGNORECASE)\n",
    "\n",
    "relist = [re_gsr, re_ipe, re_c, re_e, re_r, re_g, re_p, re_geo, re_arrayexpress]\n",
    "ids = []\n",
    "\n",
    "def remove_references_section(text):\n",
    "    lines = text.split('\\n')\n",
    "    cut_index = -1\n",
    "    \n",
    "    # Look backwards from end of document\n",
    "    for i in range(len(lines) - 1, max(0, int(len(lines) * 0.2)), -1):\n",
    "        line = lines[i].strip()\n",
    "        obvious_patterns = [\n",
    "            r'^REFERENCES?$',\n",
    "            r'^\\d+\\.?\\s+REFERENCES?$',\n",
    "            r'^\\d+\\.?\\s+References?$',\n",
    "            r'^References?:?$',\n",
    "            r'^BIBLIOGRAPHY$',\n",
    "            r'^\\d+\\.?\\s+BIBLIOGRAPHY$',\n",
    "            r'^\\d+\\.?\\s+Bibliography$',\n",
    "            r'^Bibliography:?$',\n",
    "            r'^Literature\\s+Cited$',\n",
    "            r'^Works\\s+Cited$',\n",
    "            r'^ACKNOWLEDGMENTS?$',\n",
    "            r'^Acknowledgments?$',\n",
    "            r'^FUNDING$',\n",
    "            r'^CONFLICTS?\\s+OF\\s+INTEREST$'\n",
    "        ]\n",
    "        if any(re.match(pattern, line, re.IGNORECASE) for pattern in obvious_patterns):\n",
    "            # Double-check: look at following lines for citation patterns\n",
    "            following_lines = lines[i+1:i+5]\n",
    "            has_citations = False\n",
    "            for follow_line in following_lines:\n",
    "                if follow_line.strip():\n",
    "                    # Check for obvious citation patterns\n",
    "                    if (re.search(r'\\(\\d{4}\\)', follow_line) or\n",
    "                        re.search(r'\\d{4}\\.', follow_line) or\n",
    "                        'doi:' in follow_line.lower() or\n",
    "                        ' et al' in follow_line.lower() or\n",
    "                        re.search(r'^\\[\\d+\\]', follow_line.strip()) or\n",
    "                        re.search(r'^\\d+\\.', follow_line.strip())):\n",
    "                        has_citations = True\n",
    "                        break\n",
    "            # Only cut if we found citation-like content\n",
    "            if has_citations or i >= len(lines) - 5:  # Or very near end\n",
    "                cut_index = i\n",
    "                break\n",
    "    if cut_index != -1:\n",
    "        return '\\n'.join(lines[:cut_index]).strip()\n",
    "    return text.strip()\n",
    "\n",
    "def extract_context_with_keywords(text, match_start, match_end, span_len=300):\n",
    "    keyword_scores = {\n",
    "        \"data are available\": 5, \"datasets are available\": 5, \"deposited in\": 5, \n",
    "        \"submitted to\": 5, \"accession number\": 5, \"accession code\": 5, \n",
    "        \"accession id\": 5, \"archived in\": 4, \"uploaded to\": 4, \"source code\": 4, \n",
    "        \"raw data\": 4, \"sequencing data\": 4, \"retrieved from\": 3, \"downloaded from\": 3, \n",
    "        \"obtained from\": 3, \"supplementary data\": 3, \"supporting information\": 3, \n",
    "        'deposited': 3, 'submitted': 3, 'accession': 3, \"available in the\": 2, \n",
    "        \"publicly available\": 2, \"freely available\": 2, \"supplementary material\": 2, \n",
    "        'dataset': 2, 'datasets': 2, 'database': 2, 'repository': 2, 'code': 2, \n",
    "        'scripts': 2, 'available': 1, 'download': 1, 'supplementary': 1, \n",
    "        'supporting': 1, 'software': 1, 'protocol': 1, 'data': 0.5\n",
    "    }\n",
    "    \n",
    "    contexts = {\n",
    "        'standard': text[max(0, match_start - span_len):min(len(text), match_end + span_len)],\n",
    "        'extended': text[max(0, match_start - span_len * 2):min(len(text), match_end + span_len * 2)]\n",
    "    }\n",
    "    \n",
    "    def score_context(context):\n",
    "        return sum(\n",
    "            context.lower().count(k) * v if ' ' in k \n",
    "            else len(re.findall(r'\\b' + re.escape(k) + r'\\b', context.lower())) * v\n",
    "            for k, v in keyword_scores.items()\n",
    "        )\n",
    "    \n",
    "    scores = {k: score_context(v) for k, v in contexts.items()}\n",
    "    return contexts['extended'] if scores['extended'] > scores['standard'] and scores['extended'] > 4 else contexts['standard']\n",
    "\n",
    "rows = []\n",
    "for filename in tqdm(os.listdir(pdf_directory), total=len(os.listdir(pdf_directory))):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_directory, filename)\n",
    "        article_id = filename.split(\".pdf\")[0]\n",
    "        try:\n",
    "            with pymupdf.open(pdf_path) as doc:\n",
    "                text = \"\\n\".join(page.get_text() for page in doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not process {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        text = remove_references_section(text)\n",
    "        rows.append({\"article_id\": article_id, \"text\": text})\n",
    "        doi_matches = list(re_doi.finditer(text))\n",
    "        for match in doi_matches:\n",
    "            # Exclude the article's own DOI if it's mentioned\n",
    "            if match.group() in article_id:\n",
    "                continue\n",
    "            chunk = extract_context_with_keywords(text, match.start(), match.end(), text_span_len)\n",
    "            chunks.append((article_id, chunk))\n",
    "            \n",
    "        for rr in relist:\n",
    "            matches = list(rr.finditer(text))\n",
    "            for match in matches:\n",
    "                ids.append(match.group())\n",
    "                chunk = extract_context_with_keywords(text, match.start(), match.end(), text_span_len)\n",
    "                chunks2.append((article_id, chunk))\n",
    "\n",
    "print(f\"DOI chunks: {len(chunks)}\")\n",
    "print(f\"Other ID chunks: {len(chunks2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d583f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:44:10.468191Z",
     "iopub.status.busy": "2025-07-15T11:44:10.467751Z",
     "iopub.status.idle": "2025-07-15T11:44:35.514348Z",
     "shell.execute_reply": "2025-07-15T11:44:35.513699Z"
    },
    "papermill": {
     "duration": 25.115216,
     "end_time": "2025-07-15T11:44:35.515461",
     "exception": false,
     "start_time": "2025-07-15T11:44:10.400245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:44:17.438784: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752579857.778448      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752579857.877401      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 🧠 Load model and tokenizer\n",
    "model_path = \"/kaggle/input/makedatacount-mixed-train/saved_model_dual_text\"\n",
    "token_path = model_path\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(token_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6fd8fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:44:35.555545Z",
     "iopub.status.busy": "2025-07-15T11:44:35.554995Z",
     "iopub.status.idle": "2025-07-15T11:44:37.018673Z",
     "shell.execute_reply": "2025-07-15T11:44:37.017964Z"
    },
    "papermill": {
     "duration": 1.484689,
     "end_time": "2025-07-15T11:44:37.019956",
     "exception": false,
     "start_time": "2025-07-15T11:44:35.535267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4841a502a30472b95a7daec14827fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🔮 Predict type\n",
    "label_map = {0: \"Primary\", 1: \"Secondary\", 2: \"Missing\"}\n",
    "batch_size = 8\n",
    "preds = []\n",
    "\n",
    "for i in tqdm(range(0, len(rows), batch_size)):\n",
    "    batch_texts = [r[\"text\"] for r in rows[i:i+batch_size]]\n",
    "    enc = tokenizer(batch_texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "        p = torch.argmax(logits, dim=1).cpu().tolist()\n",
    "        preds.extend(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd28289f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:44:37.059929Z",
     "iopub.status.busy": "2025-07-15T11:44:37.059457Z",
     "iopub.status.idle": "2025-07-15T11:44:37.064324Z",
     "shell.execute_reply": "2025-07-15T11:44:37.063838Z"
    },
    "papermill": {
     "duration": 0.025539,
     "end_time": "2025-07-15T11:44:37.065359",
     "exception": false,
     "start_time": "2025-07-15T11:44:37.039820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_dataset_ids(text):\n",
    "    \"\"\"\n",
    "    Extract DOIs and known accession IDs robustly.\n",
    "    Returns a sorted list of unique dataset IDs.\n",
    "    \"\"\"\n",
    "    #repos = ['dryad','zenodo','figshare','pangaea','tcia','p9','d9','pasta','cranfield','dtu','usn','f7','jb','xyb','dl']\n",
    "    repos = ['dryad', 'zenodo', 'figshare', 'pangaea', 'tcia']\n",
    "    candidates = set()\n",
    "\n",
    "    # DOI pattern (strict)\n",
    "    doi_pattern = r'10\\.\\d{4,9}/[^\\s\\)\\]<]+'\n",
    "    for match in re.findall(doi_pattern, text):\n",
    "        clean = match.rstrip('.,;)]>').strip()\n",
    "        # Keep only known repositories\n",
    "        if any(repo in clean.lower() for repo in repos):\n",
    "            candidates.add(f\"https://doi.org/{clean}\")\n",
    "\n",
    "    for pat in relist:\n",
    "        candidates.update(re.findall(pat, text))\n",
    "\n",
    "    # Filter: drop very short garbage\n",
    "    candidates = [c for c in candidates if len(c) >= 5]\n",
    "\n",
    "    return None # sorted(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b8e44fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:44:37.104644Z",
     "iopub.status.busy": "2025-07-15T11:44:37.104409Z",
     "iopub.status.idle": "2025-07-15T11:44:37.556217Z",
     "shell.execute_reply": "2025-07-15T11:44:37.555663Z"
    },
    "papermill": {
     "duration": 0.472652,
     "end_time": "2025-07-15T11:44:37.557421",
     "exception": false,
     "start_time": "2025-07-15T11:44:37.084769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 🏷️ Extract dataset IDs and build results\n",
    "results = []\n",
    "for i, r in enumerate(rows):\n",
    "    t = r[\"text\"]\n",
    "    dataset_ids = extract_dataset_ids(t)\n",
    "    if not dataset_ids:\n",
    "        dataset_ids = [\"Missing\"]  # or optionally: [\"Missing\"]\n",
    "    \n",
    "    for did in dataset_ids:\n",
    "        results.append({\n",
    "            \"article_id\": r[\"article_id\"],\n",
    "            \"dataset_id\": did,\n",
    "            \"type\": label_map[preds[i]]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8960e9de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:44:37.596573Z",
     "iopub.status.busy": "2025-07-15T11:44:37.596355Z",
     "iopub.status.idle": "2025-07-15T11:44:37.604594Z",
     "shell.execute_reply": "2025-07-15T11:44:37.603908Z"
    },
    "papermill": {
     "duration": 0.028787,
     "end_time": "2025-07-15T11:44:37.605642",
     "exception": false,
     "start_time": "2025-07-15T11:44:37.576855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82bc6be",
   "metadata": {
    "papermill": {
     "duration": 0.01864,
     "end_time": "2025-07-15T11:44:37.642990",
     "exception": false,
     "start_time": "2025-07-15T11:44:37.624350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ae5686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:44:37.681739Z",
     "iopub.status.busy": "2025-07-15T11:44:37.681052Z",
     "iopub.status.idle": "2025-07-15T11:44:37.684702Z",
     "shell.execute_reply": "2025-07-15T11:44:37.683925Z"
    },
    "papermill": {
     "duration": 0.024203,
     "end_time": "2025-07-15T11:44:37.685873",
     "exception": false,
     "start_time": "2025-07-15T11:44:37.661670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "think_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c96048c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:44:37.725509Z",
     "iopub.status.busy": "2025-07-15T11:44:37.725325Z",
     "iopub.status.idle": "2025-07-15T11:46:54.548355Z",
     "shell.execute_reply": "2025-07-15T11:46:54.547563Z"
    },
    "papermill": {
     "duration": 136.84477,
     "end_time": "2025-07-15T11:46:54.549884",
     "exception": false,
     "start_time": "2025-07-15T11:44:37.705114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-15 11:44:38 [__init__.py:244] Automatically detected platform cuda.\n",
      "INFO 07-15 11:44:54 [config.py:841] This model supports multiple tasks: {'reward', 'embed', 'generate', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 07-15 11:44:54 [config.py:1472] Using max model len 4096\n",
      "WARNING 07-15 11:44:54 [config.py:960] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "WARNING 07-15 11:44:55 [cuda.py:102] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 07-15 11:44:55 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.2) with config: model='/kaggle/input/qwen-3/transformers/8b-awq/1', speculative_config=None, tokenizer='/kaggle/input/qwen-3/transformers/8b-awq/1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='xgrammar', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/kaggle/input/qwen-3/transformers/8b-awq/1, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":0,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "WARNING 07-15 11:44:56 [__init__.py:2662] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\n",
      "WARNING 07-15 11:44:56 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 2 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 07-15 11:44:56 [cuda.py:311] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 07-15 11:44:56 [cuda.py:360] Using XFormers backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:45:00.684933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752579900.705061      91 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752579900.711256      91 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-15 11:45:05 [__init__.py:244] Automatically detected platform cuda.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:45:06 [multiproc_worker_utils.py:226] Worker ready; awaiting tasks\n",
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:45:07 [cuda.py:311] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:45:07 [cuda.py:360] Using XFormers backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W715 11:45:17.585560976 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n",
      "[W715 11:45:18.025527572 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n",
      "[W715 11:45:27.596282783 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-15 11:45:37 [__init__.py:1152] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:45:37 [__init__.py:1152] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:45:37 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "INFO 07-15 11:45:37 [pynccl.py:70] vLLM is using nccl==2.26.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W715 11:45:37.606785109 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-15 11:45:38 [custom_all_reduce_utils.py:208] generating GPU P2P access cache in /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "INFO 07-15 11:46:00 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:46:00 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "INFO 07-15 11:46:00 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_92960e88'), local_subscribe_addr='ipc:///tmp/4b6c342b-5452-4646-a1b3-dd5e3cabfc6d', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 07-15 11:46:00 [parallel_state.py:1076] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:46:00 [parallel_state.py:1076] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\n",
      "INFO 07-15 11:46:00 [model_runner.py:1171] Starting to load model /kaggle/input/qwen-3/transformers/8b-awq/1...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:46:00 [model_runner.py:1171] Starting to load model /kaggle/input/qwen-3/transformers/8b-awq/1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb6a47fbcef412fa18535e62b8f29be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:46:41 [default_loader.py:272] Loading weights took 40.41 seconds\n",
      "INFO 07-15 11:46:41 [default_loader.py:272] Loading weights took 40.61 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:46:42 [model_runner.py:1203] Model loading took 2.8510 GiB and 40.643792 seconds\n",
      "INFO 07-15 11:46:42 [model_runner.py:1203] Model loading took 2.8510 GiB and 40.847761 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:46:49 [worker.py:294] Memory profiling takes 6.31 seconds\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:46:49 [worker.py:294] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.92) = 13.56GiB\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=91)\u001b[0;0m INFO 07-15 11:46:49 [worker.py:294] model weights take 2.85GiB; non_torch_memory takes 0.12GiB; PyTorch activation peak memory takes 0.32GiB; the rest of the memory reserved for KV Cache is 10.27GiB.\n",
      "INFO 07-15 11:46:49 [worker.py:294] Memory profiling takes 6.43 seconds\r\n",
      "INFO 07-15 11:46:49 [worker.py:294] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.92) = 13.56GiB\r\n",
      "INFO 07-15 11:46:49 [worker.py:294] model weights take 2.85GiB; non_torch_memory takes 0.10GiB; PyTorch activation peak memory takes 1.41GiB; the rest of the memory reserved for KV Cache is 9.20GiB.\n",
      "INFO 07-15 11:46:50 [executor_base.py:113] # cuda blocks: 8376, # CPU blocks: 3640\n",
      "INFO 07-15 11:46:50 [executor_base.py:118] Maximum concurrency for 4096 tokens per request: 32.72x\n",
      "INFO 07-15 11:46:54 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 11.81 seconds\n"
     ]
    }
   ],
   "source": [
    "if think_mode:\n",
    "    model_path = \"/kaggle/input/qwen-3/transformers/8b-awq/1\"\n",
    "    llm = vllm.LLM(\n",
    "        model_path,\n",
    "        quantization='awq',\n",
    "        tensor_parallel_size=torch.cuda.device_count(),\n",
    "        gpu_memory_utilization=0.92,\n",
    "        trust_remote_code=True,\n",
    "        dtype=\"half\",\n",
    "        enforce_eager=True,\n",
    "        max_model_len=4096,\n",
    "        disable_log_stats=True,\n",
    "        enable_prefix_caching=True\n",
    "    )\n",
    "else:\n",
    "    model_path = \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\"\n",
    "    llm = vllm.LLM(\n",
    "        model_path,\n",
    "        quantization='awq',\n",
    "        tensor_parallel_size=torch.cuda.device_count(),\n",
    "        gpu_memory_utilization=0.92,\n",
    "        trust_remote_code=True,\n",
    "        dtype=\"half\",\n",
    "        enforce_eager=True,\n",
    "        max_model_len=1024+512,\n",
    "        disable_log_stats=True,\n",
    "        enable_prefix_caching=True\n",
    "    )\n",
    "tokenizer = llm.get_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7099e7",
   "metadata": {
    "papermill": {
     "duration": 0.022096,
     "end_time": "2025-07-15T11:46:54.595017",
     "exception": false,
     "start_time": "2025-07-15T11:46:54.572921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# System prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5632bcf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:46:54.650060Z",
     "iopub.status.busy": "2025-07-15T11:46:54.649493Z",
     "iopub.status.idle": "2025-07-15T11:46:54.657833Z",
     "shell.execute_reply": "2025-07-15T11:46:54.657094Z"
    },
    "papermill": {
     "duration": 0.031484,
     "end_time": "2025-07-15T11:46:54.658996",
     "exception": false,
     "start_time": "2025-07-15T11:46:54.627512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYS_PROMPT_DOI = \"\"\"\n",
    "You are an expert at identifying RESEARCH DATA citations in academic papers.\n",
    "Your task is to determine if a DOI in the provided text specifically refers to a dataset, software, or data repository, NOT another academic paper.\n",
    "\n",
    "**Crucial Rules:**\n",
    "1.  **LOOK FOR DATA CONTEXT:** The DOI must be near keywords like \"data available\", \"deposited in\", \"repository\", \"accession number\", \"software\", \"code\".\n",
    "2.  **IGNORE BIBLIOGRAPHY:** If the DOI is clearly part of a numbered or author-year list in a \"References\" or \"Bibliography\" section, you MUST respond with \"Irrelevant\".\n",
    "3.  **PRIORITIZE DATA DOIs:** If there are multiple DOIs, return the one most likely to be a dataset.\n",
    "\n",
    "Only respond with either a full normalized DOI URL starting with \"https://doi.org/\" or the single word \"Irrelevant\".\n",
    "Do NOT include any other text or explanation.\n",
    "\"\"\"\n",
    "\n",
    "if think_mode:\n",
    "    \n",
    "    SYS_PROMPT_ACCESSION = \"\"\"\n",
    "    You are an expert at analyzing research data usage in academic papers.\n",
    "    \n",
    "    Think step-by-step about the surrounding text, identifying clues such as:\n",
    "    - PRIMARY data: “we deposited”, “data generated in this study”, “our data”, “submitted to”, “newly generated”\n",
    "    - SECONDARY data: “downloaded from”, “obtained from”, “previously published”, “publicly available”, “existing dataset”\n",
    "    - MISSING: mentioned only in references, general methodology descriptions without actual usage, or contexts unrelated to research data\n",
    "    \n",
    "    Silently reason through the classification.\n",
    "    \n",
    "    Please show your choice in the answer field with only the choice letter, e.g.,  \n",
    "    \"answer\": \"C\"\n",
    "    \"\"\"\n",
    "    \n",
    "    SYS_PROMPT_CLASSIFY_DOI = \"\"\"\n",
    "    You are an expert at analyzing research data citations in academic papers.\n",
    "    \n",
    "    First, reason step-by-step about whether the DOI refers to data that is:\n",
    "    A) Primary – generated specifically for this study  \n",
    "    B) Secondary – reused or derived from prior work  \n",
    "    C) Missing – merely cited in references, not research data, or otherwise unrelated\n",
    "    \n",
    "    Perform this reasoning silently.\n",
    "    \n",
    "    Please show your choice in the answer field with only the choice letter, e.g.,  \n",
    "    \"answer\": \"B\"\n",
    "    \"\"\"\n",
    "\n",
    "else:    \n",
    "    SYS_PROMPT_ACCESSION = \"\"\"\n",
    "    You are an expert at analyzing research data usage in academic papers.\n",
    "    \n",
    "    Look for contextual clues:\n",
    "    - For PRIMARY data: \"we deposited\", \"data generated in this study\", \"our data\", \"submitted to\", \"newly generated\"\n",
    "    - For SECONDARY data: \"downloaded from\", \"obtained from\", \"previously published\", \"publicly available\", \"existing dataset\"\n",
    "    - For MISSING: mentioned in references, methodology descriptions without actual usage, or unrelated contexts\n",
    "    \n",
    "    Respond with only one letter: A, B, or C.\n",
    "    \"\"\"\n",
    "    \n",
    "    SYS_PROMPT_CLASSIFY_DOI = \"\"\"\n",
    "    You are an expert at analyzing research data citations in academic papers.\n",
    "    \n",
    "    Classify the data as:\n",
    "    A) Primary: if the data was generated specifically for this study\n",
    "    B) Secondary: if the data was reused or derived from prior work  \n",
    "    C) Missing: if the DOI is in references, doesn't refer to research data, or is unrelated\n",
    "    \n",
    "    Respond with only one letter: A, B, or C.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7758b97",
   "metadata": {
    "papermill": {
     "duration": 0.020493,
     "end_time": "2025-07-15T11:46:54.700390",
     "exception": false,
     "start_time": "2025-07-15T11:46:54.679897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ask LLM to extract DOI links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73339a18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:46:54.741953Z",
     "iopub.status.busy": "2025-07-15T11:46:54.741739Z",
     "iopub.status.idle": "2025-07-15T11:47:45.174679Z",
     "shell.execute_reply": "2025-07-15T11:47:45.173941Z"
    },
    "papermill": {
     "duration": 50.455158,
     "end_time": "2025-07-15T11:47:45.175949",
     "exception": false,
     "start_time": "2025-07-15T11:46:54.720791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8aba615a0746de89d2865f5961c7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecfb92ce91604b9f90f4e2ea801868c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/293 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts = []\n",
    "for article_id, academic_text in chunks:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT_DOI},\n",
    "        {\"role\": \"user\", \"content\": academic_text}\n",
    "    ]\n",
    "\n",
    "    if think_mode:\n",
    "\n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False,enable_thinking=False\n",
    "        )\n",
    "    else:\n",
    "         prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False\n",
    "        )\n",
    "    \n",
    "    prompts.append(prompt)\n",
    "\n",
    "outputs = llm.generate(\n",
    "    prompts,\n",
    "    vllm.SamplingParams(\n",
    "        seed=0,\n",
    "        skip_special_tokens=True,\n",
    "        max_tokens=64,\n",
    "        temperature=0\n",
    "    ),\n",
    "    use_tqdm=True\n",
    ")\n",
    "\n",
    "responses = [output.outputs[0].text.strip() for output in outputs]\n",
    "\n",
    "doi_pattern = re.compile(r'(10\\.\\d{4,9}/[-._;()/:A-Z0-9]+)', re.I)\n",
    "\n",
    "doi_urls = []\n",
    "for response in responses:\n",
    "    if response.lower() == \"irrelevant\":\n",
    "        doi_urls.append(\"Irrelevant\")\n",
    "    else:\n",
    "        match = doi_pattern.search(response)\n",
    "        if match:\n",
    "            doi_urls.append(\"https://doi.org/\" + match.group(1))\n",
    "        else:\n",
    "            doi_urls.append(\"Irrelevant\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06f87a44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:47:45.220656Z",
     "iopub.status.busy": "2025-07-15T11:47:45.219985Z",
     "iopub.status.idle": "2025-07-15T11:47:45.224642Z",
     "shell.execute_reply": "2025-07-15T11:47:45.223938Z"
    },
    "papermill": {
     "duration": 0.027698,
     "end_time": "2025-07-15T11:47:45.225792",
     "exception": false,
     "start_time": "2025-07-15T11:47:45.198094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_answer_with_regex(response_text: str):\n",
    "\n",
    "    if not isinstance(response_text, str):\n",
    "        return 'Missing'\n",
    "\n",
    "    match = re.search(r'answer\\b.*?([ABC])\\b', response_text, re.IGNORECASE | re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "\n",
    "    all_choices = re.findall(r'[ABC]', response_text)\n",
    "    if all_choices:\n",
    "        return all_choices[-1]\n",
    "        \n",
    "    return 'Missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f02df616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:47:45.270209Z",
     "iopub.status.busy": "2025-07-15T11:47:45.269734Z",
     "iopub.status.idle": "2025-07-15T11:50:05.856875Z",
     "shell.execute_reply": "2025-07-15T11:50:05.856150Z"
    },
    "papermill": {
     "duration": 140.63312,
     "end_time": "2025-07-15T11:50:05.880017",
     "exception": false,
     "start_time": "2025-07-15T11:47:45.246897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169580c9b3bb4cdeb0847113b08e5d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be47f97113643c38b7bcddbe3bfc30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/69 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts = []\n",
    "valid_indices = []\n",
    "\n",
    "if think_mode:\n",
    "    for i, (chunk, url) in enumerate(zip(chunks, doi_urls)):\n",
    "        if url == \"Irrelevant\":\n",
    "            continue\n",
    "    \n",
    "        article_id, academic_text = chunk\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYS_PROMPT_CLASSIFY_DOI},\n",
    "            {\"role\": \"user\", \"content\": f\"DOI: {url}\\n\\nAcademic text:\\n{academic_text}\"}\n",
    "        ]\n",
    "    \n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False,\n",
    "            enable_thinking=True\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "        valid_indices.append(i)\n",
    "    \n",
    "    outputs = llm.generate(\n",
    "        prompts,\n",
    "        vllm.SamplingParams(\n",
    "            seed=777,\n",
    "            temperature=0.65,\n",
    "            top_p=0.95,\n",
    "            top_k=20,\n",
    "            skip_special_tokens=True,\n",
    "            max_tokens=2048+1024,\n",
    "            presence_penalty=1.5\n",
    "        ),\n",
    "        use_tqdm=True\n",
    "    )\n",
    "\n",
    "    choice_to_type_map = {'A': 'Primary', 'B': 'Secondary', 'C': 'Missing'}\n",
    "\n",
    "    responses = [output.outputs[0].text.strip() for output in outputs]\n",
    "    \n",
    "    parsed_doi_choices = [parse_answer_with_regex(resp) for resp in responses]\n",
    "    final_doi_answers = [choice_to_type_map.get(choice) for choice in parsed_doi_choices]\n",
    "    \n",
    "    answers = ['Missing'] * len(chunks)\n",
    "    for i, answer in zip(valid_indices, final_doi_answers):\n",
    "        answers[i] = answer\n",
    "    \n",
    "    \n",
    "else:\n",
    "    for i, (chunk, url) in enumerate(zip(chunks, doi_urls)):\n",
    "        if url == \"Irrelevant\":\n",
    "            continue\n",
    "    \n",
    "        article_id, academic_text = chunk\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYS_PROMPT_CLASSIFY_DOI},\n",
    "            {\"role\": \"user\", \"content\": f\"DOI: {url}\\n\\nAcademic text:\\n{academic_text}\"}\n",
    "        ]\n",
    "    \n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False,enable_thinking=False\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "        valid_indices.append(i)\n",
    "    \n",
    "    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=[\"A\", \"B\", \"C\"])\n",
    "    \n",
    "    outputs = llm.generate(\n",
    "        prompts,\n",
    "        vllm.SamplingParams(\n",
    "            seed=777,\n",
    "            temperature=0.05, \n",
    "            skip_special_tokens=True,\n",
    "            max_tokens=1,\n",
    "            logits_processors=[mclp],\n",
    "            logprobs=len(mclp.choices)\n",
    "        ),\n",
    "        use_tqdm=True\n",
    "    )\n",
    "    \n",
    "    logprobs = []\n",
    "    for lps in [output.outputs[0].logprobs[0].values() for output in outputs]:\n",
    "        logprobs.append({lp.decoded_token: lp.logprob for lp in list(lps)})\n",
    "    \n",
    "    logit_matrix = pd.DataFrame(logprobs)[[\"A\", \"B\", \"C\"]].values\n",
    "    choices = [\"Primary\", \"Secondary\", 'Missing']\n",
    "    answers = ['Missing'] * len(chunks)\n",
    "    \n",
    "    for i, (idx, logit_row) in enumerate(zip(valid_indices, logit_matrix)):\n",
    "        max_logit = np.max(logit_row)\n",
    "        max_idx = np.argmax(logit_row)\n",
    "        \n",
    "        if max_logit > -2.0:\n",
    "            answers[idx] = choices[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "471269b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:50:05.925234Z",
     "iopub.status.busy": "2025-07-15T11:50:05.924536Z",
     "iopub.status.idle": "2025-07-15T11:50:17.950879Z",
     "shell.execute_reply": "2025-07-15T11:50:17.950149Z"
    },
    "papermill": {
     "duration": 12.049633,
     "end_time": "2025-07-15T11:50:17.952039",
     "exception": false,
     "start_time": "2025-07-15T11:50:05.902406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a0d4e84c75429e8721c516ca7011a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b57e942faad494fa386adde0b425a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts = []\n",
    "\n",
    "if think_mode:\n",
    "    for chunk, acc_id in zip(chunks2, ids):\n",
    "        article_id, academic_text = chunk\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYS_PROMPT_ACCESSION},\n",
    "            {\"role\": \"user\", \"content\": f\"Accession ID: {acc_id}\\n\\nAcademic text:\\n{academic_text}\"}\n",
    "        ]\n",
    "    \n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False,\n",
    "            enable_thinking=True\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    outputs = llm.generate(\n",
    "        prompts,\n",
    "        vllm.SamplingParams(\n",
    "            seed=777,\n",
    "            temperature=0.65,\n",
    "            top_p=0.95,\n",
    "            top_k=20,\n",
    "            skip_special_tokens=True,\n",
    "            max_tokens=2048+1024,\n",
    "            presence_penalty=1.5\n",
    "        ),\n",
    "        use_tqdm=True\n",
    "    )\n",
    "    choice_to_type_map = {'A': 'Primary', 'B': 'Secondary', 'C': 'Missing'}\n",
    "\n",
    "    responses = [output.outputs[0].text.strip() for output in outputs]\n",
    "    \n",
    "    parsed_doi_choices = [parse_answer_with_regex(resp) for resp in responses]\n",
    "    answers2 = [choice_to_type_map.get(choice) for choice in parsed_doi_choices]\n",
    "\n",
    "else:\n",
    "    for chunk, acc_id in zip(chunks2, ids):\n",
    "        article_id, academic_text = chunk\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYS_PROMPT_ACCESSION},\n",
    "            {\"role\": \"user\", \"content\": f\"Accession ID: {acc_id}\\n\\nAcademic text:\\n{academic_text}\"}\n",
    "        ]\n",
    "    \n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False,enable_thinking=False\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    outputs = llm.generate(\n",
    "        prompts,\n",
    "        vllm.SamplingParams(\n",
    "            seed=777,\n",
    "            temperature=0.05,\n",
    "            skip_special_tokens=True,\n",
    "            max_tokens=1,\n",
    "            logits_processors=[mclp],\n",
    "            logprobs=len(mclp.choices)\n",
    "        ),\n",
    "        use_tqdm=True\n",
    "    )\n",
    "    \n",
    "    logprobs2 = []\n",
    "    for lps in [output.outputs[0].logprobs[0].values() for output in outputs]:\n",
    "        logprobs2.append({lp.decoded_token: lp.logprob for lp in list(lps)})\n",
    "    \n",
    "    logit_matrix2 = pd.DataFrame(logprobs2)[[\"A\", \"B\", \"C\"]].values\n",
    "    choices2 = [\"Primary\", \"Secondary\", 'Missing']\n",
    "    \n",
    "    answers2 = []\n",
    "    for logit_row in logit_matrix2:\n",
    "        max_logit = np.max(logit_row)\n",
    "        max_idx = np.argmax(logit_row)\n",
    "        \n",
    "        if max_logit > -2.0:\n",
    "            answers2.append(choices2[max_idx])\n",
    "        else:\n",
    "            answers2.append('')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c650105",
   "metadata": {
    "papermill": {
     "duration": 0.021817,
     "end_time": "2025-07-15T11:50:17.996616",
     "exception": false,
     "start_time": "2025-07-15T11:50:17.974799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f743d501",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:50:18.040778Z",
     "iopub.status.busy": "2025-07-15T11:50:18.040270Z",
     "iopub.status.idle": "2025-07-15T11:50:18.082594Z",
     "shell.execute_reply": "2025-07-15T11:50:18.081863Z"
    },
    "papermill": {
     "duration": 0.06563,
     "end_time": "2025-07-15T11:50:18.083608",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.017978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final submission stats:\n",
      "type\n",
      "Missing      254\n",
      "Primary       20\n",
      "Secondary     12\n",
      "Name: count, dtype: int64\n",
      "Total entries: 294\n"
     ]
    }
   ],
   "source": [
    "# change \"llm_type\" to \"type\" to use LLM predictions\n",
    "# as is, will use /kaggle/input/makedatacount-mixed-train model\n",
    "# for predicting \"type\"\n",
    "\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df[\"article_id\"] = [c[0] for c in chunks]\n",
    "sub_df[\"dataset_id\"] = doi_urls\n",
    "sub_df[\"dataset_id\"] = sub_df[\"dataset_id\"].str.lower()\n",
    "sub_df[\"type\"] = answers\n",
    "#sub_df = sub_df[sub_df[\"type\"].notnull()].reset_index(drop=True)\n",
    "\n",
    "sub_df2 = pd.DataFrame()\n",
    "sub_df2[\"article_id\"] = [c[0] for c in chunks2]\n",
    "sub_df2[\"dataset_id\"] = ids\n",
    "\n",
    "sub_df2[\"type\"] = answers2\n",
    "#sub_df2 = sub_df2[sub_df2[\"type\"].notnull()].reset_index(drop=True)\n",
    "\n",
    "# Combine and clean\n",
    "sub_df = pd.concat([sub_df, sub_df2], ignore_index=True)\n",
    "\n",
    "print(\"Final submission stats:\")\n",
    "print(sub_df[\"type\"].value_counts())\n",
    "print(f\"Total entries: {len(sub_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28504596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:50:18.127981Z",
     "iopub.status.busy": "2025-07-15T11:50:18.127762Z",
     "iopub.status.idle": "2025-07-15T11:50:18.137389Z",
     "shell.execute_reply": "2025-07-15T11:50:18.136574Z"
    },
    "papermill": {
     "duration": 0.03339,
     "end_time": "2025-07-15T11:50:18.138414",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.105024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/300274337.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  mask = sub_df.applymap(lambda x: x is None)\n"
     ]
    }
   ],
   "source": [
    "mask = sub_df.applymap(lambda x: x is None)\n",
    "cols = sub_df.columns[(mask).any()]\n",
    "for col in sub_df[cols]:\n",
    "    sub_df.loc[mask[col], col] = 'Missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00ef4cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:50:18.182336Z",
     "iopub.status.busy": "2025-07-15T11:50:18.181801Z",
     "iopub.status.idle": "2025-07-15T11:50:18.199843Z",
     "shell.execute_reply": "2025-07-15T11:50:18.199230Z"
    },
    "papermill": {
     "duration": 0.040698,
     "end_time": "2025-07-15T11:50:18.200850",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.160152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uses use /kaggle/input/makedatacount-mixed-train model\n",
    "# predictions on \"type\"\n",
    "sub_df = pd.merge(sub_df, df_preds[['article_id','type']], on=\"article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1a87a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:50:18.244058Z",
     "iopub.status.busy": "2025-07-15T11:50:18.243851Z",
     "iopub.status.idle": "2025-07-15T11:50:18.248043Z",
     "shell.execute_reply": "2025-07-15T11:50:18.247493Z"
    },
    "papermill": {
     "duration": 0.026854,
     "end_time": "2025-07-15T11:50:18.248989",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.222135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df=sub_df[~sub_df['dataset_id'].isin([\"irrelevant\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "025dc5e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:50:18.292142Z",
     "iopub.status.busy": "2025-07-15T11:50:18.291941Z",
     "iopub.status.idle": "2025-07-15T11:50:18.296292Z",
     "shell.execute_reply": "2025-07-15T11:50:18.295761Z"
    },
    "papermill": {
     "duration": 0.027101,
     "end_time": "2025-07-15T11:50:18.297408",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.270307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.type_x = sub_df.type_y.where(sub_df.type_x == 'Missing', sub_df.type_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "510ac329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:50:18.342235Z",
     "iopub.status.busy": "2025-07-15T11:50:18.342036Z",
     "iopub.status.idle": "2025-07-15T11:50:18.346339Z",
     "shell.execute_reply": "2025-07-15T11:50:18.345537Z"
    },
    "papermill": {
     "duration": 0.027359,
     "end_time": "2025-07-15T11:50:18.347457",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.320098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = sub_df[sub_df[\"type_x\"].isin([\"Primary\", \"Secondary\"])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34f1a2f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:50:18.390796Z",
     "iopub.status.busy": "2025-07-15T11:50:18.390390Z",
     "iopub.status.idle": "2025-07-15T11:50:18.394308Z",
     "shell.execute_reply": "2025-07-15T11:50:18.393728Z"
    },
    "papermill": {
     "duration": 0.026568,
     "end_time": "2025-07-15T11:50:18.395355",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.368787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del sub_df['type_y']\n",
    "sub_df = sub_df.rename(columns={'type_x': 'type'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "764f0fa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:50:18.439312Z",
     "iopub.status.busy": "2025-07-15T11:50:18.439129Z",
     "iopub.status.idle": "2025-07-15T11:50:18.459264Z",
     "shell.execute_reply": "2025-07-15T11:50:18.458586Z"
    },
    "papermill": {
     "duration": 0.04324,
     "end_time": "2025-07-15T11:50:18.460277",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.417037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enhanced deduplication with priority to Primary data\n",
    "sub_df = sub_df.sort_values(by=[\"article_id\", \"dataset_id\", \"type\"], \n",
    "                           key=lambda x: x.map({\"Primary\": 0, \"Secondary\": 1}) if x.name == \"type\" else x)\\\n",
    "               .drop_duplicates(subset=['article_id', 'dataset_id'], keep=\"first\")\\\n",
    "               .reset_index(drop=True)\n",
    "\n",
    "sub_df['row_id'] = range(len(sub_df))\n",
    "sub_df.to_csv(\"submission.csv\", index=False, columns=[\"row_id\", \"article_id\", \"dataset_id\", \"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c74c4a6",
   "metadata": {
    "papermill": {
     "duration": 0.020887,
     "end_time": "2025-07-15T11:50:18.503080",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.482193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluate validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae1cc18f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:50:18.546662Z",
     "iopub.status.busy": "2025-07-15T11:50:18.546433Z",
     "iopub.status.idle": "2025-07-15T11:50:18.551384Z",
     "shell.execute_reply": "2025-07-15T11:50:18.550859Z"
    },
    "papermill": {
     "duration": 0.027777,
     "end_time": "2025-07-15T11:50:18.552369",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.524592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_score(tp, fp, fn):\n",
    "    return 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) != 0 else 0.0\n",
    "    \n",
    "if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    pred_df = pd.read_csv(\"submission.csv\")\n",
    "    label_df = pd.read_csv(\"/kaggle/input/make-data-count-finding-data-references/train_labels.csv\")\n",
    "    label_df = label_df[label_df['type'] != 'Missing'].reset_index(drop=True)\n",
    "\n",
    "    hits_df = label_df.merge(pred_df, on=[\"article_id\", \"dataset_id\", \"type\"])\n",
    "    \n",
    "    tp = hits_df.shape[0]\n",
    "    fp = pred_df.shape[0] - tp\n",
    "    fn = label_df.shape[0] - tp\n",
    "    \n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(\"TP:\", tp)\n",
    "    print(\"FP:\", fp)\n",
    "    print(\"FN:\", fn)\n",
    "    print(\"F1 Score:\", round(f1_score(tp, fp, fn), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66131102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:50:18.596578Z",
     "iopub.status.busy": "2025-07-15T11:50:18.596306Z",
     "iopub.status.idle": "2025-07-15T11:50:18.606084Z",
     "shell.execute_reply": "2025-07-15T11:50:18.605450Z"
    },
    "papermill": {
     "duration": 0.033614,
     "end_time": "2025-07-15T11:50:18.607041",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.573427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_f1_score(y_true, y_pred):\n",
    "    if y_true.empty or y_pred.empty:\n",
    "        tp = 0\n",
    "        fp = len(y_pred)\n",
    "        fn = len(y_true)\n",
    "    else:\n",
    "        hits = y_true.merge(y_pred, on=[\"article_id\", \"dataset_id\", \"type\"])\n",
    "        tp = len(hits)\n",
    "        fp = len(y_pred) - tp\n",
    "        fn = len(y_true) - tp\n",
    "    \n",
    "    f1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0.0\n",
    "    return tp, fp, fn, f1\n",
    "\n",
    "def analyze_error_sources(pred_df, label_df):\n",
    "    label_df_filtered = label_df[label_df['type'] != 'Missing'].copy()\n",
    "\n",
    "    is_doi_pred = pred_df['dataset_id'].str.startswith('https://doi.org/')\n",
    "    is_doi_label = label_df_filtered['dataset_id'].str.startswith('10.')\n",
    "\n",
    "    pred_doi = pred_df[is_doi_pred]\n",
    "    pred_accession = pred_df[~is_doi_pred]\n",
    "    label_df_filtered['dataset_id_normalized'] = label_df_filtered['dataset_id'].apply(\n",
    "        lambda x: f\"https://doi.org/{x}\" if x.startswith('10.') else x\n",
    "    )\n",
    "    label_df_filtered = label_df_filtered.rename(columns={'dataset_id': 'original_dataset_id', 'dataset_id_normalized': 'dataset_id'})\n",
    "    \n",
    "    is_doi_label_norm = label_df_filtered['dataset_id'].str.startswith('https://doi.org/')\n",
    "\n",
    "    label_doi = label_df_filtered[is_doi_label_norm]\n",
    "    label_accession = label_df_filtered[~is_doi_label_norm]\n",
    "\n",
    "    tp_doi, fp_doi, fn_doi, f1_doi = calculate_f1_score(label_doi, pred_doi)\n",
    "    tp_acc, fp_acc, fn_acc, f1_acc = calculate_f1_score(label_accession, pred_accession)\n",
    "    \n",
    "    print(\"=\"*40)\n",
    "    print(\"🔬 Error Analysis by ID Type\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    print(\"\\n--- DOI ---\")\n",
    "    print(f\"Total Predictions: {len(pred_doi)}\")\n",
    "    print(f\"True Positives (TP): {tp_doi}\")\n",
    "    print(f\"False Positives (FP): {fp_doi}\")\n",
    "    print(f\"False Negatives (FN): {fn_doi}\")\n",
    "    print(f\"F1 Score: {f1_doi:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Accession ID ---\")\n",
    "    print(f\"Total Predictions: {len(pred_accession)}\")\n",
    "    print(f\"True Positives (TP): {tp_acc}\")\n",
    "    print(f\"False Positives (FP): {fp_acc}\")\n",
    "    print(f\"False Negatives (FN): {fn_acc}\")\n",
    "    print(f\"F1 Score: {f1_acc:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"Total FP:\", fp_doi + fp_acc)\n",
    "    print(\"Total FN:\", fn_doi + fn_acc)\n",
    "    print(\"=\"*40)\n",
    "\n",
    "if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    try:\n",
    "        pred_df = pd.read_csv(\"submission.csv\")\n",
    "        pred_df['dataset_id'] = pred_df['dataset_id'].astype(str)\n",
    "        \n",
    "        label_df = pd.read_csv(\"/kaggle/input/make-data-count-finding-data-references/train_labels.csv\")\n",
    "        label_df['dataset_id'] = label_df['dataset_id'].astype(str)\n",
    "\n",
    "        analyze_error_sources(pred_df, label_df)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find a required file. {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc2f7c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:50:18.651460Z",
     "iopub.status.busy": "2025-07-15T11:50:18.651242Z",
     "iopub.status.idle": "2025-07-15T11:50:18.704020Z",
     "shell.execute_reply": "2025-07-15T11:50:18.703313Z"
    },
    "papermill": {
     "duration": 0.075803,
     "end_time": "2025-07-15T11:50:18.705123",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.629320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Analyst False Negatives (FN)\n",
      "=======================================================\n",
      "All FN: 714 record\n",
      "-------------------------------------------------------\n",
      "↳ It have but wrong answer: 1 record\n",
      "    Wrong DOI: 1 record\n",
      "    Wrong Accession ID: 0 record\n",
      "-------------------------------------------------------\n",
      "↳ Can't find this: 713 record\n",
      "    Can't find DOI: 319 record\n",
      "    Can't find Accession ID: 394 record\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    pred_df = pd.read_csv(\"submission.csv\")\n",
    "    label_df = pd.read_csv(\"/kaggle/input/make-data-count-finding-data-references/train_labels.csv\")\n",
    "    label_df_filtered = label_df[label_df['type'] != 'Missing'].copy()\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"An error occurred: File not found. - {e}\")\n",
    "    exit()\n",
    "\n",
    "fn_df = pd.merge(\n",
    "    label_df_filtered,\n",
    "    pred_df,\n",
    "    on=['article_id', 'dataset_id', 'type'],\n",
    "    how='left',\n",
    "    indicator=True\n",
    ").query('_merge == \"left_only\"').drop(columns=['_merge'])\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    fn_df,\n",
    "    pred_df,\n",
    "    on=['article_id', 'dataset_id'],\n",
    "    how='left',\n",
    "    indicator='source'\n",
    ")\n",
    "\n",
    "classified_incorrectly_df = merged_df[merged_df['source'] == 'both']\n",
    "classified_incorrectly_count = len(classified_incorrectly_df)\n",
    "\n",
    "completely_missed_df = merged_df[merged_df['source'] == 'left_only']\n",
    "completely_missed_count = len(completely_missed_df)\n",
    "\n",
    "incorrect_doi_count = classified_incorrectly_df[classified_incorrectly_df['dataset_id'].str.startswith('https://', na=False)].shape[0]\n",
    "incorrect_accession_count = classified_incorrectly_df[~classified_incorrectly_df['dataset_id'].str.startswith('https://', na=False)].shape[0]\n",
    "\n",
    "\n",
    "missed_doi_count = completely_missed_df[completely_missed_df['dataset_id'].str.startswith('https://', na=False)].shape[0]\n",
    "missed_accession_count = completely_missed_df[~completely_missed_df['dataset_id'].str.startswith('https://', na=False)].shape[0]\n",
    "\n",
    "\n",
    "print(\"=\"*55)\n",
    "print(\"Analyst False Negatives (FN)\")\n",
    "print(\"=\"*55)\n",
    "print(f\"All FN: {fn_df.shape[0]} record\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"↳ It have but wrong answer: {classified_incorrectly_count} record\")\n",
    "print(f\"    Wrong DOI: {incorrect_doi_count} record\")\n",
    "print(f\"    Wrong Accession ID: {incorrect_accession_count} record\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"↳ Can't find this: {completely_missed_count} record\")\n",
    "print(f\"    Can't find DOI: {missed_doi_count} record\")\n",
    "print(f\"    Can't find Accession ID: {missed_accession_count} record\")\n",
    "print(\"=\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b159b85",
   "metadata": {
    "papermill": {
     "duration": 0.021398,
     "end_time": "2025-07-15T11:50:18.748537",
     "exception": false,
     "start_time": "2025-07-15T11:50:18.727139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13015230,
     "isSourceIdPinned": false,
     "sourceId": 82370,
     "sourceType": "competition"
    },
    {
     "datasetId": 7847931,
     "sourceId": 12441074,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7850099,
     "sourceId": 12444547,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 248033444,
     "sourceType": "kernelVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 164048,
     "modelInstanceId": 141565,
     "sourceId": 166368,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 322000,
     "modelInstanceId": 322452,
     "sourceId": 391615,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 629.51856,
   "end_time": "2025-07-15T11:50:22.893582",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-15T11:39:53.375022",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05dea65a03e0445d87cee2d63cbe4313": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "08297d97026349e99565b9a2d864ed9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "08c6c5131d8a4aaa9ed1a9df27dcbc52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b70fb86f34e4289944586fdbbd49c4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7df3cb42a72e424d8a1c2e19c293ef14",
       "max": 293.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_05dea65a03e0445d87cee2d63cbe4313",
       "tabbable": null,
       "tooltip": null,
       "value": 293.0
      }
     },
     "0d43bf5448194a46be199a3080c23af9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "109036c92bf04efa8590ed5899e6803a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f7737e0a035e4ce894a5e2fccc462869",
       "max": 69.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b772e04d11f44b2cbf72aecb6d0a338c",
       "tabbable": null,
       "tooltip": null,
       "value": 69.0
      }
     },
     "137ba059785143edb509a52f1a71ee23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d9fe1133741f41a79f6ed26ae6a335fd",
       "placeholder": "​",
       "style": "IPY_MODEL_78948f65505d4a3ab2704b23fbf7a44e",
       "tabbable": null,
       "tooltip": null,
       "value": "Processed prompts: 100%"
      }
     },
     "166bfb8ff6114c2e8b0993d20d4ce3c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "169580c9b3bb4cdeb0847113b08e5d8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9fa21f4a32aa48968cd52f2463c1c0d0",
        "IPY_MODEL_109036c92bf04efa8590ed5899e6803a",
        "IPY_MODEL_44a2b1d74cf1405db2013ecfe020fa91"
       ],
       "layout": "IPY_MODEL_08c6c5131d8a4aaa9ed1a9df27dcbc52",
       "tabbable": null,
       "tooltip": null
      }
     },
     "178f5636d30d48fd84ce13d02d97830a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "1c9071d34e6c4f85933696b7ebec013d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4d03e22e6431431e8e77bae1f51018ca",
       "placeholder": "​",
       "style": "IPY_MODEL_ddc6ab84e62a4b6f9a77fe529760ac76",
       "tabbable": null,
       "tooltip": null,
       "value": "Adding requests: 100%"
      }
     },
     "1d2df311d93045e4bafc58f7f722c598": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1def214a4d3c443e9eb96415fd530058": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "26a6335c44ee407d92288554d0ef3164": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2acdd284f0344da4b816a0d820821091": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_33fecd42a30446cc894f8b3bf008e8c6",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8ec4d98d2bf94eb395c9912eda857bc3",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "2bfa87293b8d4143947876835badb17e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d15ba78719ce4099857670294cbdb8b5",
       "placeholder": "​",
       "style": "IPY_MODEL_8af967f87aa04367b0d5731342330b32",
       "tabbable": null,
       "tooltip": null,
       "value": "Processed prompts: 100%"
      }
     },
     "306a705906114d96b29654c585b113b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3339ddc6fbd14f9f9f4f741bbadfe08f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33fecd42a30446cc894f8b3bf008e8c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b00a28ff1fa4f0fba355b30b3a811e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d63d84b0097b43baa044b7075691d67e",
       "placeholder": "​",
       "style": "IPY_MODEL_a134926fcc324ed48be1e7d0a3c934e5",
       "tabbable": null,
       "tooltip": null,
       "value": "Adding requests: 100%"
      }
     },
     "3f9d1e69e1674ee3b037494ea858a7ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "44a2b1d74cf1405db2013ecfe020fa91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f843a880e448456e812fc1c1387f802b",
       "placeholder": "​",
       "style": "IPY_MODEL_c7c2290abd7f4ceb9d98e373d23168c8",
       "tabbable": null,
       "tooltip": null,
       "value": " 69/69 [00:00&lt;00:00, 719.84it/s]"
      }
     },
     "46701dc3cfc4459d9416ee210137d344": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "480e52c40f0a48bfaa437fdd293d2595": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "489538becc82451c94f7ef5104cffefd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d03e22e6431431e8e77bae1f51018ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f1843c7d1cc42348d981ccc5182bbf6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5033434340a54cc3b915fd04b71e32c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5561bf5e679c4d178a8416862d58fa15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_afe2b5ccc9064a50a81009cee8c20710",
       "max": 293.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d3478c61813946689232f2f2ea155312",
       "tabbable": null,
       "tooltip": null,
       "value": 293.0
      }
     },
     "58744cb9fc804bcd919eda1c18e0da89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "588d0321317145fabfc72d4e6e4770e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "59aee0c9cdfa4bdeaaf88c330ef3e067": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59c466f07105464992b8722f2dfa5240": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5d1b8477914649b297846acddf774984": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e05d66861894449a13896b5d4592bd2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_26a6335c44ee407d92288554d0ef3164",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f27a630b1a36444e9fc1fe869a4b4b7f",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "60d00e653c8d453192156029b39c2790": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "62deda376b604e26ab54ae0e6d191628": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6888bf5956974b229cfad68c43925b37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6892a46ae35c4767a9c6f4b8643755ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6b333195ef674fc8bcb294eeb59408da",
       "placeholder": "​",
       "style": "IPY_MODEL_5033434340a54cc3b915fd04b71e32c1",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40&lt;00:00, 17.76s/it]\n"
      }
     },
     "69cf913cfdd449f384b8b9a71025abcb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b333195ef674fc8bcb294eeb59408da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "758135092f5c41cea62ec5c1f9fb5a14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a28e562ae69844d79c445203269136a9",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bbdd75737d034f2488fd2534ddbe9080",
       "tabbable": null,
       "tooltip": null,
       "value": 4.0
      }
     },
     "77b73d04823447bcae3ed0fe1cb20af9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78948f65505d4a3ab2704b23fbf7a44e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7909c3ad303945ebb694b258021c4303": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7ae18d99562c4b83b278d630c769a88f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "7be47f97113643c38b7bcddbe3bfc30f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d69566b791ae4310822649a954ad1e1e",
        "IPY_MODEL_faadf19a6c9848cc8ef5ca5e37769606",
        "IPY_MODEL_af7d971a3c4943b9a04fd418de709fa8"
       ],
       "layout": "IPY_MODEL_178f5636d30d48fd84ce13d02d97830a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7c10d176819346849027079c40c76d00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1def214a4d3c443e9eb96415fd530058",
       "placeholder": "​",
       "style": "IPY_MODEL_c37a4b94398747588550865cbdb9dfe3",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "7cddead32d784089bcd3b4a264d764cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5d1b8477914649b297846acddf774984",
       "placeholder": "​",
       "style": "IPY_MODEL_59c466f07105464992b8722f2dfa5240",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 94.80it/s]"
      }
     },
     "7df3cb42a72e424d8a1c2e19c293ef14": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83a7f7343ce34da29c6dc9cf7123fc85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_eed7fa4f5c3d4f0ea499e3bf1dcee052",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_480e52c40f0a48bfaa437fdd293d2595",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "83aa94166eb64a96953531014c9abc95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8af967f87aa04367b0d5731342330b32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8b57e942faad494fa386adde0b425a35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_137ba059785143edb509a52f1a71ee23",
        "IPY_MODEL_2acdd284f0344da4b816a0d820821091",
        "IPY_MODEL_c69bcd4c47f241ad90e3a89f0b380a2b"
       ],
       "layout": "IPY_MODEL_d8fc26f0fb8a49909b5c6648af174580",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8d8aba615a0746de89d2865f5961c7dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1c9071d34e6c4f85933696b7ebec013d",
        "IPY_MODEL_5561bf5e679c4d178a8416862d58fa15",
        "IPY_MODEL_eafa537fafdc4d58b68b78e081a75447"
       ],
       "layout": "IPY_MODEL_166bfb8ff6114c2e8b0993d20d4ce3c5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8ec4d98d2bf94eb395c9912eda857bc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9fa21f4a32aa48968cd52f2463c1c0d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_46701dc3cfc4459d9416ee210137d344",
       "placeholder": "​",
       "style": "IPY_MODEL_306a705906114d96b29654c585b113b9",
       "tabbable": null,
       "tooltip": null,
       "value": "Adding requests: 100%"
      }
     },
     "a134926fcc324ed48be1e7d0a3c934e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a28e562ae69844d79c445203269136a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9ba4d07d47549498d024d4022328e48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "adb7daa537c14b0ba444f13e174e0415": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e059482370d5401489300d29b5385273",
       "max": 30.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_588d0321317145fabfc72d4e6e4770e9",
       "tabbable": null,
       "tooltip": null,
       "value": 30.0
      }
     },
     "ae45a6c69c414334986c9f63508bda46": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af40a97e0bd641788ebf716ea69ea434": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "af7d971a3c4943b9a04fd418de709fa8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3339ddc6fbd14f9f9f4f741bbadfe08f",
       "placeholder": "​",
       "style": "IPY_MODEL_c60ce53c36be4183aea81cbdbb1f1ddb",
       "tabbable": null,
       "tooltip": null,
       "value": " 69/69 [02:20&lt;00:00,  2.42s/it, est. speed input: 202.81 toks/s, output: 333.25 toks/s]"
      }
     },
     "afc4bfd0a2294c0d8bc8f8515a2a3a2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ae45a6c69c414334986c9f63508bda46",
       "placeholder": "​",
       "style": "IPY_MODEL_1d2df311d93045e4bafc58f7f722c598",
       "tabbable": null,
       "tooltip": null,
       "value": " 4/4 [00:01&lt;00:00,  3.14it/s]"
      }
     },
     "afe2b5ccc9064a50a81009cee8c20710": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4841a502a30472b95a7daec14827fff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_deb194c891044b5885e2f8a2d287b2b6",
        "IPY_MODEL_758135092f5c41cea62ec5c1f9fb5a14",
        "IPY_MODEL_afc4bfd0a2294c0d8bc8f8515a2a3a2d"
       ],
       "layout": "IPY_MODEL_77b73d04823447bcae3ed0fe1cb20af9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b4d97bae5d234e20848f5fe79d9d71b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b772e04d11f44b2cbf72aecb6d0a338c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bbdd75737d034f2488fd2534ddbe9080": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bd35f3308531495a954e469f6c905b44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_489538becc82451c94f7ef5104cffefd",
       "placeholder": "​",
       "style": "IPY_MODEL_b4d97bae5d234e20848f5fe79d9d71b9",
       "tabbable": null,
       "tooltip": null,
       "value": " 30/30 [00:04&lt;00:00,  7.01it/s]"
      }
     },
     "c37a4b94398747588550865cbdb9dfe3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c3f51a64f3034b52beec9b00e1232bae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a9ba4d07d47549498d024d4022328e48",
       "placeholder": "​",
       "style": "IPY_MODEL_62deda376b604e26ab54ae0e6d191628",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "c60ce53c36be4183aea81cbdbb1f1ddb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c69bcd4c47f241ad90e3a89f0b380a2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cb15b29869eb4d65be36ec24444e81fa",
       "placeholder": "​",
       "style": "IPY_MODEL_6888bf5956974b229cfad68c43925b37",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:12&lt;00:00, 12.00s/it, est. speed input: 26.49 toks/s, output: 29.66 toks/s]"
      }
     },
     "c7c2290abd7f4ceb9d98e373d23168c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cb15b29869eb4d65be36ec24444e81fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d15ba78719ce4099857670294cbdb8b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d1b1037bce3e407cb321f78ab0cbe2b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d2a0d4e84c75429e8721c516ca7011a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3b00a28ff1fa4f0fba355b30b3a811e8",
        "IPY_MODEL_83a7f7343ce34da29c6dc9cf7123fc85",
        "IPY_MODEL_7cddead32d784089bcd3b4a264d764cd"
       ],
       "layout": "IPY_MODEL_0d43bf5448194a46be199a3080c23af9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d3478c61813946689232f2f2ea155312": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d63d84b0097b43baa044b7075691d67e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d69566b791ae4310822649a954ad1e1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_59aee0c9cdfa4bdeaaf88c330ef3e067",
       "placeholder": "​",
       "style": "IPY_MODEL_af40a97e0bd641788ebf716ea69ea434",
       "tabbable": null,
       "tooltip": null,
       "value": "Processed prompts: 100%"
      }
     },
     "d8fc26f0fb8a49909b5c6648af174580": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "d9fe1133741f41a79f6ed26ae6a335fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ddc6ab84e62a4b6f9a77fe529760ac76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "deb194c891044b5885e2f8a2d287b2b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3f9d1e69e1674ee3b037494ea858a7ac",
       "placeholder": "​",
       "style": "IPY_MODEL_83aa94166eb64a96953531014c9abc95",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "e059482370d5401489300d29b5385273": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2c04f6d255c479fb67ee039b9a36b0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eafa537fafdc4d58b68b78e081a75447": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4f1843c7d1cc42348d981ccc5182bbf6",
       "placeholder": "​",
       "style": "IPY_MODEL_e2c04f6d255c479fb67ee039b9a36b0a",
       "tabbable": null,
       "tooltip": null,
       "value": " 293/293 [00:00&lt;00:00, 418.15it/s]"
      }
     },
     "ec6a0a493141468789269e52ae22b3c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_60d00e653c8d453192156029b39c2790",
       "placeholder": "​",
       "style": "IPY_MODEL_08297d97026349e99565b9a2d864ed9f",
       "tabbable": null,
       "tooltip": null,
       "value": " 293/293 [00:49&lt;00:00, 14.64it/s, est. speed input: 2601.38 toks/s, output: 45.97 toks/s]"
      }
     },
     "ecfb92ce91604b9f90f4e2ea801868c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2bfa87293b8d4143947876835badb17e",
        "IPY_MODEL_0b70fb86f34e4289944586fdbbd49c4e",
        "IPY_MODEL_ec6a0a493141468789269e52ae22b3c0"
       ],
       "layout": "IPY_MODEL_7ae18d99562c4b83b278d630c769a88f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "eeb6a47fbcef412fa18535e62b8f29be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7c10d176819346849027079c40c76d00",
        "IPY_MODEL_5e05d66861894449a13896b5d4592bd2",
        "IPY_MODEL_6892a46ae35c4767a9c6f4b8643755ad"
       ],
       "layout": "IPY_MODEL_7909c3ad303945ebb694b258021c4303",
       "tabbable": null,
       "tooltip": null
      }
     },
     "eed7fa4f5c3d4f0ea499e3bf1dcee052": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f27a630b1a36444e9fc1fe869a4b4b7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f7737e0a035e4ce894a5e2fccc462869": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f843a880e448456e812fc1c1387f802b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "faadf19a6c9848cc8ef5ca5e37769606": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d1b1037bce3e407cb321f78ab0cbe2b7",
       "max": 69.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_58744cb9fc804bcd919eda1c18e0da89",
       "tabbable": null,
       "tooltip": null,
       "value": 69.0
      }
     },
     "fb58957882194fc2a5571d59d235beb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c3f51a64f3034b52beec9b00e1232bae",
        "IPY_MODEL_adb7daa537c14b0ba444f13e174e0415",
        "IPY_MODEL_bd35f3308531495a954e469f6c905b44"
       ],
       "layout": "IPY_MODEL_69cf913cfdd449f384b8b9a71025abcb",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
