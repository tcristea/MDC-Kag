{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":82370,"databundleVersionId":13015230,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":12444547,"sourceType":"datasetVersion","datasetId":7850099},{"sourceId":12616808,"sourceType":"datasetVersion","datasetId":7970947},{"sourceId":12625129,"sourceType":"datasetVersion","datasetId":7977103},{"sourceId":12641617,"sourceType":"datasetVersion","datasetId":7988469},{"sourceId":248118764,"sourceType":"kernelVersion"},{"sourceId":253744833,"sourceType":"kernelVersion"},{"sourceId":166368,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":141565,"modelId":164048},{"sourceId":375840,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":310551,"modelId":322000}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":488.278722,"end_time":"2025-07-24T17:55:22.890819","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-24T17:47:14.612097","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"]=\"false\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:12.597765Z","iopub.execute_input":"2025-08-03T01:27:12.597949Z","iopub.status.idle":"2025-08-03T01:27:12.604928Z","shell.execute_reply.started":"2025-08-03T01:27:12.597931Z","shell.execute_reply":"2025-08-03T01:27:12.604216Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ! uv pip uninstall --system 'tensorflow'\n! uv pip install --system --no-index --find-links='/kaggle/input/latest-mdc-whls/whls' 'pymupdf' # 'vllm' 'triton' 'logits-processor-zoo' 'numpy<2'","metadata":{"_cell_guid":"eae4b221-a822-451f-8f4b-134c3f9bfe2c","_uuid":"b1883565-f717-4130-a662-5bb541f45ea1","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":27.258583,"end_time":"2025-07-24T17:47:46.061744","exception":false,"start_time":"2025-07-24T17:47:18.803161","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:12.606310Z","iopub.execute_input":"2025-08-03T01:27:12.606567Z","iopub.status.idle":"2025-08-03T01:27:13.453557Z","shell.execute_reply.started":"2025-08-03T01:27:12.606542Z","shell.execute_reply":"2025-08-03T01:27:13.452655Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 34ms\u001b[0m\u001b[0m                                           \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 340ms\u001b[0m\u001b[0m                                              \n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 10ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpymupdf\u001b[0m\u001b[2m==1.26.1\u001b[0m\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ! uv pip install /kaggle/input/mdcfitz/pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl\n! uv pip install vllm --no-index --find-links file:///kaggle/input/mdcllm\n! uv pip install logits-processor-zoo==0.1.10 --no-index --find-links file:///kaggle/input/mdcllm\n! uv pip install triton==3.2.0 --no-index --find-links file:///kaggle/input/mdcllm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:13.454544Z","iopub.execute_input":"2025-08-03T01:27:13.454813Z","iopub.status.idle":"2025-08-03T01:27:49.211543Z","shell.execute_reply.started":"2025-08-03T01:27:13.454775Z","shell.execute_reply":"2025-08-03T01:27:49.210805Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m145 packages\u001b[0m \u001b[2min 268ms\u001b[0m\u001b[0m                                       \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m54 packages\u001b[0m \u001b[2min 29.96s\u001b[0m\u001b[0m                                           \n\u001b[2mUninstalled \u001b[1m23 packages\u001b[0m \u001b[2min 1.51s\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m54 packages\u001b[0m \u001b[2min 340ms\u001b[0m\u001b[0m                              \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mairportsdata\u001b[0m\u001b[2m==20250706\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mastor\u001b[0m\u001b[2m==0.8.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mblake3\u001b[0m\u001b[2m==1.0.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcompressed-tensors\u001b[0m\u001b[2m==0.10.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdepyf\u001b[0m\u001b[2m==0.18.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdiskcache\u001b[0m\u001b[2m==5.6.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi-cli\u001b[0m\u001b[2m==0.0.8\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi-cloud-cli\u001b[0m\u001b[2m==0.1.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mgguf\u001b[0m\u001b[2m==0.17.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.6.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.27.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1minteregular\u001b[0m\u001b[2m==0.3.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlark\u001b[0m\u001b[2m==1.2.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mllguidance\u001b[0m\u001b[2m==0.7.30\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.43.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.44.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlm-format-enforcer\u001b[0m\u001b[2m==0.10.11\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmistral-common\u001b[0m\u001b[2m==1.6.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmsgspec\u001b[0m\u001b[2m==0.19.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.60.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.61.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.6.4.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.6.80\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.5.1.17\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.0.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.11.1.6\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.7.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.1.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.4.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.26.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.6.85\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.91.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.90.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moutlines\u001b[0m\u001b[2m==0.1.11\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moutlines-core\u001b[0m\u001b[2m==0.1.26\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpartial-json-parser\u001b[0m\u001b[2m==0.2.1.1.post6\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mprometheus-fastapi-instrumentator\u001b[0m\u001b[2m==7.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpybase64\u001b[0m\u001b[2m==1.4.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpycountry\u001b[0m\u001b[2m==24.6.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==24.0.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.0.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrich-toolkit\u001b[0m\u001b[2m==0.14.8\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrignore\u001b[0m\u001b[2m==0.5.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.7.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.7.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0+cu124 (from https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.22.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mvllm\u001b[0m\u001b[2m==0.9.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.30\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxgrammar\u001b[0m\u001b[2m==0.1.19\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m54 packages\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m                                                \n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0mo==0.1.10                         \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlogits-processor-zoo\u001b[0m\u001b[2m==0.1.10\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m                                            \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 2.79s\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"! mkdir -p /tmp/src","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:49.212592Z","iopub.execute_input":"2025-08-03T01:27:49.212864Z","iopub.status.idle":"2025-08-03T01:27:49.329684Z","shell.execute_reply.started":"2025-08-03T01:27:49.212826Z","shell.execute_reply":"2025-08-03T01:27:49.328979Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"%%writefile /tmp/src/helpers.py\nimport logging, os, kagglehub, inspect\nfrom pathlib import Path\nimport polars as pl\n\nos.environ[\"TOKENIZERS_PARALLELISM\"]=\"False\"\nIS_KAGGLE_ENV = sum(['KAGGLE' in k for k in os.environ]) > 0\nos.environ[\"KAGGLE_IS_COMPETITION_RERUN\"] = \"1\"\n\nIS_KAGGLE_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n\nCOMP_DIR = Path(('/kaggle/input/make-data-count-finding-data-references' if IS_KAGGLE_SUBMISSION else kagglehub.competition_download('make-data-count-finding-data-references')))\nPDF_DIR = COMP_DIR / ('test' if IS_KAGGLE_SUBMISSION else 'train') / 'PDF'\nWORKING_DIR = Path(('/kaggle/working/' if IS_KAGGLE_ENV else '.working/'))\n\nDOI_LINK = 'https://doi.org/'\n\nDEFAULT_LOG_LEVEL = os.getenv(\"LOG_LEVEL\", \"DEBUG\").upper() if not IS_KAGGLE_SUBMISSION else \"WARNING\"\nLOG_FILE_PATH = os.getenv(\"LOG_FILE\", \"logs/project.log\")\nLOG_DIR = Path(LOG_FILE_PATH).parent\n\nLOG_DIR.mkdir(parents=True, exist_ok=True)\n\nLOG_FORMAT = \"%(levelname)s %(asctime)s  [%(filename)s:%(lineno)d - %(funcName)s()] %(message)s\"\nLOG_DATEFMT = \"%Y-%m-%d %H:%M:%S\"\n\ndef get_logger(name=None):\n    if name is None:\n        frame = inspect.currentframe()\n        if frame is None or frame.f_back is None:\n            name = \"__main__\"\n        else:\n            name = frame.f_back.f_globals.get(\"__name__\", \"__main__\")\n\n    logger = logging.getLogger(name)\n\n    if not logger.handlers:\n        logger.setLevel(DEFAULT_LOG_LEVEL)\n        formatter = logging.Formatter(fmt=LOG_FORMAT, datefmt=LOG_DATEFMT)\n        ch = logging.StreamHandler()\n        ch.setLevel(DEFAULT_LOG_LEVEL)\n        ch.setFormatter(formatter)\n        fh = logging.FileHandler(LOG_FILE_PATH)\n        fh.setLevel(DEFAULT_LOG_LEVEL)\n        fh.setFormatter(formatter)\n        logger.addHandler(ch)\n        logger.addHandler(fh)\n        logger.propagate = False\n    return logger\n\ndef is_doi_link(name: str) -> pl.Expr:\n    return pl.col(name).str.starts_with(DOI_LINK)\n\ndef string_normalization(name: str) -> pl.Expr:\n    return pl.col(name).str.normalize(\"NFKC\").str.replace_all(r\"[^\\p{Ascii}]\", '').str.replace_all(r\"https?://zenodo\\.org/record/(\\d+)\", r\" 10.5281/zenodo.$1 \")\n\ndef get_df(parse_dir: str):\n    records = []\n    txt_files = list(Path(parse_dir).glob('*.txt'))\n    for txt_file in txt_files:\n        id_ = txt_file.stem\n        with open(txt_file, 'r') as f:\n            text = f.read()\n        records.append({'article_id': id_, 'text': text})\n    return pl.DataFrame(records).with_columns(string_normalization('text').alias('text'))\n\ndef assume_type(df: pl.DataFrame) -> pl.DataFrame:\n    return (\n        df.with_columns(pl.when(is_doi_link('dataset_id').or_(pl.col('dataset_id').str.starts_with('SAMN'))).then(pl.lit('Primary')).otherwise(pl.lit('Secondary')).alias('type'))\n    )\n\ndef score(df, gt, on, tag='all'):\n    hits = gt.join(df, on=on)\n    tp = hits.height\n    fp = df.height - tp\n    fn = gt.height - tp\n    f1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) != 0 else 0.0\n    return f\"{tag} - f1: {f1:.4f} [{tp}/{fp}/{fn}]\"\n\ndef evaluate(df, on=['article_id', 'dataset_id']):\n    gt = pl.read_csv(COMP_DIR/'train_labels.csv').filter(pl.col('type')!='Missing')\n    return (\n        score(df, gt, on),\n        score(df.filter(is_doi_link('dataset_id')), gt.filter(is_doi_link('dataset_id')), on, 'doi'),\n        score(df.filter(~is_doi_link('dataset_id')), gt.filter(~is_doi_link('dataset_id')), on, 'acc'),\n    )","metadata":{"_cell_guid":"34135540-31fa-4d24-8934-acb1e0711a4f","_uuid":"92f33014-02d3-41cb-b906-ffeb89a3f353","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.017137,"end_time":"2025-07-24T17:47:46.087471","exception":false,"start_time":"2025-07-24T17:47:46.070334","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:49.331658Z","iopub.execute_input":"2025-08-03T01:27:49.331875Z","iopub.status.idle":"2025-08-03T01:27:52.039618Z","shell.execute_reply.started":"2025-08-03T01:27:49.331854Z","shell.execute_reply":"2025-08-03T01:27:52.038711Z"}},"outputs":[{"name":"stdout","text":"Writing /tmp/src/helpers.py\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"%%writefile /tmp/src/parse.py\nimport argparse\nfrom pathlib import Path\nimport pymupdf\nfrom helpers import get_logger, PDF_DIR\n\nl = get_logger()\n\ndef pdf_to_txt(output_dir: Path):\n    output_dir.mkdir(parents=True, exist_ok=True)\n    pdf_files = list(PDF_DIR.glob(\"*.pdf\")) + list(PDF_DIR.glob(\"*.PDF\"))\n    existing_txt_files = {f.stem for f in output_dir.glob(\"*.txt\")}\n    for pdf_file in pdf_files:\n        txt_file = output_dir / f\"{pdf_file.stem}.txt\"\n        if pdf_file.stem in existing_txt_files:\n            continue\n        try:\n            text = \"\"\n            with pymupdf.open(pdf_file) as doc:\n                for page in doc:\n                    text += page.get_text()\n            txt_file.write_text(text, encoding='utf-8')\n        except Exception:\n            pass\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('output_dir', type=Path, help='Directory to save text files')\n    args = parser.parse_args()\n    pdf_to_txt(args.output_dir)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_cell_guid":"98be0899-3cad-423b-a3db-313209068df0","_uuid":"84859532-6acd-4011-b783-d0d24257a19b","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.015142,"end_time":"2025-07-24T17:47:46.110538","exception":false,"start_time":"2025-07-24T17:47:46.095396","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:52.040405Z","iopub.execute_input":"2025-08-03T01:27:52.040712Z","iopub.status.idle":"2025-08-03T01:27:53.210746Z","shell.execute_reply.started":"2025-08-03T01:27:52.040686Z","shell.execute_reply":"2025-08-03T01:27:53.209924Z"}},"outputs":[{"name":"stdout","text":"Writing /tmp/src/parse.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"%%writefile /tmp/src/check_parse.py\nimport polars as pl\nfrom pathlib import Path\nfrom helpers import *\n\nl=get_logger()\n\ndef gt_dataset_id_normalization(name:str) -> pl.Expr:\n    return (\n        pl.when(is_doi_link(name))\n        .then(pl.col(name).str.split(DOI_LINK).list.last())\n        .otherwise(name)\n        .str.to_lowercase()\n    )\n\ndef main():\n    if IS_KAGGLE_SUBMISSION:\n        l.debug('skipping check_parse for submission')\n        return\n    df = (\n        get_df('/tmp/train_parse')\n        .with_columns(pl.col('text').str.replace_all('\\s+', '').str.to_lowercase().alias('text'))\n    )\n\n    gt = (\n        pl.read_csv(COMP_DIR/'train_labels.csv')\n        .filter(pl.col('article_id').is_in(df['article_id']))\n        .filter(pl.col('type')!='Missing')\n        .with_columns(gt_dataset_id_normalization('dataset_id').alias('norm_id'))\n    )\n\n    l.info(f\"pymupdf misses: {gt.join(df, on='article_id').with_columns(hit=pl.col('text').str.contains(pl.col('norm_id'), literal=True)).filter(~pl.col('hit')).height} dataset_ids\")\n\nif __name__=='__main__': main()","metadata":{"_cell_guid":"01632e8b-2a68-4dec-9606-f91214a8c020","_uuid":"5210e49f-e5ab-45c6-b673-f0bd08dc1877","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.014538,"end_time":"2025-07-24T17:47:46.133223","exception":false,"start_time":"2025-07-24T17:47:46.118685","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:53.211797Z","iopub.execute_input":"2025-08-03T01:27:53.212068Z","iopub.status.idle":"2025-08-03T01:27:54.016397Z","shell.execute_reply.started":"2025-08-03T01:27:53.212043Z","shell.execute_reply":"2025-08-03T01:27:54.015512Z"}},"outputs":[{"name":"stdout","text":"Writing /tmp/src/check_parse.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"%%writefile /tmp/src/getid.py\nimport re\nimport polars as pl\nfrom typing import Optional, Tuple\n\nfrom helpers import *\n\nCOMPILED_PATTERNS = {\n    'ref_header_patterns': [re.compile(r'\\b(R\\s*E\\s*F\\s*E\\s*R\\s*E\\s*N\\s*C\\s*E\\s*S|BIBLIOGRAPHY|LITERATURE CITED|WORKS CITED|CITED WORKS|ACKNOWLEDGEMENTS)\\b[:\\s]*', re.IGNORECASE)],\n    'citation_pattern': re.compile(r'^\\s*(\\[\\d+\\]|\\(\\d+\\)|\\d+\\.|\\d+\\)|\\d+(?=\\s|$))\\s*'),\n    'first_citation_patterns': [\n        re.compile(r'^\\s*\\[1\\]\\s*'),\n        re.compile(r'^\\s*\\(1\\)\\s*'),\n        re.compile(r'^\\s*1\\.\\s*'),\n        re.compile(r'^\\s*1\\)\\s*'),\n        re.compile(r'^\\s*1(?=\\s|$)'),\n    ],\n}\n\nl = get_logger()\n\ndef find_last_reference_header(text: str, header_patterns: list[re.Pattern]) -> Optional[int]:\n    last_match_idx = None\n    for pattern in header_patterns:\n        matches = list(pattern.finditer(text))\n        if matches:\n            last_match_idx = matches[-1].start()\n    return last_match_idx\n\ndef find_last_first_citation(text: str) -> Optional[int]:\n    lines = text.splitlines()\n    last_match_line = None\n    for line_num, line in enumerate(lines):\n        line = line.strip()\n        for pattern in COMPILED_PATTERNS['first_citation_patterns']:\n            if pattern.match(line):\n                next_lines = lines[line_num:line_num+3]\n                if any(COMPILED_PATTERNS['citation_pattern'].match(l.strip()) for l in next_lines[1:]):\n                    last_match_line = line_num\n                break\n    return last_match_line\n\ndef find_reference_start(text: str) -> Optional[int]:\n    lines = text.splitlines()\n    last_first_citation = find_last_first_citation(text)\n    if last_first_citation is not None:\n        return last_first_citation\n    start_search_idx = int(len(lines) * 0.5)\n    for i in range(start_search_idx, len(lines)):\n        line = lines[i].strip()\n        if COMPILED_PATTERNS['citation_pattern'].match(line):\n            next_lines = lines[i:i+3]\n            if sum(1 for l in next_lines if COMPILED_PATTERNS['citation_pattern'].match(l.strip())) >= 2:\n                for j in range(i, max(-1, i-10), -1):\n                    if not COMPILED_PATTERNS['citation_pattern'].match(lines[j].strip()):\n                        return j + 1\n                return max(0, i-10)\n    return None\n\ndef split_text_and_references(text: str) -> Tuple[str, str]:\n    header_idx = find_last_reference_header(text, COMPILED_PATTERNS['ref_header_patterns'])\n    if header_idx is not None:\n        header_idx2 = find_last_reference_header(text[:header_idx].strip(), COMPILED_PATTERNS['ref_header_patterns'])\n        if header_idx2 is not None:\n            header_idx3 = find_last_reference_header(text[:header_idx2].strip(), COMPILED_PATTERNS['ref_header_patterns'])\n            if header_idx3 is not None:\n                return text[:header_idx3].strip(), text[header_idx3:].strip()\n            return text[:header_idx2].strip(), text[header_idx2:].strip()\n        return text[:header_idx].strip(), text[header_idx:].strip()\n    ref_start_line = find_reference_start(text)\n    if ref_start_line is not None:\n        lines = text.splitlines()\n        body = '\\n'.join(lines[:ref_start_line])\n        refs = '\\n'.join(lines[ref_start_line:])\n        return body.strip(), refs.strip()\n    return text.strip(), ''\n\ndef get_splits(df: pl.DataFrame) -> pl.DataFrame:\n    bodies, refs = [], []\n    for raw_text in df['text']:\n        main, ref = split_text_and_references(raw_text)\n        bodies.append(main)\n        refs.append(ref)\n    return df.with_columns(pl.Series('body', bodies), pl.Series('ref', refs))\n\ndef tidy_extraction(df) -> pl.DataFrame:\n    bad_ids = [f'{DOI_LINK}{e}' for e in ['10.5061/dryad', '10.5281/zenodo', '10.6073/pasta']]\n\n    doi_df = (\n        df.with_columns(pl.col('body').str.extract_all(r'10\\s*\\.\\s*\\d{4,9}\\s*/\\s*\\S+').alias('match'))\n          .explode('match')\n          .drop_nulls('match')\n          .with_columns(\n              pl.col('match').str.replace_all(r'\\s+', '')\n                             .str.replace(r'[^A-Za-z0-9]+$', '')\n                             .str.to_lowercase()\n                             .alias('dataset_id')\n          )\n          .group_by('article_id', 'dataset_id')\n          .agg('match')\n          .with_columns((DOI_LINK + pl.col('dataset_id')).alias('dataset_id'))\n    )\n\n    REGEX_IDS = (\n        r\"(?i)\\b(?:\"\n        r\"CHEMBL\\d+|\"\n        r\"E-GEOD-\\d+|E-PROT-\\d+|EMPIAR-\\d+|\"\n        r\"ENSBTAG\\d+|ENSOARG\\d+|\"\n        r\"EPI_ISL_\\d{5,}|EPI\\d{6,7}|\"\n        r\"HPA\\d+|CP\\d{6}|IPR\\d{6}|PF\\d{5}|KX\\d{6}|K0\\d{4}|\"\n        r\"PRJNA\\d+|PRJEB\\d+|PXD\\d+|SAMN\\d+|\"\n        r\"GSE\\d+|GSM\\d+|GPL\\d+|\"\n        r\"E-MTAB-\\d+|E-MEXP-\\d+|\"\n        r\"PDB\\s?\\w{4}|HMDB\\d+|\"\n        r\"dryad\\.[^\\s\\\"<>]+|pasta\\/[^\\s\\\"<>]+|\"\n        r\"(?:SRR|SRX|SRP|ERR|DRR|DRX|DRP|ERP|ERX)\\d+\"\n        r\")\"\n    )\n\n\n    acc_df = (\n        df.with_columns(\n            pl.col('text').str.extract_all(REGEX_IDS).alias('match')\n        )\n        .explode('match')\n        .drop_nulls('match')\n        .with_columns(\n            pl.col('match').str.replace_all(r'\\s+', '')\n                           .str.replace(r'[^A-Za-z0-9]+$', '')\n                           .alias('dataset_id')\n        )\n        .group_by('article_id', 'dataset_id')\n        .agg('match')\n        .with_columns(\n            pl.when(pl.col('dataset_id').str.starts_with('dryad.'))\n              .then(f'{DOI_LINK}10.5061/' + pl.col('dataset_id'))\n              .otherwise('dataset_id')\n              .alias('dataset_id')\n        )\n        .with_columns(\n            pl.when(pl.col('dataset_id').str.starts_with('pasta/'))\n              .then(f'{DOI_LINK}10.6073/' + pl.col('dataset_id'))\n              .otherwise('dataset_id')\n              .alias('dataset_id')\n        )\n    )\n\n    df = pl.concat([doi_df, acc_df])\n\n    df = (\n        df.unique(['article_id', 'dataset_id'])  # CHANGED\n          .filter(~pl.col('article_id').str.replace('_','/').str.contains(pl.col('dataset_id').str.split(DOI_LINK).list.last().str.escape_regex()))\n          .filter(~pl.col('dataset_id').str.contains(pl.col('article_id').str.replace('_','/').str.escape_regex()))\n          .filter(~pl.col('dataset_id').str.contains('figshare', literal=True))\n          .filter(~pl.col('dataset_id').is_in(bad_ids))\n          .filter(\n              pl.when(is_doi_link('dataset_id') &\n                      (pl.col('dataset_id').str.split('/').list.last().str.len_chars() < 5))\n               .then(False)\n               .otherwise(True)\n          )\n          .with_columns(pl.col('match').list.unique())\n    )\n    return df\n\ndef get_context_window(text: str, substring: str, window: int = 100) -> str:\n    idx = text.find(substring)\n    if idx == -1:\n        raise ValueError\n    start = max(idx - window, 0)\n    end = min(idx + len(substring) + window, len(text))\n    return text[start:end]\n\ndef get_window_df(text_df, ids_df):\n    df = ids_df.join(text_df, on='article_id')\n    windows = []\n    for text, match_ids in df.select('text', 'match').rows():\n        windows.append(get_context_window(text, match_ids[0]))\n    return df.with_columns(pl.Series('window', windows)).select('article_id', 'dataset_id', 'window')\n\ndef main():\n    text_df = get_df('/tmp/train_parse')\n    df = get_splits(text_df)\n    df = get_splits(text_df)\n    df.write_parquet(\"/tmp/train_parse_split.parquet\")  # <-- Add this line\n    df = tidy_extraction(df)\n    df = get_window_df(text_df, df)\n    df.write_parquet('/tmp/extracted.parquet')\n    df = assume_type(df)\n    df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n    if not IS_KAGGLE_SUBMISSION:\n        results = evaluate(df)\n        for r in results: l.info(r)\n        results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n        for r in results: l.info(r)\n\nif __name__=='__main__': main()","metadata":{"_cell_guid":"83084a3e-ab3e-4c24-9045-7bc81df72e34","_uuid":"5a79e391-1a5c-4264-9aa5-747cb657a266","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.017716,"end_time":"2025-07-24T17:47:46.158794","exception":false,"start_time":"2025-07-24T17:47:46.141078","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:54.018177Z","iopub.execute_input":"2025-08-03T01:27:54.018521Z","iopub.status.idle":"2025-08-03T01:27:55.080739Z","shell.execute_reply.started":"2025-08-03T01:27:54.018490Z","shell.execute_reply":"2025-08-03T01:27:55.079745Z"}},"outputs":[{"name":"stdout","text":"Writing /tmp/src/getid.py\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"%%writefile /tmp/src/addon_fix_broken_dois.py\nimport re\nimport polars as pl\nfrom helpers import *\n\nl = get_logger()\n\nBROKEN_DOI_REGEX = re.compile(r'10\\s*\\.\\s*\\d{4,9}\\s*/\\s*[A-Za-z0-9._;()/:\\-]+', re.IGNORECASE)\n\ndef normalize_doi(s: str) -> str:\n    return re.sub(r'[^A-Za-z0-9./-]+', '', s).lower().rstrip('.;:,')\n\ndef extract_broken_dois(df: pl.DataFrame) -> pl.DataFrame:\n    l.info(\"Extracting broken DOIs from ref section\")\n    return (\n        df.select(['article_id', 'ref'])\n          .with_columns(\n              pl.col(\"ref\").map_elements(lambda x: BROKEN_DOI_REGEX.findall(x or ''), return_dtype=pl.List(pl.String)).alias(\"match\")\n          )\n          .explode(\"match\")\n          .drop_nulls(\"match\")\n          .with_columns(\n              pl.col(\"match\").map_elements(normalize_doi, return_dtype=pl.String).alias(\"dataset_id\")\n          )\n          .filter(pl.col(\"dataset_id\").str.starts_with(\"10.\"))\n          .group_by(\"article_id\", \"dataset_id\")\n          .agg(pl.col(\"match\"))\n          .with_columns((DOI_LINK + pl.col(\"dataset_id\")).alias(\"dataset_id\"))\n    )\n\ndef main():\n    df = pl.read_parquet('/tmp/train_parse_split.parquet')\n    broken_dois = extract_broken_dois(df)\n    broken_dois.write_parquet('/tmp/addon_broken_dois.parquet')\n    l.info(f\"Extracted {broken_dois.shape[0]} broken DOIs\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:55.081881Z","iopub.execute_input":"2025-08-03T01:27:55.082206Z","iopub.status.idle":"2025-08-03T01:27:56.263165Z","shell.execute_reply.started":"2025-08-03T01:27:55.082179Z","shell.execute_reply":"2025-08-03T01:27:56.262365Z"}},"outputs":[{"name":"stdout","text":"Writing /tmp/src/addon_fix_broken_dois.py\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%%writefile /tmp/src/addon_reference_priority.py\nimport polars as pl\nfrom helpers import *\n\nl = get_logger()\n\ndef extract_reference_dois(df: pl.DataFrame) -> pl.DataFrame:\n    l.info(\"Tagging DOIs from reference section only\")\n    return (\n        df.select(['article_id', 'ref'])\n          .with_columns(\n              pl.col(\"ref\")\n              .str.extract_all(r'10\\.\\d{4,9}/\\S+')\n              .alias(\"match\")\n          )\n          .explode(\"match\")\n          .drop_nulls(\"match\")\n          .with_columns(\n              pl.col(\"match\")\n              .str.replace_all(r'[\\s]+', '')\n              .str.replace(r'[^A-Za-z0-9./-]+$', '')\n              .str.to_lowercase()\n              .alias(\"dataset_id\")\n          )\n          .filter(pl.col(\"dataset_id\").str.starts_with(\"10.\"))\n          .group_by(\"article_id\", \"dataset_id\")\n          .agg(pl.col(\"match\"))\n          .with_columns((DOI_LINK + pl.col(\"dataset_id\")).alias(\"dataset_id\"))\n    )\n\ndef main():\n    df = pl.read_parquet('/tmp/train_parse_split.parquet')\n    ref_dois = extract_reference_dois(df)\n    ref_dois.write_parquet('/tmp/addon_ref_priority.parquet')\n    l.info(f\"Extracted {ref_dois.shape[0]} reference-priority DOIs\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:56.264010Z","iopub.execute_input":"2025-08-03T01:27:56.264246Z","iopub.status.idle":"2025-08-03T01:27:56.276975Z","shell.execute_reply.started":"2025-08-03T01:27:56.264229Z","shell.execute_reply":"2025-08-03T01:27:56.276249Z"}},"outputs":[{"name":"stdout","text":"Writing /tmp/src/addon_reference_priority.py\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"%%writefile /tmp/src/merge_augmented_ids.py\nimport polars as pl\n\ndef drop_if_exists(df: pl.DataFrame, col: str) -> pl.DataFrame:\n    return df.drop(col) if col in df.columns else df\n\ndef align_columns(df: pl.DataFrame, target_columns: list[str]) -> pl.DataFrame:\n    for col in target_columns:\n        if col not in df.columns:\n            df = df.with_columns(pl.lit(None).alias(col))\n    return df.select(target_columns)\n\n# Standard column order\ntarget_columns = [\"article_id\", \"dataset_id\", \"window\"]\n\n# Load base\na = pl.read_parquet(\"/tmp/scibert_predictions.parquet\")\na = align_columns(a, target_columns)\n\n# Load and align broken DOIs\nb = pl.read_parquet(\"/tmp/addon_broken_dois.parquet\")\nb = drop_if_exists(b, \"match\")\nb = align_columns(b, target_columns)\n\n# Merge a + b\nmerged_ab = pl.concat([a, b]).unique(subset=[\"article_id\", \"dataset_id\"])\nmerged_ab.write_parquet(\"/tmp/scibert_predictions.parquet\")\n\n# Load and align ref-section DOIs\nc = pl.read_parquet(\"/tmp/addon_ref_priority.parquet\")\nc = drop_if_exists(c, \"match\")\nc = align_columns(c, target_columns)\n\n# Final merge\nfinal = pl.concat([merged_ab, c]).unique(subset=[\"article_id\", \"dataset_id\"])\nfinal = final.filter(pl.col(\"window\").is_not_null())\nfinal.write_parquet(\"/tmp/scibert_predictions.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:56.277867Z","iopub.execute_input":"2025-08-03T01:27:56.278312Z","iopub.status.idle":"2025-08-03T01:27:56.290205Z","shell.execute_reply.started":"2025-08-03T01:27:56.278286Z","shell.execute_reply":"2025-08-03T01:27:56.289614Z"}},"outputs":[{"name":"stdout","text":"Writing /tmp/src/merge_augmented_ids.py\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"%%writefile /tmp/src/llm_validate.py\nimport polars as pl\nimport os\n\nfrom helpers import *\n\nl = get_logger()\n\nSYS_PROMPT_CLASSIFY_ALL = \"\"\"\nYou are a highly accurate dataset identifier classifier. Given a snippet of academic text containing a DOI or accession number, choose:\n\n  A) Data — the identifier points directly to research data in a repository  \n  B) Literature — the identifier points to a journal article, book chapter, protocol paper, or other non-data resource  \n\n=== Repository Prefixes (Always DATA) ===\nDOIs starting with:\n  • 10.5061 (Dryad)  \n  • 10.5281 (Zenodo)  \n  • 10.6084 (Figshare)  \n  • 10.24433/ (Mendeley Data)  \n  • 10.17632 (Mendeley Data)  \n\nAccession numbers:\n  • SRA/E- (e.g. SRP, SRA, ERR, DRR)  \n  • PRJNA, PRJEB, PRJDB (NCBI BioProject)  \n  • SAMN, SAMEA, SAMD (BioSample)\n  • GSE, GDS, GPL, GSM (GEO)\n  • PXD (PRIDE Proteomics)  \n  • E-MTAB, E-GEOD, E-PROT (ArrayExpress)\n  • CHEMBL (ChEMBL)\n  • EMPIAR (Electron Microscopy)\n  • EPI_ISL, EPI (GISAID)\n  • HPA (Human Protein Atlas)\n  • CP (Cell Painting)\n  • IPR, PF (InterPro/Pfam)\n  • KX, K0 (KEGG)\n\n=== Publisher DOIs (Usually LITERATURE) ===\n  • 10.1038, 10.1126, 10.1016, 10.1007, 10.1101, 10.1371, 10.1073, etc.\n\n=== Few-Shot Examples ===\n1) \"Raw images are stored on Figshare (DOI 10.6084/m9.figshare.1234567).\" → A  \n2) \"Sequence reads available under BioProject accession PRJNA765432.\" → A  \n3) \"As described in Nature Methods (DOI 10.1038/s41592-020-0793-2).\" → B  \n4) \"See Supplementary Data at Zenodo (10.5281/zenodo.987654).\" → A  \n5) \"Method details published in J. Proteome Res. DOI: 10.1021/acs.jproteome.0c00845.\" → B  \n6) \"Data has been uploaded to Dryad (10.5061/dryad.x1y2z3).\" → A  \n7) \"Referenced paper: DOI 10.1101/2020.01.01.123456 (bioRxiv preprint).\" → B  \n8) \"Metabolomics data in MetaboLights MTBLS1234.\" → A  \n9) \"RNA-seq data deposited in GEO under accession GSE123456.\" → A\n10) \"Protein sequences from CHEMBL4567890 were analyzed.\" → A\n11) \"Sample metadata available as SAMN12345678.\" → A\n\n=== Instructions ===\n- Use both the identifier and its surrounding context.  \n- If the identifier matches known data repository patterns above, choose A.  \n- If it's a publisher DOI (journal article), choose B.  \n- Look for context clues: \"deposited\", \"uploaded\", \"archived\", \"available at\" → likely A\n- Look for context clues: \"described in\", \"published in\", \"see methods\" → likely B\n- Output exactly one letter: A or B, and nothing else.\n\"\"\".strip()\n\ndef build_df():\n    \"\"\"Load extracted data and separate DOIs from accession numbers, but process both\"\"\"\n    df = pl.read_parquet('/tmp/extracted.parquet')\n    \n    # Separate but don't filter - we'll process both types\n    accession_df = df.filter(~is_doi_link('dataset_id'))\n    doi_df = df.filter(is_doi_link('dataset_id'))\n    \n    # Still write accession subset for backwards compatibility if needed\n    accession_df.select('article_id', 'dataset_id').write_csv('/tmp/accid_sub.csv')\n    \n    # Return the full dataframe for LLM processing\n    return df\n\ndef build_prompt(tokenizer, df):\n    \"\"\"Build prompts for both DOIs and accession numbers\"\"\"\n    prompts = []\n    for dataset_id, text in df.select('dataset_id', 'window').rows():\n        # Enhanced context for the prompt\n        enhanced_text = f\"Text snippet: {text}\\n\\nIdentifier to classify: {dataset_id}\"\n        messages = [\n            {'role': 'system', 'content': SYS_PROMPT_CLASSIFY_ALL}, \n            {'role': 'user', 'content': enhanced_text}\n        ]\n        prompts.append(tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False, enable_thinking=False))\n    return df.with_columns(pl.Series('prompt', prompts))\n\nif __name__=='__main__':\n    os.environ[\"VLLM_USE_V1\"] = \"0\"\n    import vllm\n    from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n    \n    model_path = \"/kaggle/input/qwen-3/transformers/32b-awq/1\"\n    llm = vllm.LLM(model_path, quantization='awq', tensor_parallel_size=2, gpu_memory_utilization=0.9, trust_remote_code=True, dtype=\"half\", enforce_eager=True, max_model_len=2048, disable_log_stats=True, disable_custom_all_reduce=True, enable_prefix_caching=True, task='generate')\n    tokenizer = llm.get_tokenizer()\n    \n    # Process ALL identifiers (both DOIs and accession numbers)\n    df = build_df()\n    df = build_prompt(tokenizer, df)\n    prompts = df['prompt'].to_list()\n    \n    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=[\"A\", \"B\"])\n    outputs = llm.generate(prompts, vllm.SamplingParams(seed=777, temperature=0.1, skip_special_tokens=True, max_tokens=1, logits_processors=[mclp], logprobs=len(mclp.choices)), use_tqdm=True)\n    \n    logprobs = [{lp.decoded_token: lp.logprob for lp in list(lps)} for lps in [output.outputs[0].logprobs[0].values() for output in outputs]]\n    pred_letters = [max(lpdict, key=lpdict.get) for lpdict in logprobs]  # \"A\" or \"B\"\n    type_llm = [True if p == \"A\" else False for p in pred_letters]\n    \n    # Add all columns to your dataframe\n    df = df.with_columns([\n        pl.Series('type_llm', type_llm),\n        pl.Series('logprob_A', [d.get(\"A\", float('-inf')) for d in logprobs]),\n        pl.Series('logprob_B', [d.get(\"B\", float('-inf')) for d in logprobs]),\n        pl.Series('pred_letter', pred_letters)\n    ])\n    \n    # Save full result for hybrid work (now includes both DOIs and accessions)\n    df.select(['article_id', 'dataset_id', 'type_llm', 'logprob_A', 'logprob_B']).write_csv('/kaggle/working/submission_llm_logprobs.csv')\n\n    # Filter for data predictions (A)\n    choices = [max(d, key=d.get) for d in logprobs]\n    types = {'A': True, 'B': False}\n    choices = [types[c] for c in choices]\n    df = df.with_columns(pl.Series('type', choices))\n    \n    # Get all data predictions (both DOIs and accessions)\n    data_predictions = df.filter(pl.col('type'))\n    \n    # Apply type classification and write final submission\n    df_final = assume_type(data_predictions)\n    df_final.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n    \n    # Evaluation (if not submission)\n    if not IS_KAGGLE_SUBMISSION:\n        results = evaluate(df_final)\n        for r in results: l.info(r) \n        results = evaluate(df_final, on=['article_id', 'dataset_id', 'type'])\n        for r in results: l.info(r)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:56.290974Z","iopub.execute_input":"2025-08-03T01:27:56.291190Z","iopub.status.idle":"2025-08-03T01:27:56.305247Z","shell.execute_reply.started":"2025-08-03T01:27:56.291164Z","shell.execute_reply":"2025-08-03T01:27:56.304600Z"}},"outputs":[{"name":"stdout","text":"Writing /tmp/src/llm_validate.py\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"%%writefile /tmp/src/llm_validate-bak.py\nimport polars as pl\nimport os\n\nfrom helpers import *\n\nl = get_logger()\n\nSYS_PROMPT_CLASSIFY_DOI = \"\"\"\nYou are a highly accurate DOI/type classifier. Given a snippet of academic text containing a DOI or accession, choose:\n\n  A) Data — the identifier points directly to research data in a repository  \n  B) Literature — the identifier points to a journal article, book chapter, protocol paper, or other non-data resource  \n\n=== Repository Prefixes ===\nTreat as DATA if the DOI starts with any of:\n  • 10.5061 (Dryad)  \n  • 10.5281 (Zenodo)  \n  • 10.6084 (Figshare)  \n  • 10.24433/ (Mendeley Data)  \n  • 10.17632 (Mendeley Data)  \n  • SRA/E- (e.g. SRP, SRA)  \n  • PRJNA, PRJEB, PRJDB (NCBI BioProject)  \n  • PRIDE:PXD (Proteomics)  \n  • EMBL:E-MTAB, E- (ArrayExpress)  \n\nEverything else is LITERATURE unless you see explicit data-repository context (e.g. “deposited in Dryad under DOI…”).\n\n=== Few-Shot Examples ===\n1) “Raw images are stored on Figshare (DOI 10.6084/m9.figshare.1234567).” → A  \n2) “Sequence reads available under BioProject accession PRJNA765432.” → A  \n3) “As described in Nature Methods (DOI 10.1038/s41592-020-0793-2).” → B  \n4) “See Supplementary Data at Zenodo (10.5281/zenodo.987654).” → A  \n5) “Method details published in J. Proteome Res. DOI: 10.1021/acs.jproteome.0c00845.” → B  \n6) “Data has been uploaded to Dryad (10.5061/dryad.x1y2z3).” → A  \n7) “Referenced paper: DOI 10.1101/2020.01.01.123456 (bioRxiv preprint).” → B  \n8) “Metabolomics data in MetaboLights MTBLS1234.” → A  \n\n=== Instructions ===\n- Use only the identifier itself and its context.  \n- If the DOI prefix is in the list above, always choose A.  \n- If it belongs to a known publisher prefix (e.g. 10.1007, 10.1038, 10.1126, 10.1016…), choose B.  \n- Otherwise, rely on context words (“deposited”, “uploaded”, “archived”) to decide.  \n- Output exactly one letter: A or B, and nothing else.\n\"\"\".strip()\n\ndef build_df():\n    df = pl.read_parquet('/tmp/extracted.parquet')\n    df.filter(~is_doi_link('dataset_id')).select('article_id', 'dataset_id').write_csv('/tmp/accid_sub.csv')\n    return df.filter(is_doi_link('dataset_id'))\n\ndef build_prompt(tokenizer, df):\n    prompts = []\n    for doi, text in df.select('dataset_id', 'window').rows():\n        messages = [{'role':'system','content': SYS_PROMPT_CLASSIFY_DOI}, {'role':'user', 'content': text}]\n        prompts.append(tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False, enable_thinking=False))\n    return df.with_columns(pl.Series('prompt', prompts))\n\nif __name__=='__main__':\n    os.environ[\"VLLM_USE_V1\"] = \"0\"\n    import vllm\n    from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n    model_path = \"/kaggle/input/qwen-3/transformers/32b-awq/1\"\n    llm = vllm.LLM(model_path, quantization='awq', tensor_parallel_size=2, gpu_memory_utilization=0.9, trust_remote_code=True, dtype=\"half\", enforce_eager=True, max_model_len=2048, disable_log_stats=True, disable_custom_all_reduce=True, enable_prefix_caching=True, task='generate')\n    tokenizer = llm.get_tokenizer()\n    df = build_df()\n    df = build_prompt(tokenizer, df)\n    prompts = df['prompt'].to_list()\n    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=[\"A\", \"B\"])\n    outputs = llm.generate(prompts, vllm.SamplingParams(seed=777, temperature=0.1, skip_special_tokens=True, max_tokens=1, logits_processors=[mclp], logprobs=len(mclp.choices)), use_tqdm=True)\n    logprobs = [{lp.decoded_token: lp.logprob for lp in list(lps)} for lps in [output.outputs[0].logprobs[0].values() for output in outputs]]\n    pred_letters = [max(lpdict, key=lpdict.get) for lpdict in logprobs]  # \"A\" or \"B\"\n    type_llm = [True if p == \"A\" else False for p in pred_letters]\n    \n    # Add all columns to your dataframe\n    df = df.with_columns([\n        pl.Series('type_llm', type_llm),\n        pl.Series('logprob_A', [d.get(\"A\", float('-inf')) for d in logprobs]),\n        pl.Series('logprob_B', [d.get(\"B\", float('-inf')) for d in logprobs]),\n        pl.Series('pred_letter', pred_letters)\n    ])\n    \n    # Save full result for hybrid work\n    df.select(['article_id', 'dataset_id', 'type_llm', 'logprob_A', 'logprob_B']).write_csv('/kaggle/working/submission_llm_logprobs.csv')\n\n    choices = [max(d, key=d.get) for d in logprobs]\n    types = {'A': True, 'B': False}\n    choices = [types[c] for c in choices]\n    df = df.with_columns(pl.Series('type', choices))\n    df.filter(pl.col('type')).select('article_id', 'dataset_id').write_csv('/tmp/doi_sub.csv')\n    df = pl.concat([pl.read_csv('/tmp/doi_sub.csv'), pl.read_csv('/tmp/accid_sub.csv')])\n    df = assume_type(df)\n    df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n    if not IS_KAGGLE_SUBMISSION:\n        results = evaluate(df)\n        for r in results: l.info(r) \n        results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n        for r in results: l.info(r)","metadata":{"_cell_guid":"af30506a-e45e-4a3b-ba81-23dd154bde8d","_uuid":"94fc4779-0b43-4058-ac64-f54a7ebd8a76","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.015638,"end_time":"2025-07-24T17:47:46.18236","exception":false,"start_time":"2025-07-24T17:47:46.166722","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:56.308161Z","iopub.execute_input":"2025-08-03T01:27:56.308740Z","iopub.status.idle":"2025-08-03T01:27:56.319689Z","shell.execute_reply.started":"2025-08-03T01:27:56.308721Z","shell.execute_reply":"2025-08-03T01:27:56.319109Z"}},"outputs":[{"name":"stdout","text":"Writing /tmp/src/llm_validate-bak.py\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"%%writefile /tmp/src/post_filter.py\nimport polars as pl\nfrom helpers import *\n\n\"\"\"\nFourth essence: Post-filter to cut FP DOIs that look like literature.\n- Read /kaggle/working/submission.csv (output of llm_validate.py)\n- Join with /tmp/extracted.parquet to get context window\n- Drop DOI rows that (1) start with typical publisher prefixes AND (2) have no data-ish words nearby\n- Keep accessions untouched\n\"\"\"\n\nl = get_logger()\n\nPAPER_PREFIXES = [\n    \"10.1007\", \"10.1002\", \"10.1016\", \"10.1021\", \"10.1038\", \"10.1056\",\n    \"10.1073\", \"10.1080\", \"10.1093\", \"10.1101\", \"10.1186\", \"10.1371\",\n    \"10.1111\", \"10.5194\", \"10.3390\", \"10.1126\"\n]\n\nCONTEXT_RE = r\"(?i)\\b(data(?:set)?|repository|archive|deposited|available|supplementary|raw(?:\\s+data)?|uploaded|hosted|stored|accession)\\b\"\n\ndef is_paper_prefix(col: str = \"dataset_id\") -> pl.Expr:\n    expr = pl.lit(False)\n    for p in PAPER_PREFIXES:\n        expr = expr | pl.col(col).str.starts_with(f\"{DOI_LINK}{p}\")\n    return expr\n\ndef main():\n    sub = pl.read_csv(\"/kaggle/working/submission.csv\")\n\n    # Normalize columns: drop row_id if present so concat widths match\n    if \"row_id\" in sub.columns:\n        sub = sub.drop(\"row_id\")\n\n    # Context windows\n    win = pl.read_parquet(\"/tmp/extracted.parquet\").select(\"article_id\", \"dataset_id\", \"window\")\n\n    # DOI & ACC split\n    doi_rows = sub.filter(is_doi_link(\"dataset_id\")).join(win, on=[\"article_id\", \"dataset_id\"], how=\"left\")\n    acc_rows = sub.filter(~is_doi_link(\"dataset_id\"))\n\n    keep_mask = (\n        (~is_paper_prefix(\"dataset_id\"))  # not a known paper prefix\n        | doi_rows[\"window\"].fill_null(\"\").str.contains(CONTEXT_RE)\n    )\n\n    kept_doi = doi_rows.filter(keep_mask).select(\"article_id\", \"dataset_id\", \"type\")\n    final = pl.concat([kept_doi, acc_rows.select(\"article_id\", \"dataset_id\", \"type\")])\n\n    # Re-eval & save\n    if not IS_KAGGLE_SUBMISSION:\n        for r in evaluate(final): l.info(r)\n        for r in evaluate(final, on=[\"article_id\", \"dataset_id\", \"type\"]): l.info(r)\n\n    final.with_row_index(\"row_id\").write_csv(\"/kaggle/working/submission.csv\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"papermill":{"duration":0.015034,"end_time":"2025-07-24T17:47:46.205766","exception":false,"start_time":"2025-07-24T17:47:46.190732","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:56.320341Z","iopub.execute_input":"2025-08-03T01:27:56.320543Z","iopub.status.idle":"2025-08-03T01:27:56.333713Z","shell.execute_reply.started":"2025-08-03T01:27:56.320528Z","shell.execute_reply":"2025-08-03T01:27:56.333145Z"}},"outputs":[{"name":"stdout","text":"Writing /tmp/src/post_filter.py\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"%%writefile /tmp/src/post_filter_scibert.py\nimport polars as pl\nfrom helpers import *\n\n\"\"\"\nFourth essence: Post-filter to cut FP DOIs that look like literature.\n- Read /kaggle/working/submission.csv (output of llm_validate.py)\n- Join with /tmp/extracted.parquet to get context window\n- Drop DOI rows that (1) start with typical publisher prefixes AND (2) have no data-ish words nearby\n- Keep accessions untouched\n\"\"\"\n\nl = get_logger()\n\nPAPER_PREFIXES = [\n    \"10.1007\", \"10.1002\", \"10.1016\", \"10.1021\", \"10.1038\", \"10.1056\",\n    \"10.1073\", \"10.1080\", \"10.1093\", \"10.1101\", \"10.1186\", \"10.1371\",\n    \"10.1111\", \"10.5194\", \"10.3390\", \"10.1126\"\n]\n\nCONTEXT_RE = r\"(?i)\\b(data(?:set)?|repository|archive|deposited|available|supplementary|raw(?:\\s+data)?|uploaded|hosted|stored|accession)\\b\"\n\ndef is_paper_prefix(col: str = \"dataset_id\") -> pl.Expr:\n    expr = pl.lit(False)\n    for p in PAPER_PREFIXES:\n        expr = expr | pl.col(col).str.starts_with(f\"{DOI_LINK}{p}\")\n    return expr\n\ndef main():\n    sub = pl.read_csv(\"/kaggle/working/submission.csv\")\n\n    # Normalize columns: drop row_id if present so concat widths match\n    if \"row_id\" in sub.columns:\n        sub = sub.drop(\"row_id\")\n\n    # Context windows\n    win = pl.read_parquet(\"/tmp/scibert_predictions.parquet\").select(\"article_id\", \"dataset_id\", \"window\",'r_type')\n\n    # DOI & ACC split\n    doi_rows = sub.filter(is_doi_link(\"dataset_id\")).join(win, on=[\"article_id\", \"dataset_id\"], how=\"left\")\n    acc_rows = sub.filter(~is_doi_link(\"dataset_id\"))\n\n    keep_mask = (\n        (~is_paper_prefix(\"dataset_id\"))  # not a known paper prefix\n        | doi_rows[\"window\"].fill_null(\"\").str.contains(CONTEXT_RE)\n    )\n\n    kept_doi = doi_rows.filter(keep_mask).select(\"article_id\", \"dataset_id\", \"r_type\", 'type')\n    acc_rows = acc_rows.join(win, on=[\"article_id\", \"dataset_id\"], how=\"left\")\n    final = pl.concat([kept_doi, acc_rows.select(\"article_id\", \"dataset_id\", \"r_type\", 'type')])\n    \n    # Replace 'type' with 'r_type' for submission\n    final = final.drop(\"type\").rename({\"r_type\": \"type\"})\n    \n    # Re-eval & save\n    if not IS_KAGGLE_SUBMISSION:\n        for r in evaluate(final): l.info(r)\n        for r in evaluate(final, on=[\"article_id\", \"dataset_id\", \"type\"]): l.info(r)\n    \n    final.with_row_index(\"row_id\").write_csv(\"/kaggle/working/submission_scibert.csv\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:56.334498Z","iopub.execute_input":"2025-08-03T01:27:56.334703Z","iopub.status.idle":"2025-08-03T01:27:56.346135Z","shell.execute_reply.started":"2025-08-03T01:27:56.334683Z","shell.execute_reply":"2025-08-03T01:27:56.345626Z"}},"outputs":[{"name":"stdout","text":"Writing /tmp/src/post_filter_scibert.py\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"%cd /tmp\n! LOG_LEVEL=INFO python src/parse.py /tmp/train_parse\n! python src/check_parse.py","metadata":{"_cell_guid":"c6a12705-737a-4b21-9bf2-125b3d1ab724","_kg_hide-output":true,"_uuid":"bc8e0d68-3097-4ce9-99a1-536921913550","papermill":{"duration":456.328258,"end_time":"2025-07-24T17:55:22.542564","exception":false,"start_time":"2025-07-24T17:47:46.214306","status":"completed"},"scrolled":true,"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:27:56.346762Z","iopub.execute_input":"2025-08-03T01:27:56.346974Z","iopub.status.idle":"2025-08-03T01:29:21.378764Z","shell.execute_reply.started":"2025-08-03T01:27:56.346959Z","shell.execute_reply":"2025-08-03T01:29:21.378022Z"}},"outputs":[{"name":"stdout","text":"/tmp\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nINFO 2025-08-03 01:29:21  [check_parse.py:31 - main()] pymupdf misses: 42 dataset_ids\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"! python src/getid.py","metadata":{"_cell_guid":"c6a12705-737a-4b21-9bf2-125b3d1ab724","_kg_hide-output":true,"_uuid":"bc8e0d68-3097-4ce9-99a1-536921913550","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":456.328258,"end_time":"2025-07-24T17:55:22.542564","exception":false,"start_time":"2025-07-24T17:47:46.214306","status":"completed"},"scrolled":true,"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:29:21.379811Z","iopub.execute_input":"2025-08-03T01:29:21.380031Z","iopub.status.idle":"2025-08-03T01:29:30.636416Z","shell.execute_reply.started":"2025-08-03T01:29:21.380009Z","shell.execute_reply":"2025-08-03T01:29:30.635268Z"}},"outputs":[{"name":"stdout","text":"INFO 2025-08-03 01:29:30  [getid.py:192 - main()] all - f1: 0.5341 [486/615/233]\nINFO 2025-08-03 01:29:30  [getid.py:192 - main()] doi - f1: 0.4344 [164/266/161]\nINFO 2025-08-03 01:29:30  [getid.py:192 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-08-03 01:29:30  [getid.py:194 - main()] all - f1: 0.4429 [403/698/316]\nINFO 2025-08-03 01:29:30  [getid.py:194 - main()] doi - f1: 0.3338 [126/304/199]\nINFO 2025-08-03 01:29:30  [getid.py:194 - main()] acc - f1: 0.5202 [277/394/117]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"%%writefile /tmp/src/SciBert_train.py\nimport pandas as pd\nimport torch\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, classification_report\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    Trainer,\n    TrainingArguments,\n    TrainerCallback,\n    EarlyStoppingCallback\n)\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n# Load data from parquet and CSV\nextracted_df = pd.read_parquet(\"/tmp/extracted.parquet\")\nlabels_df = pd.read_csv(\"/kaggle/input/make-data-count-finding-data-references/train_labels.csv\")\n\n# Normalize keys for join\nlabels_df[\"article_id\"] = labels_df[\"article_id\"].str.replace(\"/\", \"_\")\nlabels_df[\"dataset_id\"] = labels_df[\"dataset_id\"].str.lower()\n\nextracted_df[\"dataset_id\"] = extracted_df[\"dataset_id\"].str.lower()\n\n# Merge and drop rows without labels\ndf = extracted_df.merge(labels_df, on=[\"article_id\", \"dataset_id\"], how=\"inner\")\ndf = df.dropna(subset=[\"window\", \"type\"])\n\n# Label encoding\ntype_to_label = {\"Primary\": 0, \"Secondary\": 1} #, \"Missing\": 2}\ndf[\"label\"] = df[\"type\"].map(type_to_label)\n\n# Train/val split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    df[\"window\"].tolist(),\n    df[\"label\"].tolist(),\n    test_size=0.2,\n    stratify=df[\"label\"],\n    random_state=42\n)\n\n# Tokenization\nmodel_name = \"allenai/scibert_scivocab_uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n\n# Dataset wrapper\nclass DataRelationDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n        item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = DataRelationDataset(train_encodings, train_labels)\nval_dataset = DataRelationDataset(val_encodings, val_labels)\n\n# Model\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, \n                                                           hidden_dropout_prob=0.3,      # Default is usually 0.1\n                                                           attention_probs_dropout_prob=0.3,  # Default is usually 0.1\n)\n\n# Metrics\ndef compute_metrics(p):    \n    preds = p.predictions.argmax(-1)\n    f1_micro = f1_score(p.label_ids, preds, average='micro')\n    f1_macro = f1_score(p.label_ids, preds, average='macro')\n    report = classification_report(p.label_ids, preds, output_dict=True, zero_division=0)\n\n    def safe_f1(class_label):\n        return report[str(class_label)][\"f1-score\"] if str(class_label) in report else 0.0\n\n    return {\n        \"f1_micro\": f1_micro,\n        \"f1_macro\": f1_macro,\n        \"f1_primary\": safe_f1(0),\n        \"f1_secondary\": safe_f1(1),\n        \"f1_missing\": safe_f1(2)\n    }\n\n# Training setup\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/results\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=101,\n    learning_rate=.5e-5,\n    weight_decay=0.15, # Increase from 0.01 to 0.1 or even 0.2\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_f1_macro\",\n    greater_is_better=True,\n    save_total_limit = 4,\n    fp16=True\n)\n\nclass PrintDevicesCallback(TrainerCallback):\n    def on_train_begin(self, args, state, control, **kwargs):\n        print(f\"Training on {torch.cuda.device_count()} GPUs:\", [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())])\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\n# Train\ntrainer.train()\nmodel.save_pretrained(\"/kaggle/working/best_model\")\ntokenizer.save_pretrained(\"/kaggle/working/best_model\")\n! zip -r /kaggle/working/output-tbt-2L.zip /kaggle/working/best_model\n! cd /kaggle/working\nfrom IPython.display import FileLink\nFileLink(r'output-tbt-2L.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:29:30.637820Z","iopub.execute_input":"2025-08-03T01:29:30.638239Z","iopub.status.idle":"2025-08-03T01:29:30.646720Z","shell.execute_reply.started":"2025-08-03T01:29:30.638205Z","shell.execute_reply":"2025-08-03T01:29:30.644982Z"}},"outputs":[{"name":"stdout","text":"Writing /tmp/src/SciBert_train.py\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# %%writefile /tmp/src/SciBert_infer.py\nfrom tqdm import tqdm\nimport pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n# 🧠 Load model and tokenizer\nmodel_path = \"/kaggle/input/btb-2l-scibert/kaggle/working/best_model\"\ntoken_path = model_path\n\ntokenizer = AutoTokenizer.from_pretrained(token_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# 🔮 Predict type\nlabel_map = {0: \"Primary\", 1: \"Secondary\",} # 2: 'Missing'}\nbatch_size = 8\npreds = []\nrows = pd.read_parquet(\"/tmp/extracted.parquet\")\n\n# Drop NA windows\nrows = rows.dropna(subset=[\"window\"]).reset_index(drop=True)\n\nlogits_list = []\n\nfor i in tqdm(range(0, len(rows), batch_size)):\n    batch_texts = rows[\"window\"].iloc[i:i+batch_size].tolist()\n    enc = tokenizer(batch_texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        logits = model(**enc).logits\n        p = torch.argmax(logits, dim=1).cpu().tolist()\n        preds.extend(p)\n        logits_list.extend(logits.cpu().tolist())\n\n\nlogits_df = pd.DataFrame(logits_list, columns=[\"logit_primary\", \"logit_secondary\"])\nrows = pd.concat([rows.reset_index(drop=True), logits_df], axis=1)\nlabel_map = {0: \"Primary\", 1: \"Secondary\"}\n\n# preds is a list of ints from argmax\nrows[\"pred_label\"] = [label_map[p] for p in preds]\n\n# Then export\nrows[[\"article_id\", \"dataset_id\", \"pred_label\", \"logit_primary\", \"logit_secondary\"]].to_csv(\n    \"/kaggle/working/submission_scibert_logits.csv\", index=False\n)\nrows[[\"article_id\", \"dataset_id\", \"pred_label\", \"logit_primary\", \"logit_secondary\"]].to_csv(\"/kaggle/working/submission_scibert_logits.csv\", index=False)\nrows[\"r_type\"] = [label_map.get(p, \"Missing\") for p in preds]\nrows[[\"article_id\", \"dataset_id\", 'window',\"r_type\"]].to_parquet(\"/tmp/scibert_predictions.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:29:30.647648Z","iopub.execute_input":"2025-08-03T01:29:30.648526Z","iopub.status.idle":"2025-08-03T01:30:04.703081Z","shell.execute_reply.started":"2025-08-03T01:29:30.648499Z","shell.execute_reply":"2025-08-03T01:30:04.702240Z"}},"outputs":[{"name":"stderr","text":"2025-08-03 01:29:44.667879: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754184584.843780      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754184584.893176      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n100%|██████████| 138/138 [00:06<00:00, 21.73it/s]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"! python src/post_filter_scibert.py\n#! rm /kaggle/working/submission.csv\n#! mv /kaggle/working/submission_scibert.csv /kaggle/working/submission.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:30:04.704063Z","iopub.execute_input":"2025-08-03T01:30:04.704843Z","iopub.status.idle":"2025-08-03T01:30:07.090830Z","shell.execute_reply.started":"2025-08-03T01:30:04.704814Z","shell.execute_reply":"2025-08-03T01:30:07.090080Z"}},"outputs":[{"name":"stdout","text":"INFO 2025-08-03 01:30:06  [post_filter_scibert.py:56 - main()] all - f1: 0.5668 [486/510/233]\nINFO 2025-08-03 01:30:06  [post_filter_scibert.py:56 - main()] doi - f1: 0.5046 [164/161/161]\nINFO 2025-08-03 01:30:06  [post_filter_scibert.py:56 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-08-03 01:30:06  [post_filter_scibert.py:57 - main()] all - f1: 0.5411 [464/532/255]\nINFO 2025-08-03 01:30:06  [post_filter_scibert.py:57 - main()] doi - f1: 0.4769 [155/170/170]\nINFO 2025-08-03 01:30:06  [post_filter_scibert.py:57 - main()] acc - f1: 0.5803 [309/362/85]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"#! python src/addon_fix_broken_dois.py\n#! python src/addon_reference_priority.py\n#! python src/merge_augmented_ids.py  # or insert the merging logic inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:30:07.091800Z","iopub.execute_input":"2025-08-03T01:30:07.092016Z","iopub.status.idle":"2025-08-03T01:30:07.095782Z","shell.execute_reply.started":"2025-08-03T01:30:07.091993Z","shell.execute_reply":"2025-08-03T01:30:07.095083Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"! python src/llm_validate.py\n! python src/post_filter.py","metadata":{"_cell_guid":"c6a12705-737a-4b21-9bf2-125b3d1ab724","_kg_hide-output":true,"_uuid":"bc8e0d68-3097-4ce9-99a1-536921913550","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":456.328258,"end_time":"2025-07-24T17:55:22.542564","exception":false,"start_time":"2025-07-24T17:47:46.214306","status":"completed"},"scrolled":true,"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:30:07.096833Z","iopub.execute_input":"2025-08-03T01:30:07.097098Z","iopub.status.idle":"2025-08-03T01:39:49.055832Z","shell.execute_reply.started":"2025-08-03T01:30:07.097074Z","shell.execute_reply":"2025-08-03T01:39:49.054815Z"}},"outputs":[{"name":"stdout","text":"2025-08-03 01:30:14.600845: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754184614.622491     237 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754184614.629156     237 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 08-03 01:30:18 [__init__.py:244] Automatically detected platform cuda.\nINFO 08-03 01:30:35 [config.py:1472] Using max model len 2048\nWARNING 08-03 01:30:35 [config.py:960] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\nWARNING 08-03 01:30:36 [cuda.py:102] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\nINFO 08-03 01:30:36 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.2) with config: model='/kaggle/input/qwen-3/transformers/32b-awq/1', speculative_config=None, tokenizer='/kaggle/input/qwen-3/transformers/32b-awq/1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=awq, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='xgrammar', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/kaggle/input/qwen-3/transformers/32b-awq/1, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":0,\"local_cache_dir\":null}, use_cached_outputs=False, \nWARNING 08-03 01:30:37 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 2 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n\u001b[1;36m(VllmWorkerProcess pid=265)\u001b[0;0m INFO 08-03 01:30:37 [multiproc_worker_utils.py:226] Worker ready; awaiting tasks\nINFO 08-03 01:30:37 [cuda.py:311] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\nINFO 08-03 01:30:37 [cuda.py:360] Using XFormers backend.\n\u001b[1;36m(VllmWorkerProcess pid=265)\u001b[0;0m INFO 08-03 01:30:37 [cuda.py:311] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n\u001b[1;36m(VllmWorkerProcess pid=265)\u001b[0;0m INFO 08-03 01:30:37 [cuda.py:360] Using XFormers backend.\n[W803 01:30:48.088947078 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W803 01:30:49.605103828 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W803 01:30:58.099530650 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W803 01:31:08.109881877 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\nINFO 08-03 01:31:08 [__init__.py:1152] Found nccl from library libnccl.so.2\n\u001b[1;36m(VllmWorkerProcess pid=265)\u001b[0;0m INFO 08-03 01:31:08 [__init__.py:1152] Found nccl from library libnccl.so.2\nINFO 08-03 01:31:08 [pynccl.py:70] vLLM is using nccl==2.26.2\n\u001b[1;36m(VllmWorkerProcess pid=265)\u001b[0;0m INFO 08-03 01:31:08 [pynccl.py:70] vLLM is using nccl==2.26.2\nINFO 08-03 01:31:09 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_46b70cb7'), local_subscribe_addr='ipc:///tmp/b6af975f-29dd-49d2-abcb-e7e736a723c4', remote_subscribe_addr=None, remote_addr_ipv6=False)\nINFO 08-03 01:31:09 [parallel_state.py:1076] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n\u001b[1;36m(VllmWorkerProcess pid=265)\u001b[0;0m INFO 08-03 01:31:09 [parallel_state.py:1076] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\nINFO 08-03 01:31:09 [model_runner.py:1171] Starting to load model /kaggle/input/qwen-3/transformers/32b-awq/1...\n\u001b[1;36m(VllmWorkerProcess pid=265)\u001b[0;0m INFO 08-03 01:31:09 [model_runner.py:1171] Starting to load model /kaggle/input/qwen-3/transformers/32b-awq/1...\nLoading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\nLoading safetensors checkpoint shards:  25% Completed | 1/4 [00:49<02:28, 49.46s/it]\nLoading safetensors checkpoint shards:  50% Completed | 2/4 [01:35<01:34, 47.28s/it]\nLoading safetensors checkpoint shards:  75% Completed | 3/4 [02:13<00:43, 43.34s/it]\nLoading safetensors checkpoint shards: 100% Completed | 4/4 [03:06<00:00, 47.11s/it]\nLoading safetensors checkpoint shards: 100% Completed | 4/4 [03:06<00:00, 46.69s/it]\n\n\u001b[1;36m(VllmWorkerProcess pid=265)\u001b[0;0m INFO 08-03 01:34:16 [default_loader.py:272] Loading weights took 186.39 seconds\nINFO 08-03 01:34:17 [default_loader.py:272] Loading weights took 187.16 seconds\n\u001b[1;36m(VllmWorkerProcess pid=265)\u001b[0;0m INFO 08-03 01:34:17 [model_runner.py:1203] Model loading took 9.0570 GiB and 186.745403 seconds\nINFO 08-03 01:34:17 [model_runner.py:1203] Model loading took 9.0570 GiB and 187.499868 seconds\n\u001b[1;36m(VllmWorkerProcess pid=265)\u001b[0;0m INFO 08-03 01:34:28 [worker.py:294] Memory profiling takes 10.36 seconds\n\u001b[1;36m(VllmWorkerProcess pid=265)\u001b[0;0m INFO 08-03 01:34:28 [worker.py:294] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.90) = 13.27GiB\n\u001b[1;36m(VllmWorkerProcess pid=265)\u001b[0;0m INFO 08-03 01:34:28 [worker.py:294] model weights take 9.06GiB; non_torch_memory takes 0.11GiB; PyTorch activation peak memory takes 0.41GiB; the rest of the memory reserved for KV Cache is 3.70GiB.\nINFO 08-03 01:34:28 [worker.py:294] Memory profiling takes 10.52 seconds\nINFO 08-03 01:34:28 [worker.py:294] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.90) = 13.27GiB\nINFO 08-03 01:34:28 [worker.py:294] model weights take 9.06GiB; non_torch_memory takes 0.11GiB; PyTorch activation peak memory takes 1.40GiB; the rest of the memory reserved for KV Cache is 2.70GiB.\nINFO 08-03 01:34:29 [executor_base.py:113] # cuda blocks: 1381, # CPU blocks: 2048\nINFO 08-03 01:34:29 [executor_base.py:118] Maximum concurrency for 2048 tokens per request: 10.79x\nINFO 08-03 01:34:33 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 15.49 seconds\nAdding requests: 100%|█████████████████████| 1101/1101 [00:02<00:00, 381.57it/s]\nProcessed prompts: 100%|█| 1101/1101 [05:02<00:00,  3.65it/s, est. speed input: \nINFO 2025-08-03 01:39:39  [llm_validate.py:137 - <module>()] all - f1: 0.5990 [478/399/241]\nINFO 2025-08-03 01:39:39  [llm_validate.py:137 - <module>()] doi - f1: 0.5836 [164/73/161]\nINFO 2025-08-03 01:39:39  [llm_validate.py:137 - <module>()] acc - f1: 0.6074 [314/326/80]\nINFO 2025-08-03 01:39:39  [llm_validate.py:139 - <module>()] all - f1: 0.4950 [395/482/324]\nINFO 2025-08-03 01:39:39  [llm_validate.py:139 - <module>()] doi - f1: 0.4484 [126/111/199]\nINFO 2025-08-03 01:39:39  [llm_validate.py:139 - <module>()] acc - f1: 0.5203 [269/371/125]\nINFO 08-03 01:39:40 [multiproc_worker_utils.py:125] Killing local vLLM worker processes\n[rank0]:[W803 01:39:41.279464997 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\nINFO 2025-08-03 01:39:48  [post_filter.py:52 - main()] all - f1: 0.5990 [478/399/241]\nINFO 2025-08-03 01:39:48  [post_filter.py:52 - main()] doi - f1: 0.5836 [164/73/161]\nINFO 2025-08-03 01:39:48  [post_filter.py:52 - main()] acc - f1: 0.6074 [314/326/80]\nINFO 2025-08-03 01:39:48  [post_filter.py:53 - main()] all - f1: 0.4950 [395/482/324]\nINFO 2025-08-03 01:39:48  [post_filter.py:53 - main()] doi - f1: 0.4484 [126/111/199]\nINFO 2025-08-03 01:39:48  [post_filter.py:53 - main()] acc - f1: 0.5203 [269/371/125]\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# %%writefile /tmp/src/HybridProbs.py\nimport pandas as pd\n\n# Load everything\ntruth = pd.read_csv(\"/kaggle/input/make-data-count-finding-data-references/train_labels.csv\")\ntruth = truth[truth[\"type\"] != \"Missing\"].copy()\nllm = pd.read_csv(\"/kaggle/working/submission_llm_logprobs.csv\").rename(columns={\"type\": \"type_llm\"})\nscibert = pd.read_csv(\"/kaggle/working/submission_scibert_logits.csv\").rename(columns={\"pred_label\": \"type_scibert\"})\n# Ensure no trailing slashes, lowercase, and consistent formats\ntruth[\"article_id\"] = truth[\"article_id\"].astype(str).str.strip()\ntruth[\"dataset_id\"] = truth[\"dataset_id\"].astype(str).str.strip().str.lower()\n\nllm[\"article_id\"] = llm[\"article_id\"].astype(str).str.strip()\nllm[\"dataset_id\"] = llm[\"dataset_id\"].astype(str).str.strip().str.lower()\n\nscibert[\"article_id\"] = scibert[\"article_id\"].astype(str).str.strip()\nscibert[\"dataset_id\"] = scibert[\"dataset_id\"].astype(str).str.strip().str.lower()\n\n# Merge\ndf = (\n    truth.rename(columns={\"type\": \"type_truth\"})\n    .merge(llm, on=[\"article_id\", \"dataset_id\"], how=\"left\")\n    .merge(scibert, on=[\"article_id\", \"dataset_id\"], how=\"left\")\n)\n\n# Save\ndf.to_csv(\"/kaggle/working/merged_predictions_with_confidence.csv\", index=False)\n\n# Preview\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:39:49.057068Z","iopub.execute_input":"2025-08-03T01:39:49.057326Z","iopub.status.idle":"2025-08-03T01:39:49.136991Z","shell.execute_reply.started":"2025-08-03T01:39:49.057301Z","shell.execute_reply":"2025-08-03T01:39:49.136367Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"             article_id                               dataset_id type_truth  \\\n0  10.1002_2017jc013030           https://doi.org/10.17882/49388    Primary   \n1     10.1002_ece3.4466    https://doi.org/10.5061/dryad.r6nq870    Primary   \n2     10.1002_ece3.5260    https://doi.org/10.5061/dryad.2f62927    Primary   \n3     10.1002_ece3.6144  https://doi.org/10.5061/dryad.zw3r22854    Primary   \n4     10.1002_ece3.6303  https://doi.org/10.5061/dryad.37pvmcvgb    Primary   \n\n  type_llm  logprob_A   logprob_B type_scibert  logit_primary  logit_secondary  \n0      NaN        NaN         NaN          NaN            NaN              NaN  \n1     True        0.0 -204.424896      Primary       2.372571        -1.902298  \n2     True        0.0 -199.736267      Primary       2.089813        -1.519837  \n3     True        0.0 -193.484772      Primary       2.192287        -1.654931  \n4     True        0.0 -190.984161      Primary       2.379811        -1.916411  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_id</th>\n      <th>dataset_id</th>\n      <th>type_truth</th>\n      <th>type_llm</th>\n      <th>logprob_A</th>\n      <th>logprob_B</th>\n      <th>type_scibert</th>\n      <th>logit_primary</th>\n      <th>logit_secondary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.1002_2017jc013030</td>\n      <td>https://doi.org/10.17882/49388</td>\n      <td>Primary</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.1002_ece3.4466</td>\n      <td>https://doi.org/10.5061/dryad.r6nq870</td>\n      <td>Primary</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>-204.424896</td>\n      <td>Primary</td>\n      <td>2.372571</td>\n      <td>-1.902298</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.1002_ece3.5260</td>\n      <td>https://doi.org/10.5061/dryad.2f62927</td>\n      <td>Primary</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>-199.736267</td>\n      <td>Primary</td>\n      <td>2.089813</td>\n      <td>-1.519837</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.1002_ece3.6144</td>\n      <td>https://doi.org/10.5061/dryad.zw3r22854</td>\n      <td>Primary</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>-193.484772</td>\n      <td>Primary</td>\n      <td>2.192287</td>\n      <td>-1.654931</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10.1002_ece3.6303</td>\n      <td>https://doi.org/10.5061/dryad.37pvmcvgb</td>\n      <td>Primary</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>-190.984161</td>\n      <td>Primary</td>\n      <td>2.379811</td>\n      <td>-1.916411</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"#! python src/HybridProbs.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:39:49.137712Z","iopub.execute_input":"2025-08-03T01:39:49.137988Z","iopub.status.idle":"2025-08-03T01:39:49.141415Z","shell.execute_reply.started":"2025-08-03T01:39:49.137966Z","shell.execute_reply":"2025-08-03T01:39:49.140707Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"#%%writefile /tmp/src/HybridProbsMerge.py\n\ntruth_keys = set(zip(truth[\"article_id\"], truth[\"dataset_id\"]))\nllm_keys = set(zip(llm[\"article_id\"], llm[\"dataset_id\"]))\nscibert_keys = set(zip(scibert[\"article_id\"], scibert[\"dataset_id\"]))\n\nprint(\"truth total:\", len(truth_keys))\nprint(\"truth ∩ llm:\", len(truth_keys & llm_keys))\nprint(\"truth ∩ scibert:\", len(truth_keys & scibert_keys))\nmissing_in_llm = truth_keys - llm_keys\nmissing_in_scibert = truth_keys - scibert_keys\n\nprint(\"Missing in LLM:\", list(missing_in_llm)[:5])\nprint(\"Missing in SciBERT:\", list(missing_in_scibert)[:5])\nimport numpy as np\n\ndef softmax_probs_llm(logA, logB):\n    logits = np.array([logA, logB])\n    probs = np.exp(logits - np.max(logits))  # logit-stabilized\n    probs /= probs.sum()\n    return probs[0], probs[1]  # P(A), P(B)\nllm_df = llm\nllm_df[\"llm_prob_A\"], llm_df[\"llm_prob_B\"] = zip(*llm_df.apply(\n    lambda row: softmax_probs_llm(row[\"logprob_A\"], row[\"logprob_B\"]),\n    axis=1\n))\nllm_df[\"llm_margin\"] = abs(llm_df[\"llm_prob_A\"] - llm_df[\"llm_prob_B\"])\nscibert_df = scibert.copy()\nimport numpy as np\n\ndef softmax_probs_scibert_2class(logit_primary, logit_secondary):\n    logits = np.array([logit_primary, logit_secondary])\n    exps = np.exp(logits - np.max(logits))  # for numerical stability\n    return exps / exps.sum()\n\n# Apply row-wise\nscibert_df[[\"scibert_Primary\", \"scibert_Secondary\"]] = scibert_df.apply(\n    lambda row: pd.Series(softmax_probs_scibert_2class(row[\"logit_primary\"], row[\"logit_secondary\"])),\n    axis=1\n)\n\n# Compute margin\nscibert_df[\"scibert_margin\"] = abs(scibert_df[\"scibert_Primary\"] - scibert_df[\"scibert_Secondary\"])\nmerged_df = df.copy()\nmerged_df = merged_df.merge(llm_df[[\"article_id\", \"dataset_id\", \"llm_prob_A\", \"llm_prob_B\", \"llm_margin\"]], on=[\"article_id\", \"dataset_id\"], how=\"left\")\nmerged_df = merged_df.merge(scibert_df[[\"article_id\", \"dataset_id\", \"scibert_Primary\", \"scibert_Secondary\", \"scibert_margin\"]], on=[\"article_id\", \"dataset_id\"], how=\"left\")\ndef choose_type(row):\n    if row[\"llm_margin\"] >= 0.6:\n        return row[\"type_llm\"]\n    elif row[\"scibert_margin\"] >= 0.3:\n        return row[\"type_scibert\"]\n    else:\n        return row[\"type_llm\"]  # fallback if both are unsure\nmerged_df[\"type_hybrid\"] = merged_df.apply(choose_type, axis=1)\n\n##### OR \ndef combine_probs(row, alpha=0.6):\n    # LLM is binary: A=Primary, B=Secondary\n    p_primary = alpha * row[\"llm_prob_A\"] + (1 - alpha) * row[\"scibert_Primary\"]\n    p_secondary = alpha * row[\"llm_prob_B\"] + (1 - alpha) * row[\"scibert_Secondary\"]\n    return \"Primary\" if p_primary > p_secondary else \"Secondary\"\n\n# merged_df[\"type_hybrid\"] = merged_df.apply(combine_probs, axis=1)\nmerged_df.to_csv(\"/kaggle/working/merged_predictions_with_confidence.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:39:49.142139Z","iopub.execute_input":"2025-08-03T01:39:49.142331Z","iopub.status.idle":"2025-08-03T01:39:49.316855Z","shell.execute_reply.started":"2025-08-03T01:39:49.142316Z","shell.execute_reply":"2025-08-03T01:39:49.316103Z"}},"outputs":[{"name":"stdout","text":"truth total: 719\ntruth ∩ llm: 486\ntruth ∩ scibert: 486\nMissing in LLM: [('10.1101_2022.02.10.480011', 'https://doi.org/10.15482/usda.adc/1524676'), ('10.3390_v11060565', 'd10700'), ('10.1371_journal.pone.0262974', '2nrj'), ('10.1145_3461702.3462538', 'https://doi.org/10.3886/icpsr25104.v1'), ('10.1136_jitc-2021-003114', 'cvcl_2213')]\nMissing in SciBERT: [('10.1101_2022.02.10.480011', 'https://doi.org/10.15482/usda.adc/1524676'), ('10.3390_v11060565', 'd10700'), ('10.1371_journal.pone.0262974', '2nrj'), ('10.1145_3461702.3462538', 'https://doi.org/10.3886/icpsr25104.v1'), ('10.1136_jitc-2021-003114', 'cvcl_2213')]\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"%%writefile /tmp/src/nn_train.py\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom tqdm import tqdm\n\n# Load inputs\nllm_df = pd.read_csv(\"/kaggle/working/submission_llm_logprobs.csv\")\nscibert_df = pd.read_csv(\"/kaggle/working/submission_scibert_logits.csv\")\nextracted_df = pd.read_parquet(\"/tmp/extracted.parquet\")\n\n# Merge and keep only non-Missing\ndf = (\n    extracted_df.merge(llm_df, on=[\"article_id\", \"dataset_id\"], how=\"left\")\n               .merge(scibert_df, on=[\"article_id\", \"dataset_id\"], how=\"left\")\n)\ndf = df[df[\"pred_label\"] != \"Missing\"].reset_index(drop=True)\n\n# 🔠 Sentence embeddings\nembedder = SentenceTransformer(\"/kaggle/input/all-minilm-l6-v2-and-deps/all-MiniLM-L6-v2/\")\nembed_window = embedder.encode(df[\"window\"].tolist(), batch_size=64, show_progress_bar=True)\nembed_dsid = embedder.encode(df[\"dataset_id\"].tolist(), batch_size=64, show_progress_bar=True)\n\n# 🔢 One-hot encoding of types\nllm_onehot = pd.get_dummies(df[\"type_llm\"], prefix=\"llm\")\nscibert_onehot = pd.get_dummies(df[\"pred_label\"], prefix=\"scibert\")\nllm_onehot = llm_onehot.reindex(columns=[\"llm_Primary\", \"llm_Secondary\"], fill_value=0)\nscibert_onehot = scibert_onehot.reindex(columns=[\"scibert_Primary\", \"scibert_Secondary\"], fill_value=0)\n\n# 🧠 Construct training matrix\nX = np.hstack([\n    embed_window,\n    embed_dsid,\n    df[[\"logit_primary\", \"logit_secondary\"]].values,\n    df[[\"logprob_A\", \"logprob_B\"]].values,\n    llm_onehot.values,\n    scibert_onehot.values\n])\n\n# 🎯 Labels (0=Primary, 1=Secondary)\nlabel_map = {\"Primary\": 0, \"Secondary\": 1}\ny = df[\"pred_label\"].map(label_map).values\n\n# 🧽 Normalize\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# 🔀 Train/val split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# 🧱 Dataset and dataloader\ntrain_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train))\nval_ds = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val))\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=64)\n\n# 🧠 Define model\nclass Classifier(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 2)\n        )\n    def forward(self, x):\n        return self.net(x)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Classifier(input_dim=X.shape[1]).to(device)\nopt = torch.optim.Adam(model.parameters(), lr=.5e-5)\nloss_fn = nn.CrossEntropyLoss()\n\n# 🔁 Training loop\nbest_f1 = 0.0\nfor epoch in range(1, 5000):\n    model.train()\n    for xb, yb in train_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        opt.zero_grad()\n        loss = loss_fn(model(xb), yb)\n        loss.backward()\n        opt.step()\n\n    model.eval()\n    preds, true = [], []\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device)\n            logits = model(xb)\n            p = torch.argmax(logits, dim=1).cpu().numpy()\n            preds.extend(p)\n            true.extend(yb.numpy())\n\n    f1 = f1_score(true, preds, average=\"macro\")\n    print(f\"Epoch {epoch+1}: Val F1_macro={f1:.4f}, Loss={loss.item():.3f}\")\n    if f1 > best_f1:\n        print(\"✅ New best model saved!\")\n        torch.save(model, \"/kaggle/working/best_embed_mlp.pt\")\n        best_f1 = f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, classification_report\nfrom tqdm import tqdm\nimport logging\nimport os\nfrom pathlib import Path\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef load_and_merge_data():\n    \"\"\"Load and merge all data sources\"\"\"\n    try:\n        llm_df = pd.read_csv(\"/kaggle/working/submission_llm_logprobs.csv\")\n        scibert_df = pd.read_csv(\"/kaggle/working/submission_scibert_logits.csv\")\n        extracted_df = pd.read_parquet(\"/tmp/extracted.parquet\")\n        \n        # Merge datasets\n        df = (\n            extracted_df.merge(llm_df, on=[\"article_id\", \"dataset_id\"], how=\"left\")\n                       .merge(scibert_df, on=[\"article_id\", \"dataset_id\"], how=\"left\")\n        )\n        \n        # Filter out Missing labels\n        df = df[df[\"pred_label\"] != \"Missing\"].reset_index(drop=True)\n        logger.info(f\"Loaded {len(df)} samples after filtering\")\n        \n        return df\n    except Exception as e:\n        logger.error(f\"Error loading data: {e}\")\n        raise\n\ndef create_embeddings(df, embedder_path=\"/kaggle/input/all-minilm-l6-v2-and-deps/all-MiniLM-L6-v2/\"):\n    \"\"\"Generate sentence embeddings for window and dataset_id\"\"\"\n    try:\n        embedder = SentenceTransformer(embedder_path)\n        \n        logger.info(\"Generating window embeddings...\")\n        embed_window = embedder.encode(\n            df[\"window\"].tolist(), \n            batch_size=64, \n            show_progress_bar=True,\n            convert_to_numpy=True\n        )\n        \n        logger.info(\"Generating dataset_id embeddings...\")\n        embed_dsid = embedder.encode(\n            df[\"dataset_id\"].tolist(), \n            batch_size=64, \n            show_progress_bar=True,\n            convert_to_numpy=True\n        )\n        \n        return embed_window, embed_dsid\n    except Exception as e:\n        logger.error(f\"Error creating embeddings: {e}\")\n        raise\n\ndef prepare_features(df, embed_window, embed_dsid):\n    \"\"\"Prepare feature matrix and labels\"\"\"\n    # One-hot encodings with consistent columns\n    llm_onehot = pd.get_dummies(df[\"type_llm\"], prefix=\"llm\")\n    scibert_onehot = pd.get_dummies(df[\"pred_label\"], prefix=\"scibert\")\n    \n    # Ensure consistent columns\n    for col in [\"llm_Primary\", \"llm_Secondary\"]:\n        if col not in llm_onehot.columns:\n            llm_onehot[col] = 0\n    \n    for col in [\"scibert_Primary\", \"scibert_Secondary\"]:\n        if col not in scibert_onehot.columns:\n            scibert_onehot[col] = 0\n    \n    llm_onehot = llm_onehot[[\"llm_Primary\", \"llm_Secondary\"]]\n    scibert_onehot = scibert_onehot[[\"scibert_Primary\", \"scibert_Secondary\"]]\n    \n    # Construct feature matrix\n    X = np.hstack([\n        embed_window,\n        embed_dsid,\n        df[[\"logit_primary\", \"logit_secondary\"]].values,\n        df[[\"logprob_A\", \"logprob_B\"]].values,\n        llm_onehot.values,\n        scibert_onehot.values\n    ])\n    \n    # Labels\n    label_map = {\"Primary\": 0, \"Secondary\": 1}\n    y = df[\"pred_label\"].map(label_map).values\n    \n    logger.info(f\"Feature matrix shape: {X.shape}\")\n    logger.info(f\"Label distribution: {np.bincount(y)}\")\n    \n    return X, y\n\nclass Classifier(nn.Module):\n    \"\"\"Improved classifier with configurable architecture\"\"\"\n    def __init__(self, input_dim, hidden_dim=128, dropout=0.3):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.BatchNorm1d(hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, 2)\n        )\n    \n    def forward(self, x):\n        return self.net(x)\n\ndef train_epoch(model, train_loader, optimizer, loss_fn, device):\n    \"\"\"Train for one epoch\"\"\"\n    model.train()\n    total_loss = 0\n    num_batches = 0\n    \n    for xb, yb in train_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        \n        optimizer.zero_grad()\n        logits = model(xb)\n        loss = loss_fn(logits, yb)\n        loss.backward()\n        \n        # Gradient clipping\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        optimizer.step()\n        \n        total_loss += loss.item()\n        num_batches += 1\n    \n    return total_loss / num_batches\n\ndef evaluate(model, val_loader, device):\n    \"\"\"Evaluate model on validation set\"\"\"\n    model.eval()\n    preds, true = [], []\n    \n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device)\n            logits = model(xb)\n            p = torch.argmax(logits, dim=1).cpu().numpy()\n            preds.extend(p)\n            true.extend(yb.numpy())\n    \n    f1 = f1_score(true, preds, average=\"macro\")\n    return f1, preds, true\n\ndef main():\n    # Set random seeds for reproducibility\n    torch.manual_seed(42)\n    np.random.seed(42)\n    \n    # Load data\n    df = load_and_merge_data()\n    \n    # Create embeddings\n    embed_window, embed_dsid = create_embeddings(df)\n    \n    # Prepare features\n    X, y = prepare_features(df, embed_window, embed_dsid)\n    \n    # Normalize features\n    scaler = StandardScaler()\n    X = scaler.fit_transform(X)\n    \n    # Train/validation split\n    X_train, X_val, y_train, y_val = train_test_split(\n        X, y, test_size=0.2, stratify=y, random_state=42\n    )\n    \n    # Create datasets and dataloaders\n    train_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train))\n    val_ds = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val))\n    \n    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=64)\n    \n    # Model setup\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    logger.info(f\"Using device: {device}\")\n    \n    model = Classifier(input_dim=X.shape[1]).to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=0.5, patience=10\n    )\n    loss_fn = nn.CrossEntropyLoss()\n    \n    # Training loop\n    best_f1 = 0.0\n    patience_counter = 0\n    max_patience = 50\n    \n    logger.info(\"Starting training...\")\n    \n    for epoch in range(1000):  # Reduced max epochs\n        # Train\n        avg_loss = train_epoch(model, train_loader, optimizer, loss_fn, device)\n        \n        # Evaluate\n        val_f1, preds, true = evaluate(model, val_loader, device)\n        \n        # Learning rate scheduling\n        scheduler.step(val_f1)\n        \n        # Logging\n        if epoch % 10 == 0:\n            logger.info(f\"Epoch {epoch}: Val F1={val_f1:.4f}, Loss={avg_loss:.4f}\")\n        \n        # Save best model\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            patience_counter = 0\n            \n            # Save model\n            save_path = \"/kaggle/working/best_embed_mlp.pt\"\n            torch.save({\n                'model_state_dict': model.state_dict(),\n                'scaler': scaler,\n                'best_f1': best_f1,\n                'epoch': epoch\n            }, save_path)\n            \n            logger.info(f\"✅ New best model saved! F1: {best_f1:.4f}\")\n            \n            # Print detailed classification report\n            if epoch % 50 == 0:\n                print(\"\\nClassification Report:\")\n                print(classification_report(true, preds, target_names=[\"Primary\", \"Secondary\"]))\n        else:\n            patience_counter += 1\n        \n        # Early stopping\n        if patience_counter >= max_patience:\n            logger.info(f\"Early stopping at epoch {epoch}\")\n            break\n    \n    logger.info(f\"Training completed. Best F1: {best_f1:.4f}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:56:17.450665Z","iopub.execute_input":"2025-08-03T01:56:17.451229Z","iopub.status.idle":"2025-08-03T01:56:28.046189Z","shell.execute_reply.started":"2025-08-03T01:56:17.451206Z","shell.execute_reply":"2025-08-03T01:56:28.045356Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b7458e556cb460da90c49bf398dc26c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbd7b57e644445cba3dd57525e75b7a1"}},"metadata":{}},{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n     Primary       0.84      0.70      0.77       105\n   Secondary       0.77      0.88      0.82       116\n\n    accuracy                           0.80       221\n   macro avg       0.80      0.79      0.79       221\nweighted avg       0.80      0.80      0.79       221\n\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.preprocessing import StandardScaler\nimport logging\nfrom pathlib import Path\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Paths\nLLM_PATH = \"/kaggle/working/submission_llm_logprobs.csv\"\nSCIBERT_PATH = \"/kaggle/working/submission_scibert_logits.csv\"\nEXTRACTED_PATH = \"/tmp/extracted.parquet\"\nMODEL_PATH = \"/kaggle/working/best_embed_mlp.pt\"\nOUTPUT_PATH = \"/kaggle/working/submission_nn.csv\"\n\nclass Classifier(nn.Module):\n    \"\"\"Improved classifier matching training code\"\"\"\n    def __init__(self, input_dim, hidden_dim=128, dropout=0.3):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.BatchNorm1d(hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, 2)\n        )\n    \n    def forward(self, x):\n        return self.net(x)\n\ndef load_and_merge_data():\n    \"\"\"Load and merge all data sources\"\"\"\n    try:\n        llm = pd.read_csv(LLM_PATH)\n        scibert = pd.read_csv(SCIBERT_PATH)\n        extracted = pd.read_parquet(EXTRACTED_PATH)\n        \n        # Merge datasets\n        df = (\n            extracted.merge(llm, on=[\"article_id\", \"dataset_id\"], how=\"inner\")\n                     .merge(scibert, on=[\"article_id\", \"dataset_id\"], how=\"inner\")\n        )\n        \n        # Filter out 'Missing'\n        df = df[df[\"pred_label\"] != \"Missing\"].reset_index(drop=True)\n        logger.info(f\"Loaded {len(df)} samples for inference\")\n        \n        return df\n    except Exception as e:\n        logger.error(f\"Error loading data: {e}\")\n        raise\n\ndef create_embeddings(df, embedder_path=\"/kaggle/input/all-minilm-l6-v2-and-deps/all-MiniLM-L6-v2/\"):\n    \"\"\"Generate sentence embeddings for window and dataset_id\"\"\"\n    try:\n        embedder = SentenceTransformer(embedder_path)\n        \n        logger.info(\"Generating window embeddings...\")\n        embed_window = embedder.encode(\n            df[\"window\"].tolist(), \n            batch_size=64, \n            show_progress_bar=True,\n            convert_to_numpy=True\n        )\n        \n        logger.info(\"Generating dataset_id embeddings...\")\n        embed_dsid = embedder.encode(\n            df[\"dataset_id\"].tolist(), \n            batch_size=64, \n            show_progress_bar=True,\n            convert_to_numpy=True\n        )\n        \n        return embed_window, embed_dsid\n    except Exception as e:\n        logger.error(f\"Error creating embeddings: {e}\")\n        raise\n\ndef prepare_features(df, embed_window, embed_dsid):\n    \"\"\"Prepare feature matrix - must match training exactly\"\"\"\n    # One-hot encodings with consistent columns\n    llm_onehot = pd.get_dummies(df[\"type_llm\"], prefix=\"llm\")\n    scibert_onehot = pd.get_dummies(df[\"pred_label\"], prefix=\"scibert\")\n    \n    # Ensure consistent columns (same as training)\n    for col in [\"llm_Primary\", \"llm_Secondary\"]:\n        if col not in llm_onehot.columns:\n            llm_onehot[col] = 0\n    \n    for col in [\"scibert_Primary\", \"scibert_Secondary\"]:\n        if col not in scibert_onehot.columns:\n            scibert_onehot[col] = 0\n    \n    llm_onehot = llm_onehot[[\"llm_Primary\", \"llm_Secondary\"]]\n    scibert_onehot = scibert_onehot[[\"scibert_Primary\", \"scibert_Secondary\"]]\n    \n    # Construct feature matrix (same order as training)\n    X = np.hstack([\n        embed_window,\n        embed_dsid,\n        df[[\"logit_primary\", \"logit_secondary\"]].values,\n        df[[\"logprob_A\", \"logprob_B\"]].values,\n        llm_onehot.values,\n        scibert_onehot.values\n    ])\n    \n    logger.info(f\"Feature matrix shape: {X.shape}\")\n    return X\n\ndef load_model_and_scaler():\n    \"\"\"Load trained model and scaler\"\"\"\n    try:\n        # Load saved checkpoint\n        checkpoint = torch.load(MODEL_PATH, map_location='cpu', weights_only=False)\n        \n        # Check if it's the new format (with scaler) or old format\n        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n            # New format\n            scaler = checkpoint['scaler']\n            model_state = checkpoint['model_state_dict']\n            logger.info(f\"Loaded model with F1: {checkpoint.get('best_f1', 'unknown')}\")\n        else:\n            # Old format - model only\n            model_state = checkpoint.state_dict() if hasattr(checkpoint, 'state_dict') else None\n            scaler = None\n            logger.warning(\"Old model format detected - scaler not saved with model\")\n        \n        return model_state, scaler\n    except Exception as e:\n        logger.error(f\"Error loading model: {e}\")\n        raise\n\ndef main():\n    # Load data\n    df = load_and_merge_data()\n    \n    # Create embeddings\n    embed_window, embed_dsid = create_embeddings(df)\n    \n    # Prepare features\n    X = prepare_features(df, embed_window, embed_dsid)\n    \n    # Load model and scaler\n    model_state, saved_scaler = load_model_and_scaler()\n    \n    # Normalize features\n    if saved_scaler is not None:\n        # Use saved scaler from training\n        logger.info(\"Using saved scaler from training\")\n        X = saved_scaler.transform(X)\n    else:\n        # Fallback: fit new scaler (not ideal for inference)\n        logger.warning(\"No saved scaler found - fitting new scaler (may cause issues)\")\n        scaler = StandardScaler()\n        X = scaler.fit_transform(X)\n    \n    # Setup device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    logger.info(f\"Using device: {device}\")\n    \n    # Load model\n    model = Classifier(input_dim=X.shape[1])\n    \n    if model_state is not None:\n        model.load_state_dict(model_state)\n    else:\n        # Fallback for old format\n        model = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n    \n    model.to(device)\n    model.eval()\n    \n    logger.info(\"Running inference...\")\n    \n    # Predict in batches to handle large datasets\n    batch_size = 1000\n    all_preds = []\n    \n    with torch.no_grad():\n        for i in range(0, len(X), batch_size):\n            batch_X = X[i:i+batch_size]\n            inputs = torch.tensor(batch_X, dtype=torch.float32).to(device)\n            logits = model(inputs)\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            all_preds.extend(preds)\n    \n    # Map predictions\n    id2label = {0: \"Primary\", 1: \"Secondary\"}\n    df[\"type\"] = [id2label[p] for p in all_preds]\n    \n    # Log prediction distribution\n    pred_counts = df[\"type\"].value_counts()\n    logger.info(f\"Prediction distribution: {pred_counts.to_dict()}\")\n    \n    # Create submission\n    submission = df[[\"article_id\", \"dataset_id\", \"type\"]].copy()\n    submission.insert(0, \"row_id\", submission.index)\n    \n    # Save submission\n    submission.to_csv(OUTPUT_PATH, index=False)\n    logger.info(f\"✅ Submission saved to {OUTPUT_PATH}\")\n    logger.info(f\"Submission shape: {submission.shape}\")\n    \n    # Display first few rows\n    print(\"\\nFirst 5 rows of submission:\")\n    print(submission.head())\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T02:02:09.420457Z","iopub.execute_input":"2025-08-03T02:02:09.420759Z","iopub.status.idle":"2025-08-03T02:02:11.216310Z","shell.execute_reply.started":"2025-08-03T02:02:09.420729Z","shell.execute_reply":"2025-08-03T02:02:11.215716Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c7a15b196944794be899e4a3dca168f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcdd25b3d3f244138e464dd3ab058fa1"}},"metadata":{}},{"name":"stdout","text":"\nFirst 5 rows of submission:\n   row_id                       article_id  \\\n0       0   10.12688_f1000research.13064.1   \n1       1  10.1590_1678-4685-gmb-2018-0055   \n2       2        10.1128_spectrum.00422-24   \n3       3                10.1111_cas.12935   \n4       4        10.1128_spectrum.00422-24   \n\n                                          dataset_id       type  \n0  https://doi.org/10.5256/f1000research.13064.d1...    Primary  \n1                                         SRR3187022    Primary  \n2                                             K02412  Secondary  \n3                                          HPA007450  Secondary  \n4                                             K02414  Secondary  \n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"%%writefile /tmp/src/nn_infer.py\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.preprocessing import StandardScaler\n\n# Paths\nLLM_PATH = \"/kaggle/working/submission_llm_logprobs.csv\"\nSCIBERT_PATH = \"/kaggle/working/submission_scibert_logits.csv\"\nEXTRACTED_PATH = \"/tmp/extracted.parquet\"\nMODEL_PATH = \"/kaggle/working/best_embed_mlp.pt\"\nOUTPUT_PATH = \"/kaggle/working/submission_nn.csv\"\n\n# Load data\nllm = pd.read_csv(LLM_PATH)\nscibert = pd.read_csv(SCIBERT_PATH)\nextracted = pd.read_parquet(EXTRACTED_PATH)\n\n# Merge\ndf = (\n    extracted.merge(llm, on=[\"article_id\", \"dataset_id\"], how=\"inner\")\n             .merge(scibert, on=[\"article_id\", \"dataset_id\"], how=\"inner\")\n)\n\n# Filter out 'Missing'\ndf = df[df[\"pred_label\"] != \"Missing\"].reset_index(drop=True)\n\n# Load embedder\nembedder = SentenceTransformer(\"/kaggle/input/all-minilm-l6-v2-and-deps/all-MiniLM-L6-v2/\")\nembed_window = embedder.encode(df[\"window\"].tolist(), batch_size=64, show_progress_bar=True)\nembed_dsid = embedder.encode(df[\"dataset_id\"].tolist(), batch_size=64, show_progress_bar=True)\n\n# One-hot types\nllm_onehot = pd.get_dummies(df[\"type_llm\"], prefix=\"llm\")\nscibert_onehot = pd.get_dummies(df[\"pred_label\"], prefix=\"scibert\")\nllm_onehot = llm_onehot.reindex(columns=[\"llm_Primary\", \"llm_Secondary\"], fill_value=0)\nscibert_onehot = scibert_onehot.reindex(columns=[\"scibert_Primary\", \"scibert_Secondary\"], fill_value=0)\n\n# Features\nX = np.hstack([\n    embed_window,\n    embed_dsid,\n    df[[\"logit_primary\", \"logit_secondary\"]].values,\n    df[[\"logprob_A\", \"logprob_B\"]].values,\n    llm_onehot.values,\n    scibert_onehot.values\n])\n\n# Normalize (same transform as training)\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# 🧠 Define model\nclass Classifier(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 2)\n        )\n    def forward(self, x):\n        return self.net(x)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Classifier(input_dim=X.shape[1]).to(device)\nmodel = torch.load(MODEL_PATH, weights_only=False)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()\n\n# Predict\nwith torch.no_grad():\n    inputs = torch.tensor(X, dtype=torch.float32).to(device)\n    logits = model(inputs)\n    preds = torch.argmax(logits, dim=1).cpu().numpy()\n\n# Map predictions\nid2label = {0: \"Primary\", 1: \"Secondary\"}\ndf[\"type\"] = [id2label[p] for p in preds]\n\n# Create submission\nsubmission = df[[\"article_id\", \"dataset_id\", \"type\"]].copy()\nsubmission.insert(0, \"row_id\", submission.index)\nsubmission.to_csv(OUTPUT_PATH, index=False)\n\nprint(f\"✅ Submission saved to {OUTPUT_PATH}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:48:34.116082Z","iopub.execute_input":"2025-08-03T01:48:34.116635Z","iopub.status.idle":"2025-08-03T01:48:36.341714Z","shell.execute_reply.started":"2025-08-03T01:48:34.116607Z","shell.execute_reply":"2025-08-03T01:48:36.341027Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bb99b5f77004bde949e1905b62f28f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b18240070a794e4eb1570a79999d2548"}},"metadata":{}},{"name":"stdout","text":"✅ Submission saved to /kaggle/working/submission_nn.csv\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"%%writefile /tmp/src/Failures.py\nimport polars as pl\n\n# Load predictions\npred_df = pl.read_csv(\"/kaggle/working/submission_nn.csv\")\n\n# Load official labels\ntruth_df = pl.read_csv(\"/kaggle/input/make-data-count-finding-data-references/train_labels.csv\")\n\n# Rename truth type for disambiguation\ntruth_df = truth_df.rename({\"type\": \"type_truth\"})\n\n# Full outer join on article_id and dataset_id\njoined = pred_df.join(truth_df, on=[\"article_id\", \"dataset_id\"], how=\"right\")\nprint(len(joined))\n# Add error type column\nerror_expr = (\n    pl.when(pl.col(\"type\").is_null() & pl.col(\"type_truth\").is_not_null()).then(pl.lit(\"false_negative\"))\n    .when(pl.col(\"type\").is_not_null() & pl.col(\"type_truth\").is_null()).then(pl.lit(\"false_positive\"))\n    .when(\n        pl.col(\"type\").is_not_null()\n        & pl.col(\"type_truth\").is_not_null()\n        & (pl.col(\"type\") != pl.col(\"type_truth\"))\n    ).then(pl.lit(\"type_mismatch\"))\n    .otherwise(pl.lit(\"correct\"))\n)\n\njoined = joined.with_columns(error_expr.alias(\"error_type\"))\n\n# Extract error subsets\nfalse_negatives = joined.filter(pl.col(\"error_type\") == \"false_negative\")\nfalse_positives = joined.filter(pl.col(\"error_type\") == \"false_positive\")\ntype_mismatches = joined.filter(pl.col(\"error_type\") == \"type_mismatch\")\n\n# Report\nprint(f\"False negatives: {false_negatives.shape[0]}\")\nprint(f\"False positives: {false_positives.shape[0]}\")\nprint(f\"Type mismatches: {type_mismatches.shape[0]}\")\n\n# Save detailed breakdowns\nfalse_negatives.write_csv(\"/kaggle/working/false_negatives.csv\")\nfalse_positives.write_csv(\"/kaggle/working/false_positives.csv\")\ntype_mismatches.write_csv(\"/kaggle/working/type_mismatches.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T01:59:33.542201Z","iopub.execute_input":"2025-08-03T01:59:33.542866Z","iopub.status.idle":"2025-08-03T01:59:33.558902Z","shell.execute_reply.started":"2025-08-03T01:59:33.542822Z","shell.execute_reply":"2025-08-03T01:59:33.558182Z"}},"outputs":[{"name":"stdout","text":"1066\nFalse negatives: 580\nFalse positives: 0\nType mismatches: 22\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"! cat /tmp/logs/project.log","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-01T22:15:58.232Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"INFO 2025-07-23 15:22:18  [post_filter.py:52 - main()] all - f1: 0.6891 [481/196/238]\n\nINFO 2025-07-23 15:22:18  [post_filter.py:52 - main()] doi - f1: 0.5889 [164/68/161]\n\nINFO 2025-07-23 15:22:18  [post_filter.py:52 - main()] acc - f1: 0.7557 [317/128/77]\n\nINFO 2025-07-23 15:22:18  [post_filter.py:53 - main()] all - f1: 0.5759 [402/275/317]\n\nINFO 2025-07-23 15:22:18  [post_filter.py:53 - main()] doi - f1: 0.4596 [128/104/197]\n\nINFO 2025-07-23 15:22:18  [post_filter.py:53 - main()] acc - f1: 0.6532 [274/171/120]","metadata":{"papermill":{"duration":0.010278,"end_time":"2025-07-24T17:55:22.563271","exception":false,"start_time":"2025-07-24T17:55:22.552993","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"INFO 2025-07-30 10:24:30  [post_filter_scibert.py:56 - main()] all - f1: 0.5960 [486/426/233]\n\nINFO 2025-07-30 10:24:30  [post_filter_scibert.py:56 - main()] doi - f1: 0.5795 [164/77/161]\n\nINFO 2025-07-30 10:24:30  [post_filter_scibert.py:56 - main()] acc - f1: 0.6047 [322/349/72]\n\nINFO 2025-07-30 10:24:30  [post_filter_scibert.py:57 - main()] all - f1: 0.5861 [478/434/241]\n\nINFO 2025-07-30 10:24:30  [post_filter_scibert.py:57 - main()] doi - f1: 0.5583 [158/83/167]\n\nINFO 2025-07-30 10:24:30  [post_filter_scibert.py:57 - main()] acc - f1: 0.6009 [320/351/74]\n","metadata":{}}]}