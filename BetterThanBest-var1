{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":82370,"databundleVersionId":13015230,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":12444547,"sourceType":"datasetVersion","datasetId":7850099},{"sourceId":248118764,"sourceType":"kernelVersion"},{"sourceId":166368,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":141565,"modelId":164048},{"sourceId":375840,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":310551,"modelId":322000}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":488.278722,"end_time":"2025-07-24T17:55:22.890819","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-24T17:47:14.612097","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"4888e6f0","cell_type":"markdown","source":"# Changes\n\nAdded new regexes. Nothing more.","metadata":{"papermill":{"duration":0.003459,"end_time":"2025-07-24T17:47:18.800271","exception":false,"start_time":"2025-07-24T17:47:18.796812","status":"completed"},"tags":[]}},{"id":"3c6b82df","cell_type":"code","source":"# ! uv pip uninstall --system 'tensorflow'\n! uv pip install --system --no-index --find-links='/kaggle/input/latest-mdc-whls/whls' 'pymupdf' # 'vllm' 'triton' 'logits-processor-zoo' 'numpy<2'","metadata":{"_cell_guid":"eae4b221-a822-451f-8f4b-134c3f9bfe2c","_uuid":"b1883565-f717-4130-a662-5bb541f45ea1","collapsed":false,"execution":{"iopub.status.busy":"2025-07-25T12:47:10.599277Z","iopub.execute_input":"2025-07-25T12:47:10.599524Z","iopub.status.idle":"2025-07-25T12:47:11.636426Z","shell.execute_reply.started":"2025-07-25T12:47:10.599499Z","shell.execute_reply":"2025-07-25T12:47:11.635543Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":27.258583,"end_time":"2025-07-24T17:47:46.061744","exception":false,"start_time":"2025-07-24T17:47:18.803161","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 36ms\u001b[0m\u001b[0m                                           \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 468ms\u001b[0m\u001b[0m                                              \n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpymupdf\u001b[0m\u001b[2m==1.26.1\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"id":"8e5b266f-70c2-47c6-a021-7b4cd4b5792b","cell_type":"code","source":"# ! uv pip install /kaggle/input/mdcfitz/pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl\n! uv pip install vllm --no-index --find-links file:///kaggle/input/mdcllm\n! uv pip install logits-processor-zoo==0.1.10 --no-index --find-links file:///kaggle/input/mdcllm\n! uv pip install triton==3.2.0 --no-index --find-links file:///kaggle/input/mdcllm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T12:47:11.637413Z","iopub.execute_input":"2025-07-25T12:47:11.637777Z","iopub.status.idle":"2025-07-25T12:47:50.425601Z","shell.execute_reply.started":"2025-07-25T12:47:11.637745Z","shell.execute_reply":"2025-07-25T12:47:50.424695Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m145 packages\u001b[0m \u001b[2min 274ms\u001b[0m\u001b[0m                                       \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m54 packages\u001b[0m \u001b[2min 32.65s\u001b[0m\u001b[0m                                           \n\u001b[2mUninstalled \u001b[1m23 packages\u001b[0m \u001b[2min 1.55s\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m54 packages\u001b[0m \u001b[2min 350ms\u001b[0m\u001b[0m                              \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mairportsdata\u001b[0m\u001b[2m==20250706\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mastor\u001b[0m\u001b[2m==0.8.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mblake3\u001b[0m\u001b[2m==1.0.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcompressed-tensors\u001b[0m\u001b[2m==0.10.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdepyf\u001b[0m\u001b[2m==0.18.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdiskcache\u001b[0m\u001b[2m==5.6.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi-cli\u001b[0m\u001b[2m==0.0.8\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi-cloud-cli\u001b[0m\u001b[2m==0.1.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mgguf\u001b[0m\u001b[2m==0.17.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.6.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.27.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1minteregular\u001b[0m\u001b[2m==0.3.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlark\u001b[0m\u001b[2m==1.2.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mllguidance\u001b[0m\u001b[2m==0.7.30\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.43.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.44.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlm-format-enforcer\u001b[0m\u001b[2m==0.10.11\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmistral-common\u001b[0m\u001b[2m==1.6.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmsgspec\u001b[0m\u001b[2m==0.19.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.60.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.61.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.6.4.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.6.80\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.5.1.17\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.0.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.11.1.6\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.7.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.1.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.4.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.26.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.6.85\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.91.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.90.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moutlines\u001b[0m\u001b[2m==0.1.11\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moutlines-core\u001b[0m\u001b[2m==0.1.26\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpartial-json-parser\u001b[0m\u001b[2m==0.2.1.1.post6\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mprometheus-fastapi-instrumentator\u001b[0m\u001b[2m==7.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpybase64\u001b[0m\u001b[2m==1.4.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpycountry\u001b[0m\u001b[2m==24.6.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==24.0.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.0.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrich-toolkit\u001b[0m\u001b[2m==0.14.8\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrignore\u001b[0m\u001b[2m==0.5.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.7.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.7.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0+cu124 (from https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.22.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mvllm\u001b[0m\u001b[2m==0.9.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.30\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxgrammar\u001b[0m\u001b[2m==0.1.19\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m54 packages\u001b[0m \u001b[2min 14ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m                                                \n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0mo==0.1.10                         \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlogits-processor-zoo\u001b[0m\u001b[2m==0.1.10\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 14ms\u001b[0m\u001b[0m                                           \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 3.06s\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n","output_type":"stream"}],"execution_count":2},{"id":"22af8a7c-7d37-4273-a576-95ce0a25e2fa","cell_type":"code","source":"! mkdir -p /tmp/src","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T12:47:50.427490Z","iopub.execute_input":"2025-07-25T12:47:50.428406Z","iopub.status.idle":"2025-07-25T12:47:50.545260Z","shell.execute_reply.started":"2025-07-25T12:47:50.428384Z","shell.execute_reply":"2025-07-25T12:47:50.544317Z"}},"outputs":[],"execution_count":3},{"id":"300ac069","cell_type":"code","source":"%%writefile /tmp/src/helpers.py\nimport logging, os, kagglehub, inspect\nfrom pathlib import Path\nimport polars as pl\n\nIS_KAGGLE_ENV = sum(['KAGGLE' in k for k in os.environ]) > 0\nIS_KAGGLE_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\nos.environ[\"KAGGLE_IS_COMPETITION_RERUN\"] = \"1\"\n\nCOMP_DIR = Path(('/kaggle/input/make-data-count-finding-data-references' if IS_KAGGLE_SUBMISSION else kagglehub.competition_download('make-data-count-finding-data-references')))\nPDF_DIR = COMP_DIR / ('test' if IS_KAGGLE_SUBMISSION else 'train') / 'PDF'\nWORKING_DIR = Path(('/kaggle/working/' if IS_KAGGLE_ENV else '.working/'))\n\nDOI_LINK = 'https://doi.org/'\n\nDEFAULT_LOG_LEVEL = os.getenv(\"LOG_LEVEL\", \"DEBUG\").upper() if not IS_KAGGLE_SUBMISSION else \"WARNING\"\nLOG_FILE_PATH = os.getenv(\"LOG_FILE\", \"logs/project.log\")\nLOG_DIR = Path(LOG_FILE_PATH).parent\n\nLOG_DIR.mkdir(parents=True, exist_ok=True)\n\nLOG_FORMAT = \"%(levelname)s %(asctime)s  [%(filename)s:%(lineno)d - %(funcName)s()] %(message)s\"\nLOG_DATEFMT = \"%Y-%m-%d %H:%M:%S\"\n\ndef get_logger(name=None):\n    if name is None:\n        frame = inspect.currentframe()\n        if frame is None or frame.f_back is None:\n            name = \"__main__\"\n        else:\n            name = frame.f_back.f_globals.get(\"__name__\", \"__main__\")\n\n    logger = logging.getLogger(name)\n\n    if not logger.handlers:\n        logger.setLevel(DEFAULT_LOG_LEVEL)\n        formatter = logging.Formatter(fmt=LOG_FORMAT, datefmt=LOG_DATEFMT)\n        ch = logging.StreamHandler()\n        ch.setLevel(DEFAULT_LOG_LEVEL)\n        ch.setFormatter(formatter)\n        fh = logging.FileHandler(LOG_FILE_PATH)\n        fh.setLevel(DEFAULT_LOG_LEVEL)\n        fh.setFormatter(formatter)\n        logger.addHandler(ch)\n        logger.addHandler(fh)\n        logger.propagate = False\n    return logger\n\ndef is_doi_link(name: str) -> pl.Expr:\n    return pl.col(name).str.starts_with(DOI_LINK)\n\ndef string_normalization(name: str) -> pl.Expr:\n    return pl.col(name).str.normalize(\"NFKC\").str.replace_all(r\"[^\\p{Ascii}]\", '').str.replace_all(r\"https?://zenodo\\.org/record/(\\d+)\", r\" 10.5281/zenodo.$1 \")\n\ndef get_df(parse_dir: str):\n    records = []\n    txt_files = list(Path(parse_dir).glob('*.txt'))\n    for txt_file in txt_files:\n        id_ = txt_file.stem\n        with open(txt_file, 'r') as f:\n            text = f.read()\n        records.append({'article_id': id_, 'text': text})\n    return pl.DataFrame(records).with_columns(string_normalization('text').alias('text'))\n\ndef assume_type(df: pl.DataFrame) -> pl.DataFrame:\n    return (\n        df.with_columns(pl.when(is_doi_link('dataset_id').or_(pl.col('dataset_id').str.starts_with('SAMN'))).then(pl.lit('Primary')).otherwise(pl.lit('Secondary')).alias('type'))\n    )\n\ndef score(df, gt, on, tag='all'):\n    hits = gt.join(df, on=on)\n    tp = hits.height\n    fp = df.height - tp\n    fn = gt.height - tp\n    f1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) != 0 else 0.0\n    return f\"{tag} - f1: {f1:.4f} [{tp}/{fp}/{fn}]\"\n\ndef evaluate(df, on=['article_id', 'dataset_id']):\n    gt = pl.read_csv(COMP_DIR/'train_labels.csv').filter(pl.col('type')!='Missing')\n    return (\n        score(df, gt, on),\n        score(df.filter(is_doi_link('dataset_id')), gt.filter(is_doi_link('dataset_id')), on, 'doi'),\n        score(df.filter(~is_doi_link('dataset_id')), gt.filter(~is_doi_link('dataset_id')), on, 'acc'),\n    )","metadata":{"_cell_guid":"34135540-31fa-4d24-8934-acb1e0711a4f","_uuid":"92f33014-02d3-41cb-b906-ffeb89a3f353","collapsed":false,"execution":{"iopub.status.busy":"2025-07-25T12:47:50.546314Z","iopub.execute_input":"2025-07-25T12:47:50.546544Z","iopub.status.idle":"2025-07-25T12:47:54.607749Z","shell.execute_reply.started":"2025-07-25T12:47:50.546522Z","shell.execute_reply":"2025-07-25T12:47:54.606963Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.017137,"end_time":"2025-07-24T17:47:46.087471","exception":false,"start_time":"2025-07-24T17:47:46.070334","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Writing /tmp/src/helpers.py\n","output_type":"stream"}],"execution_count":4},{"id":"435964fd","cell_type":"code","source":"%%writefile /tmp/src/parse.py\nimport argparse\nfrom pathlib import Path\nimport pymupdf\nfrom helpers import get_logger, PDF_DIR\n\nl = get_logger()\n\ndef pdf_to_txt(output_dir: Path):\n    output_dir.mkdir(parents=True, exist_ok=True)\n    pdf_files = list(PDF_DIR.glob(\"*.pdf\")) + list(PDF_DIR.glob(\"*.PDF\"))\n    existing_txt_files = {f.stem for f in output_dir.glob(\"*.txt\")}\n    for pdf_file in pdf_files:\n        txt_file = output_dir / f\"{pdf_file.stem}.txt\"\n        if pdf_file.stem in existing_txt_files:\n            continue\n        try:\n            text = \"\"\n            with pymupdf.open(pdf_file) as doc:\n                for page in doc:\n                    text += page.get_text()\n            txt_file.write_text(text, encoding='utf-8')\n        except Exception:\n            pass\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('output_dir', type=Path, help='Directory to save text files')\n    args = parser.parse_args()\n    pdf_to_txt(args.output_dir)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_cell_guid":"98be0899-3cad-423b-a3db-313209068df0","_uuid":"84859532-6acd-4011-b783-d0d24257a19b","collapsed":false,"execution":{"iopub.status.busy":"2025-07-25T12:47:54.608542Z","iopub.execute_input":"2025-07-25T12:47:54.608795Z","iopub.status.idle":"2025-07-25T12:47:55.188961Z","shell.execute_reply.started":"2025-07-25T12:47:54.608768Z","shell.execute_reply":"2025-07-25T12:47:55.188259Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.015142,"end_time":"2025-07-24T17:47:46.110538","exception":false,"start_time":"2025-07-24T17:47:46.095396","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Writing /tmp/src/parse.py\n","output_type":"stream"}],"execution_count":5},{"id":"57d9f5bb","cell_type":"code","source":"%%writefile /tmp/src/check_parse.py\nimport polars as pl\nfrom pathlib import Path\nfrom helpers import *\n\nl=get_logger()\n\ndef gt_dataset_id_normalization(name:str) -> pl.Expr:\n    return (\n        pl.when(is_doi_link(name))\n        .then(pl.col(name).str.split(DOI_LINK).list.last())\n        .otherwise(name)\n        .str.to_lowercase()\n    )\n\ndef main():\n    if IS_KAGGLE_SUBMISSION:\n        l.debug('skipping check_parse for submission')\n        return\n    df = (\n        get_df('/tmp/train_parse')\n        .with_columns(pl.col('text').str.replace_all('\\s+', '').str.to_lowercase().alias('text'))\n    )\n\n    gt = (\n        pl.read_csv(COMP_DIR/'train_labels.csv')\n        .filter(pl.col('article_id').is_in(df['article_id']))\n        .filter(pl.col('type')!='Missing')\n        .with_columns(gt_dataset_id_normalization('dataset_id').alias('norm_id'))\n    )\n\n    l.info(f\"pymupdf misses: {gt.join(df, on='article_id').with_columns(hit=pl.col('text').str.contains(pl.col('norm_id'), literal=True)).filter(~pl.col('hit')).height} dataset_ids\")\n\nif __name__=='__main__': main()","metadata":{"_cell_guid":"01632e8b-2a68-4dec-9606-f91214a8c020","_uuid":"5210e49f-e5ab-45c6-b673-f0bd08dc1877","collapsed":false,"execution":{"iopub.status.busy":"2025-07-25T12:47:55.189719Z","iopub.execute_input":"2025-07-25T12:47:55.189930Z","iopub.status.idle":"2025-07-25T12:47:55.202751Z","shell.execute_reply.started":"2025-07-25T12:47:55.189914Z","shell.execute_reply":"2025-07-25T12:47:55.202180Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.014538,"end_time":"2025-07-24T17:47:46.133223","exception":false,"start_time":"2025-07-24T17:47:46.118685","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Writing /tmp/src/check_parse.py\n","output_type":"stream"}],"execution_count":6},{"id":"3966e2df","cell_type":"code","source":"%%writefile /tmp/src/getid.py\nimport re\nimport polars as pl\nfrom typing import Optional, Tuple\n\nfrom helpers import *\n\nCOMPILED_PATTERNS = {\n    'ref_header_patterns': [re.compile(r'\\b(R\\s*E\\s*F\\s*E\\s*R\\s*E\\s*N\\s*C\\s*E\\s*S|BIBLIOGRAPHY|LITERATURE CITED|WORKS CITED|CITED WORKS|ACKNOWLEDGEMENTS)\\b[:\\s]*', re.IGNORECASE)],    \n    'citation_pattern': re.compile(r'^\\s*(\\[\\d+\\]|\\(\\d+\\)|\\d+\\.|\\d+\\)|\\d+(?=\\s|$))\\s*'),\n    'first_citation_patterns': [\n        re.compile(r'^\\s*\\[1\\]\\s*'),\n        re.compile(r'^\\s*\\(1\\)\\s*'),\n        re.compile(r'^\\s*1\\.\\s*'),\n        re.compile(r'^\\s*1\\)\\s*'),\n        re.compile(r'^\\s*1(?=\\s|$)'),\n    ],\n}\n\nl = get_logger()\n\ndef find_last_reference_header(text: str, header_patterns: list[re.Pattern]) -> Optional[int]:\n    last_match_idx = None\n    for pattern in header_patterns:\n        matches = list(pattern.finditer(text))\n        if matches:\n            last_match_idx = matches[-1].start()\n    return last_match_idx\n\ndef find_last_first_citation(text: str) -> Optional[int]:\n    lines = text.splitlines()\n    last_match_line = None\n    for line_num, line in enumerate(lines):\n        line = line.strip()\n        for pattern in COMPILED_PATTERNS['first_citation_patterns']:\n            if pattern.match(line):\n                next_lines = lines[line_num:line_num+3]\n                if any(COMPILED_PATTERNS['citation_pattern'].match(l.strip()) for l in next_lines[1:]):\n                    last_match_line = line_num\n                break\n    return last_match_line\n\ndef find_reference_start(text: str) -> Optional[int]:\n    lines = text.splitlines()\n    last_first_citation = find_last_first_citation(text)\n    if last_first_citation is not None:\n        return last_first_citation\n    start_search_idx = int(len(lines) * 0.5)\n    for i in range(start_search_idx, len(lines)):\n        line = lines[i].strip()\n        if COMPILED_PATTERNS['citation_pattern'].match(line):\n            next_lines = lines[i:i+3]\n            if sum(1 for l in next_lines if COMPILED_PATTERNS['citation_pattern'].match(l.strip())) >= 2:\n                for j in range(i, max(-1, i-10), -1):\n                    if not COMPILED_PATTERNS['citation_pattern'].match(lines[j].strip()):\n                        return j + 1\n                return max(0, i-10)\n    return None\n\ndef split_text_and_references(text: str) -> Tuple[str, str]:\n    header_idx = find_last_reference_header(text, COMPILED_PATTERNS['ref_header_patterns'])\n    if header_idx is not None:\n        header_idx2 = find_last_reference_header(text[:header_idx].strip(), COMPILED_PATTERNS['ref_header_patterns'])\n        if header_idx2 is not None:\n            header_idx3 = find_last_reference_header(text[:header_idx2].strip(), COMPILED_PATTERNS['ref_header_patterns'])\n            if header_idx3 is not None:\n                return text[:header_idx3].strip(), text[header_idx3:].strip()\n            return text[:header_idx2].strip(), text[header_idx2:].strip()\n        return text[:header_idx].strip(), text[header_idx:].strip()\n    ref_start_line = find_reference_start(text)\n    if ref_start_line is not None:\n        lines = text.splitlines()\n        body = '\\n'.join(lines[:ref_start_line])\n        refs = '\\n'.join(lines[ref_start_line:])\n        return body.strip(), refs.strip()\n    return text.strip(), ''\n\ndef get_splits(df: pl.DataFrame) -> pl.DataFrame:\n    bodies, refs = [], []\n    for raw_text in df['text']:\n        main, ref = split_text_and_references(raw_text)\n        bodies.append(main)\n        refs.append(ref)\n    return df.with_columns(pl.Series('body', bodies), pl.Series('ref', refs))\n\ndef tidy_extraction(df) -> pl.DataFrame:\n    bad_ids = [f'{DOI_LINK}{e}' for e in ['10.5061/dryad', '10.5281/zenodo', '10.6073/pasta']]\n\n    doi_df = (\n        df.with_columns(pl.col('body').str.extract_all(r'10\\s*\\.\\s*\\d{4,9}\\s*/\\s*\\S+').alias('match'))\n          .explode('match')\n          .drop_nulls('match')\n          .with_columns(\n              pl.col('match').str.replace_all(r'\\s+', '')\n                             .str.replace(r'[^A-Za-z0-9]+$', '')\n                             .str.to_lowercase()\n                             .alias('dataset_id')\n          )\n          .group_by('article_id', 'dataset_id')\n          .agg('match')\n          .with_columns((DOI_LINK + pl.col('dataset_id')).alias('dataset_id'))\n    )\n\n    REGEX_IDS = (\n        r\"(?i)\\b(?:\"\n        r\"CHEMBL\\d+|\"\n        r\"E-GEOD-\\d+|E-PROT-\\d+|EMPIAR-\\d+|\"\n        r\"ENSBTAG\\d+|ENSOARG\\d+|\"\n        r\"EPI_ISL_\\d{5,}|EPI\\d{6,7}|\"\n        r\"HPA\\d+|CP\\d{6}|IPR\\d{6}|PF\\d{5}|KX\\d{6}|K0\\d{4}|\"\n        r\"PRJNA\\d+|PRJEB\\d+|PXD\\d+|SAMN\\d+|\"\n        r\"GSE\\d+|GSM\\d+|GPL\\d+|\"\n        r\"E-MTAB-\\d+|E-MEXP-\\d+|\"\n        r\"PDB\\s?\\w{4}|HMDB\\d+|\"\n        r\"dryad\\.[^\\s\\\"<>]+|pasta\\/[^\\s\\\"<>]+|\"\n        r\"(?:SRR|SRX|SRP|ERR|DRR|DRX|DRP|ERP|ERX)\\d+\"\n        r\")\"\n    )    \n\n    \n    acc_df = (\n        df.with_columns(\n            pl.col('text').str.extract_all(REGEX_IDS).alias('match')\n        )\n        .explode('match')\n        .drop_nulls('match')\n        .with_columns(\n            pl.col('match').str.replace_all(r'\\s+', '')\n                           .str.replace(r'[^A-Za-z0-9]+$', '')\n                           .alias('dataset_id')\n        )\n        .group_by('article_id', 'dataset_id')\n        .agg('match')\n        .with_columns(\n            pl.when(pl.col('dataset_id').str.starts_with('dryad.'))\n              .then(f'{DOI_LINK}10.5061/' + pl.col('dataset_id'))\n              .otherwise('dataset_id')\n              .alias('dataset_id')\n        )\n        .with_columns(\n            pl.when(pl.col('dataset_id').str.starts_with('pasta/'))\n              .then(f'{DOI_LINK}10.6073/' + pl.col('dataset_id'))\n              .otherwise('dataset_id')\n              .alias('dataset_id')\n        )\n    )\n\n    df = pl.concat([doi_df, acc_df])\n\n    df = (\n        df.unique(['article_id', 'dataset_id'])  # CHANGED\n          .filter(~pl.col('article_id').str.replace('_','/').str.contains(pl.col('dataset_id').str.split(DOI_LINK).list.last().str.escape_regex()))\n          .filter(~pl.col('dataset_id').str.contains(pl.col('article_id').str.replace('_','/').str.escape_regex()))\n          .filter(~pl.col('dataset_id').str.contains('figshare', literal=True))\n          .filter(~pl.col('dataset_id').is_in(bad_ids))\n          .filter(\n              pl.when(is_doi_link('dataset_id') &\n                      (pl.col('dataset_id').str.split('/').list.last().str.len_chars() < 5))\n               .then(False)\n               .otherwise(True)\n          )\n          .with_columns(pl.col('match').list.unique())\n    )\n    return df\n\ndef get_context_window(text: str, substring: str, window: int = 100) -> str:\n    idx = text.find(substring)\n    if idx == -1:\n        raise ValueError\n    start = max(idx - window, 0)\n    end = min(idx + len(substring) + window, len(text))\n    return text[start:end]\n\ndef get_window_df(text_df, ids_df):\n    df = ids_df.join(text_df, on='article_id')\n    windows = []\n    for text, match_ids in df.select('text', 'match').rows():\n        windows.append(get_context_window(text, match_ids[0]))\n    return df.with_columns(pl.Series('window', windows)).select('article_id', 'dataset_id', 'window')\n\ndef main():\n    text_df = get_df('/tmp/train_parse')\n    df = get_splits(text_df)\n    df = tidy_extraction(df)\n    df = get_window_df(text_df, df)\n    df.write_parquet('/tmp/extracted.parquet')\n    df = assume_type(df)\n    df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n    if not IS_KAGGLE_SUBMISSION:\n        results = evaluate(df)\n        for r in results: l.info(r)\n        results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n        for r in results: l.info(r)\n\nif __name__=='__main__': main()","metadata":{"_cell_guid":"83084a3e-ab3e-4c24-9045-7bc81df72e34","_uuid":"5a79e391-1a5c-4264-9aa5-747cb657a266","collapsed":false,"execution":{"iopub.status.busy":"2025-07-25T12:47:55.203502Z","iopub.execute_input":"2025-07-25T12:47:55.203700Z","iopub.status.idle":"2025-07-25T12:47:55.220939Z","shell.execute_reply.started":"2025-07-25T12:47:55.203678Z","shell.execute_reply":"2025-07-25T12:47:55.220331Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.017716,"end_time":"2025-07-24T17:47:46.158794","exception":false,"start_time":"2025-07-24T17:47:46.141078","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Writing /tmp/src/getid.py\n","output_type":"stream"}],"execution_count":7},{"id":"d77c14fc","cell_type":"code","source":"%%writefile /tmp/src/llm_validate.py\nimport polars as pl\nimport os\n\nfrom helpers import *\n\nl = get_logger()\n\nSYS_PROMPT_CLASSIFY_DOI = \"\"\"\nYou are a highly accurate DOI/type classifier. Given a snippet of academic text containing a DOI or accession, choose:\n\n  A) Data — the identifier points directly to research data in a repository  \n  B) Literature — the identifier points to a journal article, book chapter, protocol paper, or other non-data resource  \n\n=== Repository Prefixes ===\nTreat as DATA if the DOI starts with any of:\n  • 10.5061 (Dryad)  \n  • 10.5281 (Zenodo)  \n  • 10.6084 (Figshare)  \n  • 10.24433/ (Mendeley Data)  \n  • 10.17632 (Mendeley Data)  \n  • SRA/E- (e.g. SRP, SRA)  \n  • PRJNA, PRJEB, PRJDB (NCBI BioProject)  \n  • PRIDE:PXD (Proteomics)  \n  • EMBL:E-MTAB, E- (ArrayExpress)  \n\nEverything else is LITERATURE unless you see explicit data-repository context (e.g. “deposited in Dryad under DOI…”).\n\n=== Few-Shot Examples ===\n1) “Raw images are stored on Figshare (DOI 10.6084/m9.figshare.1234567).” → A  \n2) “Sequence reads available under BioProject accession PRJNA765432.” → A  \n3) “As described in Nature Methods (DOI 10.1038/s41592-020-0793-2).” → B  \n4) “See Supplementary Data at Zenodo (10.5281/zenodo.987654).” → A  \n5) “Method details published in J. Proteome Res. DOI: 10.1021/acs.jproteome.0c00845.” → B  \n6) “Data has been uploaded to Dryad (10.5061/dryad.x1y2z3).” → A  \n7) “Referenced paper: DOI 10.1101/2020.01.01.123456 (bioRxiv preprint).” → B  \n8) “Metabolomics data in MetaboLights MTBLS1234.” → A  \n\n=== Instructions ===\n- Use only the identifier itself and its context.  \n- If the DOI prefix is in the list above, always choose A.  \n- If it belongs to a known publisher prefix (e.g. 10.1007, 10.1038, 10.1126, 10.1016…), choose B.  \n- Otherwise, rely on context words (“deposited”, “uploaded”, “archived”) to decide.  \n- Output exactly one letter: A or B, and nothing else.\n\"\"\".strip()\n\ndef build_df():\n    df = pl.read_parquet('/tmp/extracted.parquet')\n    df.filter(~is_doi_link('dataset_id')).select('article_id', 'dataset_id').write_csv('/tmp/accid_sub.csv')\n    return df.filter(is_doi_link('dataset_id'))\n\ndef build_prompt(tokenizer, df):\n    prompts = []\n    for doi, text in df.select('dataset_id', 'window').rows():\n        messages = [{'role':'system','content': SYS_PROMPT_CLASSIFY_DOI}, {'role':'user', 'content': text}]\n        prompts.append(tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False, enable_thinking=False))\n    return df.with_columns(pl.Series('prompt', prompts))\n\nif __name__=='__main__':\n    os.environ[\"VLLM_USE_V1\"] = \"0\"\n    import vllm\n    from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n    model_path = \"/kaggle/input/qwen-3/transformers/32b-awq/1\"\n    llm = vllm.LLM(model_path, quantization='awq', tensor_parallel_size=2, gpu_memory_utilization=0.9, trust_remote_code=True, dtype=\"half\", enforce_eager=True, max_model_len=2048, disable_log_stats=True, disable_custom_all_reduce=True, enable_prefix_caching=True, task='generate')\n    tokenizer = llm.get_tokenizer()\n    df = build_df()\n    df = build_prompt(tokenizer, df)\n    prompts = df['prompt'].to_list()\n    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=[\"A\", \"B\"])\n    outputs = llm.generate(prompts, vllm.SamplingParams(seed=777, temperature=0.1, skip_special_tokens=True, max_tokens=1, logits_processors=[mclp], logprobs=len(mclp.choices)), use_tqdm=True)\n    logprobs = [{lp.decoded_token: lp.logprob for lp in list(lps)} for lps in [output.outputs[0].logprobs[0].values() for output in outputs]]\n    choices = [max(d, key=d.get) for d in logprobs]\n    types = {'A': True, 'B': False}\n    choices = [types[c] for c in choices]\n    df = df.with_columns(pl.Series('type', choices))\n    df.filter(pl.col('type')).select('article_id', 'dataset_id').write_csv('/tmp/doi_sub.csv')\n    df = pl.concat([pl.read_csv('/tmp/doi_sub.csv'), pl.read_csv('/tmp/accid_sub.csv')])\n    df = assume_type(df)\n    df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n    if not IS_KAGGLE_SUBMISSION:\n        results = evaluate(df)\n        for r in results: l.info(r) \n        results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n        for r in results: l.info(r)","metadata":{"_cell_guid":"af30506a-e45e-4a3b-ba81-23dd154bde8d","_uuid":"94fc4779-0b43-4058-ac64-f54a7ebd8a76","collapsed":false,"execution":{"iopub.status.busy":"2025-07-25T13:18:59.032856Z","iopub.execute_input":"2025-07-25T13:18:59.033150Z","iopub.status.idle":"2025-07-25T13:18:59.040702Z","shell.execute_reply.started":"2025-07-25T13:18:59.033127Z","shell.execute_reply":"2025-07-25T13:18:59.040147Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.015638,"end_time":"2025-07-24T17:47:46.182360","exception":false,"start_time":"2025-07-24T17:47:46.166722","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting /tmp/src/llm_validate.py\n","output_type":"stream"}],"execution_count":24},{"id":"44326b6d","cell_type":"code","source":"%%writefile /tmp/src/post_filter.py\nimport polars as pl\nfrom helpers import *\n\n\"\"\"\nFourth essence: Post-filter to cut FP DOIs that look like literature.\n- Read /kaggle/working/submission.csv (output of llm_validate.py)\n- Join with /tmp/extracted.parquet to get context window\n- Drop DOI rows that (1) start with typical publisher prefixes AND (2) have no data-ish words nearby\n- Keep accessions untouched\n\"\"\"\n\nl = get_logger()\n\nPAPER_PREFIXES = [\n    \"10.1007\", \"10.1002\", \"10.1016\", \"10.1021\", \"10.1038\", \"10.1056\",\n    \"10.1073\", \"10.1080\", \"10.1093\", \"10.1101\", \"10.1186\", \"10.1371\",\n    \"10.1111\", \"10.5194\", \"10.3390\", \"10.1126\"\n]\n\nCONTEXT_RE = r\"(?i)\\b(data(?:set)?|repository|archive|deposited|available|supplementary|raw(?:\\s+data)?|uploaded|hosted|stored|accession)\\b\"\n\ndef is_paper_prefix(col: str = \"dataset_id\") -> pl.Expr:\n    expr = pl.lit(False)\n    for p in PAPER_PREFIXES:\n        expr = expr | pl.col(col).str.starts_with(f\"{DOI_LINK}{p}\")\n    return expr\n\ndef main():\n    sub = pl.read_csv(\"/kaggle/working/submission.csv\")\n\n    # Normalize columns: drop row_id if present so concat widths match\n    if \"row_id\" in sub.columns:\n        sub = sub.drop(\"row_id\")\n\n    # Context windows\n    win = pl.read_parquet(\"/tmp/extracted.parquet\").select(\"article_id\", \"dataset_id\", \"window\")\n\n    # DOI & ACC split\n    doi_rows = sub.filter(is_doi_link(\"dataset_id\")).join(win, on=[\"article_id\", \"dataset_id\"], how=\"left\")\n    acc_rows = sub.filter(~is_doi_link(\"dataset_id\"))\n\n    keep_mask = (\n        (~is_paper_prefix(\"dataset_id\"))  # not a known paper prefix\n        | doi_rows[\"window\"].fill_null(\"\").str.contains(CONTEXT_RE)\n    )\n\n    kept_doi = doi_rows.filter(keep_mask).select(\"article_id\", \"dataset_id\", \"type\")\n    final = pl.concat([kept_doi, acc_rows.select(\"article_id\", \"dataset_id\", \"type\")])\n\n    # Re-eval & save\n    if not IS_KAGGLE_SUBMISSION:\n        for r in evaluate(final): l.info(r)\n        for r in evaluate(final, on=[\"article_id\", \"dataset_id\", \"type\"]): l.info(r)\n\n    final.with_row_index(\"row_id\").write_csv(\"/kaggle/working/submission.csv\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2025-07-25T12:47:55.238840Z","iopub.execute_input":"2025-07-25T12:47:55.239055Z","iopub.status.idle":"2025-07-25T12:47:55.254303Z","shell.execute_reply.started":"2025-07-25T12:47:55.239032Z","shell.execute_reply":"2025-07-25T12:47:55.253678Z"},"papermill":{"duration":0.015034,"end_time":"2025-07-24T17:47:46.205766","exception":false,"start_time":"2025-07-24T17:47:46.190732","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Writing /tmp/src/post_filter.py\n","output_type":"stream"}],"execution_count":9},{"id":"f5a81343-7422-4341-aa77-615262e09350","cell_type":"code","source":"%cd /tmp\n!LOG_LEVEL=INFO python src/parse.py /tmp/train_parse\n! python src/check_parse.py\n! python src/getid.py","metadata":{"_cell_guid":"c6a12705-737a-4b21-9bf2-125b3d1ab724","_kg_hide-output":true,"_uuid":"bc8e0d68-3097-4ce9-99a1-536921913550","collapsed":false,"execution":{"iopub.status.busy":"2025-07-25T12:47:55.254926Z","iopub.execute_input":"2025-07-25T12:47:55.255182Z","iopub.status.idle":"2025-07-25T12:52:28.284660Z","shell.execute_reply.started":"2025-07-25T12:47:55.255166Z","shell.execute_reply":"2025-07-25T12:52:28.284001Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":456.328258,"end_time":"2025-07-24T17:55:22.542564","exception":false,"start_time":"2025-07-24T17:47:46.214306","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"b1e0eeb9-63f7-46fa-ab12-b53d9e73e6d8","cell_type":"code","source":"! python src/llm_validate.py\n! python src/post_filter.py","metadata":{"_cell_guid":"c6a12705-737a-4b21-9bf2-125b3d1ab724","_kg_hide-output":true,"_uuid":"bc8e0d68-3097-4ce9-99a1-536921913550","collapsed":false,"execution":{"iopub.status.busy":"2025-07-25T13:19:09.700843Z","iopub.execute_input":"2025-07-25T13:19:09.701577Z","iopub.status.idle":"2025-07-25T13:23:05.408639Z","shell.execute_reply.started":"2025-07-25T13:19:09.701551Z","shell.execute_reply":"2025-07-25T13:23:05.407706Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":456.328258,"end_time":"2025-07-24T17:55:22.542564","exception":false,"start_time":"2025-07-24T17:47:46.214306","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"2025-07-25 13:19:17.935312: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753449557.962239     905 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753449557.970058     905 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 07-25 13:19:21 [__init__.py:244] Automatically detected platform cuda.\nINFO 07-25 13:19:36 [config.py:1472] Using max model len 2048\nWARNING 07-25 13:19:37 [config.py:960] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\nWARNING 07-25 13:19:37 [cuda.py:102] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\nINFO 07-25 13:19:37 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.2) with config: model='/kaggle/input/qwen-3/transformers/32b-awq/1', speculative_config=None, tokenizer='/kaggle/input/qwen-3/transformers/32b-awq/1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=awq, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='xgrammar', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/kaggle/input/qwen-3/transformers/32b-awq/1, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":0,\"local_cache_dir\":null}, use_cached_outputs=False, \nWARNING 07-25 13:19:38 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 2 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n\u001b[1;36m(VllmWorkerProcess pid=933)\u001b[0;0m INFO 07-25 13:19:38 [multiproc_worker_utils.py:226] Worker ready; awaiting tasks\nINFO 07-25 13:19:38 [cuda.py:311] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\nINFO 07-25 13:19:38 [cuda.py:360] Using XFormers backend.\n\u001b[1;36m(VllmWorkerProcess pid=933)\u001b[0;0m INFO 07-25 13:19:38 [cuda.py:311] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n\u001b[1;36m(VllmWorkerProcess pid=933)\u001b[0;0m INFO 07-25 13:19:38 [cuda.py:360] Using XFormers backend.\n[W725 13:19:49.983133243 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W725 13:19:50.502399903 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W725 13:19:59.993726434 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W725 13:20:09.004224670 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\nINFO 07-25 13:20:09 [__init__.py:1152] Found nccl from library libnccl.so.2\n\u001b[1;36m(VllmWorkerProcess pid=933)\u001b[0;0m INFO 07-25 13:20:09 [__init__.py:1152] Found nccl from library libnccl.so.2\n\u001b[1;36m(VllmWorkerProcess pid=933)\u001b[0;0m INFO 07-25 13:20:09 [pynccl.py:70] vLLM is using nccl==2.26.2\nINFO 07-25 13:20:09 [pynccl.py:70] vLLM is using nccl==2.26.2\nINFO 07-25 13:20:09 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_94a932d9'), local_subscribe_addr='ipc:///tmp/15439c01-d161-453a-9d58-e72993223313', remote_subscribe_addr=None, remote_addr_ipv6=False)\nINFO 07-25 13:20:09 [parallel_state.py:1076] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n\u001b[1;36m(VllmWorkerProcess pid=933)\u001b[0;0m INFO 07-25 13:20:09 [parallel_state.py:1076] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\nINFO 07-25 13:20:09 [model_runner.py:1171] Starting to load model /kaggle/input/qwen-3/transformers/32b-awq/1...\n\u001b[1;36m(VllmWorkerProcess pid=933)\u001b[0;0m INFO 07-25 13:20:09 [model_runner.py:1171] Starting to load model /kaggle/input/qwen-3/transformers/32b-awq/1...\nLoading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\nLoading safetensors checkpoint shards:  25% Completed | 1/4 [00:41<02:05, 41.86s/it]\nLoading safetensors checkpoint shards:  50% Completed | 2/4 [00:44<00:37, 18.63s/it]\nLoading safetensors checkpoint shards:  75% Completed | 3/4 [00:46<00:11, 11.11s/it]\nLoading safetensors checkpoint shards: 100% Completed | 4/4 [00:47<00:00,  7.28s/it]\nLoading safetensors checkpoint shards: 100% Completed | 4/4 [00:47<00:00, 11.95s/it]\n\n\u001b[1;36m(VllmWorkerProcess pid=933)\u001b[0;0m INFO 07-25 13:20:58 [default_loader.py:272] Loading weights took 47.89 seconds\nINFO 07-25 13:20:58 [default_loader.py:272] Loading weights took 47.95 seconds\n\u001b[1;36m(VllmWorkerProcess pid=933)\u001b[0;0m INFO 07-25 13:20:59 [model_runner.py:1203] Model loading took 9.0570 GiB and 48.240953 seconds\nINFO 07-25 13:20:59 [model_runner.py:1203] Model loading took 9.0570 GiB and 48.305660 seconds\n\u001b[1;36m(VllmWorkerProcess pid=933)\u001b[0;0m INFO 07-25 13:21:05 [worker.py:294] Memory profiling takes 6.06 seconds\n\u001b[1;36m(VllmWorkerProcess pid=933)\u001b[0;0m INFO 07-25 13:21:05 [worker.py:294] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.90) = 13.27GiB\n\u001b[1;36m(VllmWorkerProcess pid=933)\u001b[0;0m INFO 07-25 13:21:05 [worker.py:294] model weights take 9.06GiB; non_torch_memory takes 0.11GiB; PyTorch activation peak memory takes 0.41GiB; the rest of the memory reserved for KV Cache is 3.70GiB.\nINFO 07-25 13:21:06 [worker.py:294] Memory profiling takes 6.32 seconds\nINFO 07-25 13:21:06 [worker.py:294] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.90) = 13.27GiB\nINFO 07-25 13:21:06 [worker.py:294] model weights take 9.06GiB; non_torch_memory takes 0.11GiB; PyTorch activation peak memory takes 1.40GiB; the rest of the memory reserved for KV Cache is 2.70GiB.\nINFO 07-25 13:21:06 [executor_base.py:113] # cuda blocks: 1381, # CPU blocks: 2048\nINFO 07-25 13:21:06 [executor_base.py:118] Maximum concurrency for 2048 tokens per request: 10.79x\nINFO 07-25 13:21:10 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 10.96 seconds\nAdding requests: 100%|███████████████████████| 430/430 [00:01<00:00, 356.64it/s]\nProcessed prompts: 100%|█| 430/430 [01:44<00:00,  4.12it/s, est. speed input: 31\nINFO 2025-07-25 13:22:56  [llm_validate.py:81 - <module>()] all - f1: 0.5960 [486/426/233]\nINFO 2025-07-25 13:22:56  [llm_validate.py:81 - <module>()] doi - f1: 0.5795 [164/77/161]\nINFO 2025-07-25 13:22:56  [llm_validate.py:81 - <module>()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 13:22:56  [llm_validate.py:83 - <module>()] all - f1: 0.4942 [403/509/316]\nINFO 2025-07-25 13:22:56  [llm_validate.py:83 - <module>()] doi - f1: 0.4452 [126/115/199]\nINFO 2025-07-25 13:22:56  [llm_validate.py:83 - <module>()] acc - f1: 0.5202 [277/394/117]\nINFO 07-25 13:22:58 [multiproc_worker_utils.py:125] Killing local vLLM worker processes\n[rank0]:[W725 13:23:00.528799815 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\nINFO 2025-07-25 13:23:05  [post_filter.py:52 - main()] all - f1: 0.5960 [486/426/233]\nINFO 2025-07-25 13:23:05  [post_filter.py:52 - main()] doi - f1: 0.5795 [164/77/161]\nINFO 2025-07-25 13:23:05  [post_filter.py:52 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 13:23:05  [post_filter.py:53 - main()] all - f1: 0.4942 [403/509/316]\nINFO 2025-07-25 13:23:05  [post_filter.py:53 - main()] doi - f1: 0.4452 [126/115/199]\nINFO 2025-07-25 13:23:05  [post_filter.py:53 - main()] acc - f1: 0.5202 [277/394/117]\n","output_type":"stream"}],"execution_count":25},{"id":"77c319f4-9d39-47ad-bb7c-b932cac791e9","cell_type":"code","source":"# ! grep \"f1:\" /tmp/logs/project.log","metadata":{"_cell_guid":"c6a12705-737a-4b21-9bf2-125b3d1ab724","_kg_hide-output":true,"_uuid":"bc8e0d68-3097-4ce9-99a1-536921913550","collapsed":false,"execution":{"iopub.status.busy":"2025-07-25T13:10:05.646501Z","iopub.execute_input":"2025-07-25T13:10:05.647184Z","iopub.status.idle":"2025-07-25T13:10:05.767634Z","shell.execute_reply.started":"2025-07-25T13:10:05.647144Z","shell.execute_reply":"2025-07-25T13:10:05.766988Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":456.328258,"end_time":"2025-07-24T17:55:22.542564","exception":false,"start_time":"2025-07-24T17:47:46.214306","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"INFO 2025-07-25 12:49:26  [getid.py:190 - main()] all - f1: 0.5341 [486/615/233]\nINFO 2025-07-25 12:49:26  [getid.py:190 - main()] doi - f1: 0.4344 [164/266/161]\nINFO 2025-07-25 12:49:26  [getid.py:190 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 12:49:26  [getid.py:192 - main()] all - f1: 0.4429 [403/698/316]\nINFO 2025-07-25 12:49:26  [getid.py:192 - main()] doi - f1: 0.3338 [126/304/199]\nINFO 2025-07-25 12:49:26  [getid.py:192 - main()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 12:52:18  [llm_validate.py:81 - <module>()] all - f1: 0.5341 [486/615/233]\nINFO 2025-07-25 12:52:18  [llm_validate.py:81 - <module>()] doi - f1: 0.4344 [164/266/161]\nINFO 2025-07-25 12:52:18  [llm_validate.py:81 - <module>()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 12:52:18  [llm_validate.py:83 - <module>()] all - f1: 0.4429 [403/698/316]\nINFO 2025-07-25 12:52:18  [llm_validate.py:83 - <module>()] doi - f1: 0.3338 [126/304/199]\nINFO 2025-07-25 12:52:18  [llm_validate.py:83 - <module>()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 12:52:28  [post_filter.py:52 - main()] all - f1: 0.5668 [486/510/233]\nINFO 2025-07-25 12:52:28  [post_filter.py:52 - main()] doi - f1: 0.5046 [164/161/161]\nINFO 2025-07-25 12:52:28  [post_filter.py:52 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 12:52:28  [post_filter.py:53 - main()] all - f1: 0.4700 [403/593/316]\nINFO 2025-07-25 12:52:28  [post_filter.py:53 - main()] doi - f1: 0.3877 [126/199/199]\nINFO 2025-07-25 12:52:28  [post_filter.py:53 - main()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 12:58:51  [llm_validate.py:81 - <module>()] all - f1: 0.4633 [322/349/397]\nINFO 2025-07-25 12:58:51  [llm_validate.py:81 - <module>()] doi - f1: 0.0000 [0/0/325]\nINFO 2025-07-25 12:58:51  [llm_validate.py:81 - <module>()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 12:58:51  [llm_validate.py:83 - <module>()] all - f1: 0.3986 [277/394/442]\nINFO 2025-07-25 12:58:51  [llm_validate.py:83 - <module>()] doi - f1: 0.0000 [0/0/325]\nINFO 2025-07-25 12:58:51  [llm_validate.py:83 - <module>()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 12:58:59  [post_filter.py:52 - main()] all - f1: 0.4633 [322/349/397]\nINFO 2025-07-25 12:58:59  [post_filter.py:52 - main()] doi - f1: 0.0000 [0/0/325]\nINFO 2025-07-25 12:58:59  [post_filter.py:52 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 12:58:59  [post_filter.py:53 - main()] all - f1: 0.3986 [277/394/442]\nINFO 2025-07-25 12:58:59  [post_filter.py:53 - main()] doi - f1: 0.0000 [0/0/325]\nINFO 2025-07-25 12:58:59  [post_filter.py:53 - main()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 13:09:24  [llm_validate.py:81 - <module>()] all - f1: 0.5960 [486/426/233]\nINFO 2025-07-25 13:09:24  [llm_validate.py:81 - <module>()] doi - f1: 0.5795 [164/77/161]\nINFO 2025-07-25 13:09:24  [llm_validate.py:81 - <module>()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 13:09:24  [llm_validate.py:83 - <module>()] all - f1: 0.4942 [403/509/316]\nINFO 2025-07-25 13:09:24  [llm_validate.py:83 - <module>()] doi - f1: 0.4452 [126/115/199]\nINFO 2025-07-25 13:09:24  [llm_validate.py:83 - <module>()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 13:09:32  [post_filter.py:52 - main()] all - f1: 0.5960 [486/426/233]\nINFO 2025-07-25 13:09:32  [post_filter.py:52 - main()] doi - f1: 0.5795 [164/77/161]\nINFO 2025-07-25 13:09:32  [post_filter.py:52 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 13:09:32  [post_filter.py:53 - main()] all - f1: 0.4942 [403/509/316]\nINFO 2025-07-25 13:09:32  [post_filter.py:53 - main()] doi - f1: 0.4452 [126/115/199]\nINFO 2025-07-25 13:09:32  [post_filter.py:53 - main()] acc - f1: 0.5202 [277/394/117]\n","output_type":"stream"}],"execution_count":19},{"id":"d242b030-a074-471e-9b5e-2bde683bbc41","cell_type":"code","source":"# ! cat /tmp/logs/project.log","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T13:23:17.333169Z","iopub.execute_input":"2025-07-25T13:23:17.333751Z","iopub.status.idle":"2025-07-25T13:23:17.451791Z","shell.execute_reply.started":"2025-07-25T13:23:17.333723Z","shell.execute_reply":"2025-07-25T13:23:17.451159Z"}},"outputs":[{"name":"stdout","text":"INFO 2025-07-25 12:49:20  [check_parse.py:31 - main()] pymupdf misses: 42 dataset_ids\nINFO 2025-07-25 12:49:26  [getid.py:190 - main()] all - f1: 0.5341 [486/615/233]\nINFO 2025-07-25 12:49:26  [getid.py:190 - main()] doi - f1: 0.4344 [164/266/161]\nINFO 2025-07-25 12:49:26  [getid.py:190 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 12:49:26  [getid.py:192 - main()] all - f1: 0.4429 [403/698/316]\nINFO 2025-07-25 12:49:26  [getid.py:192 - main()] doi - f1: 0.3338 [126/304/199]\nINFO 2025-07-25 12:49:26  [getid.py:192 - main()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 12:52:18  [llm_validate.py:81 - <module>()] all - f1: 0.5341 [486/615/233]\nINFO 2025-07-25 12:52:18  [llm_validate.py:81 - <module>()] doi - f1: 0.4344 [164/266/161]\nINFO 2025-07-25 12:52:18  [llm_validate.py:81 - <module>()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 12:52:18  [llm_validate.py:83 - <module>()] all - f1: 0.4429 [403/698/316]\nINFO 2025-07-25 12:52:18  [llm_validate.py:83 - <module>()] doi - f1: 0.3338 [126/304/199]\nINFO 2025-07-25 12:52:18  [llm_validate.py:83 - <module>()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 12:52:28  [post_filter.py:52 - main()] all - f1: 0.5668 [486/510/233]\nINFO 2025-07-25 12:52:28  [post_filter.py:52 - main()] doi - f1: 0.5046 [164/161/161]\nINFO 2025-07-25 12:52:28  [post_filter.py:52 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 12:52:28  [post_filter.py:53 - main()] all - f1: 0.4700 [403/593/316]\nINFO 2025-07-25 12:52:28  [post_filter.py:53 - main()] doi - f1: 0.3877 [126/199/199]\nINFO 2025-07-25 12:52:28  [post_filter.py:53 - main()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 12:58:51  [llm_validate.py:81 - <module>()] all - f1: 0.4633 [322/349/397]\nINFO 2025-07-25 12:58:51  [llm_validate.py:81 - <module>()] doi - f1: 0.0000 [0/0/325]\nINFO 2025-07-25 12:58:51  [llm_validate.py:81 - <module>()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 12:58:51  [llm_validate.py:83 - <module>()] all - f1: 0.3986 [277/394/442]\nINFO 2025-07-25 12:58:51  [llm_validate.py:83 - <module>()] doi - f1: 0.0000 [0/0/325]\nINFO 2025-07-25 12:58:51  [llm_validate.py:83 - <module>()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 12:58:59  [post_filter.py:52 - main()] all - f1: 0.4633 [322/349/397]\nINFO 2025-07-25 12:58:59  [post_filter.py:52 - main()] doi - f1: 0.0000 [0/0/325]\nINFO 2025-07-25 12:58:59  [post_filter.py:52 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 12:58:59  [post_filter.py:53 - main()] all - f1: 0.3986 [277/394/442]\nINFO 2025-07-25 12:58:59  [post_filter.py:53 - main()] doi - f1: 0.0000 [0/0/325]\nINFO 2025-07-25 12:58:59  [post_filter.py:53 - main()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 13:09:24  [llm_validate.py:81 - <module>()] all - f1: 0.5960 [486/426/233]\nINFO 2025-07-25 13:09:24  [llm_validate.py:81 - <module>()] doi - f1: 0.5795 [164/77/161]\nINFO 2025-07-25 13:09:24  [llm_validate.py:81 - <module>()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 13:09:24  [llm_validate.py:83 - <module>()] all - f1: 0.4942 [403/509/316]\nINFO 2025-07-25 13:09:24  [llm_validate.py:83 - <module>()] doi - f1: 0.4452 [126/115/199]\nINFO 2025-07-25 13:09:24  [llm_validate.py:83 - <module>()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 13:09:32  [post_filter.py:52 - main()] all - f1: 0.5960 [486/426/233]\nINFO 2025-07-25 13:09:32  [post_filter.py:52 - main()] doi - f1: 0.5795 [164/77/161]\nINFO 2025-07-25 13:09:32  [post_filter.py:52 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 13:09:32  [post_filter.py:53 - main()] all - f1: 0.4942 [403/509/316]\nINFO 2025-07-25 13:09:32  [post_filter.py:53 - main()] doi - f1: 0.4452 [126/115/199]\nINFO 2025-07-25 13:09:32  [post_filter.py:53 - main()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 13:17:26  [llm_validate.py:81 - <module>()] all - f1: 0.5224 [402/418/317]\nINFO 2025-07-25 13:17:26  [llm_validate.py:81 - <module>()] doi - f1: 0.3376 [80/69/245]\nINFO 2025-07-25 13:17:26  [llm_validate.py:81 - <module>()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 13:17:26  [llm_validate.py:83 - <module>()] all - f1: 0.4379 [337/483/382]\nINFO 2025-07-25 13:17:26  [llm_validate.py:83 - <module>()] doi - f1: 0.2532 [60/89/265]\nINFO 2025-07-25 13:17:26  [llm_validate.py:83 - <module>()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 13:17:34  [post_filter.py:52 - main()] all - f1: 0.5300 [402/396/317]\nINFO 2025-07-25 13:17:34  [post_filter.py:52 - main()] doi - f1: 0.3540 [80/47/245]\nINFO 2025-07-25 13:17:34  [post_filter.py:52 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 13:17:34  [post_filter.py:53 - main()] all - f1: 0.4443 [337/461/382]\nINFO 2025-07-25 13:17:34  [post_filter.py:53 - main()] doi - f1: 0.2655 [60/67/265]\nINFO 2025-07-25 13:17:34  [post_filter.py:53 - main()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 13:22:56  [llm_validate.py:81 - <module>()] all - f1: 0.5960 [486/426/233]\nINFO 2025-07-25 13:22:56  [llm_validate.py:81 - <module>()] doi - f1: 0.5795 [164/77/161]\nINFO 2025-07-25 13:22:56  [llm_validate.py:81 - <module>()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 13:22:56  [llm_validate.py:83 - <module>()] all - f1: 0.4942 [403/509/316]\nINFO 2025-07-25 13:22:56  [llm_validate.py:83 - <module>()] doi - f1: 0.4452 [126/115/199]\nINFO 2025-07-25 13:22:56  [llm_validate.py:83 - <module>()] acc - f1: 0.5202 [277/394/117]\nINFO 2025-07-25 13:23:05  [post_filter.py:52 - main()] all - f1: 0.5960 [486/426/233]\nINFO 2025-07-25 13:23:05  [post_filter.py:52 - main()] doi - f1: 0.5795 [164/77/161]\nINFO 2025-07-25 13:23:05  [post_filter.py:52 - main()] acc - f1: 0.6047 [322/349/72]\nINFO 2025-07-25 13:23:05  [post_filter.py:53 - main()] all - f1: 0.4942 [403/509/316]\nINFO 2025-07-25 13:23:05  [post_filter.py:53 - main()] doi - f1: 0.4452 [126/115/199]\nINFO 2025-07-25 13:23:05  [post_filter.py:53 - main()] acc - f1: 0.5202 [277/394/117]\n","output_type":"stream"}],"execution_count":26},{"id":"3eddd820","cell_type":"markdown","source":"INFO 2025-07-23 15:22:18  [post_filter.py:52 - main()] all - f1: 0.6891 [481/196/238]\n\nINFO 2025-07-23 15:22:18  [post_filter.py:52 - main()] doi - f1: 0.5889 [164/68/161]\n\nINFO 2025-07-23 15:22:18  [post_filter.py:52 - main()] acc - f1: 0.7557 [317/128/77]\n\nINFO 2025-07-23 15:22:18  [post_filter.py:53 - main()] all - f1: 0.5759 [402/275/317]\n\nINFO 2025-07-23 15:22:18  [post_filter.py:53 - main()] doi - f1: 0.4596 [128/104/197]\n\nINFO 2025-07-23 15:22:18  [post_filter.py:53 - main()] acc - f1: 0.6532 [274/171/120]","metadata":{"papermill":{"duration":0.010278,"end_time":"2025-07-24T17:55:22.563271","exception":false,"start_time":"2025-07-24T17:55:22.552993","status":"completed"},"tags":[]}}]}